{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"100-Sentiment2model.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"i3dMWV0Z8y71"},"source":["**Word Embedding ‡∏Ç‡∏≠‡∏á keras**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AA-zs43j1vBr","executionInfo":{"status":"ok","timestamp":1628694884145,"user_tz":-420,"elapsed":3479,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"00622de0-f232-4555-eeac-7b8f65d83d7e"},"source":["pip install pythainlp"],"execution_count":75,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pythainlp in /usr/local/lib/python3.7/dist-packages (2.3.1)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (2.23.0)\n","Requirement already satisfied: tinydb>=3.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (4.5.1)\n","Requirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (0.9.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n","Requirement already satisfied: typing-extensions<4.0.0,>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from tinydb>=3.0->pythainlp) (3.10.0.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ED3SC9j74qN_"},"source":["\n","\n","> Import Package ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ word embedding ‡∏Ç‡∏≠‡∏á keras\n","\n"]},{"cell_type":"code","metadata":{"id":"3wUBHwwj39bh","executionInfo":{"status":"ok","timestamp":1628694884146,"user_tz":-420,"elapsed":58,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["import pandas as pd\n","import re\n","# from nltk.tokenize import word_tokenize\n","from pythainlp.tokenize import word_tokenize\n","from keras.preprocessing.text import Tokenizer\n","\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","\n","import numpy as np\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, GRU, LSTM, Bidirectional, Embedding, Dropout, BatchNormalization\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","import seaborn as sn\n","import matplotlib.pyplot as plt\n","\n","import pickle as p\n","import plotly\n","import plotly.graph_objs as go\n","\n","from sklearn.metrics import confusion_matrix\n","\n","from sklearn.metrics import classification_report"],"execution_count":76,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j6EzSfFX4MXe"},"source":["\n","\n","> ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô EPOCHS ‡πÅ‡∏•‡∏∞ Batch Size\n"]},{"cell_type":"code","metadata":{"id":"Kk_nytIB4BsD","executionInfo":{"status":"ok","timestamp":1628694884147,"user_tz":-420,"elapsed":58,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["EPOCHS = 150\n","BS = 32"],"execution_count":77,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b5t_nqMu4eQR"},"source":["\n","\n","> ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Sentiment Analysis\n","\n"]},{"cell_type":"code","metadata":{"id":"hGKxKJISs9oj","executionInfo":{"status":"ok","timestamp":1628694884147,"user_tz":-420,"elapsed":58,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["df = pd.read_csv ('Comments.csv',encoding = \"utf-8\")"],"execution_count":78,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"id":"m__zi6JO7IQS","executionInfo":{"status":"ok","timestamp":1628694884148,"user_tz":-420,"elapsed":58,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"4a181d9d-6656-487e-b63a-f901a8341beb"},"source":["df"],"execution_count":79,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>comments</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>pos</td>\n","      <td>‡∏ü‡∏±‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏¥‡∏°‡∏û‡∏π‡∏î ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏î‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏° üëèüëè</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>pos</td>\n","      <td>‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏ü‡∏±‡∏á‡∏ô‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÑ‡∏î‡πâ‡∏ô‡∏≤‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡∏ô‡∏µ‡πâ‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏•‡∏¢ ‡∏ä‡∏∑‡πà...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>pos</td>\n","      <td>‡∏ü‡∏±‡∏á‡∏Ñ‡∏∏‡∏ì‡∏´‡∏ç‡∏¥‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏û‡∏¥‡∏ò‡∏≤ ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ß‡∏±‡∏á ‡πÄ‡∏Ç‡πâ‡∏≤...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>pos</td>\n","      <td>‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‚Äã‡∏°‡∏≤‡∏Å‚Äã‡∏Ñ‡∏£‡∏±‡∏ö‚Äã‡∏Ñ‡∏∏‡∏ì‚Äã‡∏à‡∏≠‡∏°‡∏Ç‡∏ß‡∏±‡∏ç ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‚Äã‡∏™‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏Å‡∏•‡πâ‡∏≤...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>pos</td>\n","      <td>‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∏‡∏ì‡∏û‡∏¥‡∏ò‡∏≤‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏™‡∏∏‡∏î‡∏≤‡∏£‡∏±‡∏ï‡∏ô‡πå ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏ô‡∏±‡∏Å‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡πÅ‡∏•...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>neg</td>\n","      <td>‡πÅ‡∏´‡∏°‡πà‚Äã ‡πÄ‡∏≠‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏≤‡∏¢‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏¥‡∏î‡πÑ‡∏õ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‚Äã‡∏ó‡∏µ‡πà‡∏õ...</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>neg</td>\n","      <td>‡∏£‡∏±‡∏ê‡∏ö‡∏≤‡∏•‡∏≠‡∏µ‡πÇ‡∏Å‡πâ‡∏™‡∏π‡∏á ‡∏°‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏ü‡∏±‡∏á‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>neg</td>\n","      <td>‡∏°‡∏∂‡∏á‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡πÇ‡∏Ñ‡∏ï‡∏£‡∏ú‡∏±‡∏Å‡∏ä‡∏µ‡πÇ‡∏£‡∏¢‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏•‡∏¢‡∏ß‡πà‡∏∞ ‡∏à‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å...</td>\n","    </tr>\n","    <tr>\n","      <th>498</th>\n","      <td>neg</td>\n","      <td>‡πÑ‡∏õ‡∏Ç‡∏∏‡∏î‡∏£‡∏°‡∏ï.‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô ‡∏≠‡∏ô‡∏≤‡∏ñ</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>neg</td>\n","      <td>‡∏ó‡∏µ‡πà‡∏ô‡∏±‡∏Å‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡πÑ‡∏°‡πà‡∏°‡∏≤‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏Ç‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡∏ú‡∏π‡πâ‡∏ô‡∏≥‡πÇ‡∏á‡πà‡πÅ‡∏•...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>500 rows √ó 2 columns</p>\n","</div>"],"text/plain":["    labels                                           comments\n","0      pos                ‡∏ü‡∏±‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏¥‡∏°‡∏û‡∏π‡∏î ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏î‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏° üëèüëè\n","1      pos  ‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏ü‡∏±‡∏á‡∏ô‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÑ‡∏î‡πâ‡∏ô‡∏≤‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡∏ô‡∏µ‡πâ‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏•‡∏¢ ‡∏ä‡∏∑‡πà...\n","2      pos  ‡∏ü‡∏±‡∏á‡∏Ñ‡∏∏‡∏ì‡∏´‡∏ç‡∏¥‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏û‡∏¥‡∏ò‡∏≤ ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ß‡∏±‡∏á ‡πÄ‡∏Ç‡πâ‡∏≤...\n","3      pos  ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‚Äã‡∏°‡∏≤‡∏Å‚Äã‡∏Ñ‡∏£‡∏±‡∏ö‚Äã‡∏Ñ‡∏∏‡∏ì‚Äã‡∏à‡∏≠‡∏°‡∏Ç‡∏ß‡∏±‡∏ç ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‚Äã‡∏™‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏Å‡∏•‡πâ‡∏≤...\n","4      pos  ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∏‡∏ì‡∏û‡∏¥‡∏ò‡∏≤‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏™‡∏∏‡∏î‡∏≤‡∏£‡∏±‡∏ï‡∏ô‡πå ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏ô‡∏±‡∏Å‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡πÅ‡∏•...\n","..     ...                                                ...\n","495    neg  ‡πÅ‡∏´‡∏°‡πà‚Äã ‡πÄ‡∏≠‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏≤‡∏¢‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏¥‡∏î‡πÑ‡∏õ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‚Äã‡∏ó‡∏µ‡πà‡∏õ...\n","496    neg                 ‡∏£‡∏±‡∏ê‡∏ö‡∏≤‡∏•‡∏≠‡∏µ‡πÇ‡∏Å‡πâ‡∏™‡∏π‡∏á ‡∏°‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏ü‡∏±‡∏á‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞\n","497    neg  ‡∏°‡∏∂‡∏á‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡πÇ‡∏Ñ‡∏ï‡∏£‡∏ú‡∏±‡∏Å‡∏ä‡∏µ‡πÇ‡∏£‡∏¢‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏•‡∏¢‡∏ß‡πà‡∏∞ ‡∏à‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å...\n","498    neg                          ‡πÑ‡∏õ‡∏Ç‡∏∏‡∏î‡∏£‡∏°‡∏ï.‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô ‡∏≠‡∏ô‡∏≤‡∏ñ\n","499    neg  ‡∏ó‡∏µ‡πà‡∏ô‡∏±‡∏Å‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡πÑ‡∏°‡πà‡∏°‡∏≤‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏Ç‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡∏ú‡∏π‡πâ‡∏ô‡∏≥‡πÇ‡∏á‡πà‡πÅ‡∏•...\n","\n","[500 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"code","metadata":{"id":"bbGotXte7a0x","executionInfo":{"status":"ok","timestamp":1628694884149,"user_tz":-420,"elapsed":58,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["df = df.drop_duplicates()"],"execution_count":80,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"_2HwogYa7ath","executionInfo":{"status":"ok","timestamp":1628694884150,"user_tz":-420,"elapsed":59,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"8bba997d-3db9-48d7-8ffb-4ec8657310a9"},"source":["pos_df = df[df.labels == \"pos\"].sample(250)\n","pos_df.head()"],"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>comments</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>144</th>\n","      <td>pos</td>\n","      <td>‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡∏Ñ‡∏∏‡∏ì‡∏û‡∏¥‡∏ò‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏≤‡∏¢‡∏Åüòä</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>pos</td>\n","      <td>‡∏Ñ‡∏∑‡∏≠‡∏£‡∏≠‡∏Å‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏¥‡∏°‡πÉ‡∏ô‡∏Ñ‡∏π‡∏´‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏£‡∏≠‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (‡∏ó‡∏µ‡πà‡πÑ‡∏°...</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>pos</td>\n","      <td>‡∏û‡∏¥‡∏ò‡∏≤ ‡πÄ‡∏ü‡∏µ‡πâ‡∏¢‡∏ß‡∏à‡∏±‡∏á‡∏ß‡∏∞</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>pos</td>\n","      <td>‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏¥‡∏°‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡∏û‡∏£‡∏£‡∏Ñ‡∏Å‡πâ‡∏≤‡∏ß‡πÑ‡∏Å‡∏• ‡∏Ñ‡∏ß‡∏≤...</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>pos</td>\n","      <td>‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏¥‡∏° ‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    labels                                           comments\n","144    pos                            ‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡∏Ñ‡∏∏‡∏ì‡∏û‡∏¥‡∏ò‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏≤‡∏¢‡∏Åüòä\n","41     pos  ‡∏Ñ‡∏∑‡∏≠‡∏£‡∏≠‡∏Å‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏¥‡∏°‡πÉ‡∏ô‡∏Ñ‡∏π‡∏´‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏£‡∏≠‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (‡∏ó‡∏µ‡πà‡πÑ‡∏°...\n","45     pos                                   ‡∏û‡∏¥‡∏ò‡∏≤ ‡πÄ‡∏ü‡∏µ‡πâ‡∏¢‡∏ß‡∏à‡∏±‡∏á‡∏ß‡∏∞\n","97     pos  ‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏¥‡∏°‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡∏û‡∏£‡∏£‡∏Ñ‡∏Å‡πâ‡∏≤‡∏ß‡πÑ‡∏Å‡∏• ‡∏Ñ‡∏ß‡∏≤...\n","36     pos                          ‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏¥‡∏° ‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á"]},"metadata":{"tags":[]},"execution_count":81}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"vGb_Zpx_7aqB","executionInfo":{"status":"ok","timestamp":1628694884151,"user_tz":-420,"elapsed":59,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"e020a578-56dd-48aa-cca4-81ba172100d0"},"source":["neg_df = df[df.labels == \"neg\"].sample(250)\n","neg_df.head()"],"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>comments</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>475</th>\n","      <td>neg</td>\n","      <td>‡∏ô‡∏µ‡πà‡πÄ‡∏≠‡∏≤‡∏£‡∏±‡∏ê‡∏°‡∏ô‡∏ï‡∏£‡∏µ‡∏°‡∏≤‡∏Ñ‡∏∏‡∏¢‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏´‡∏£‡∏≠‡∏Ñ‡∏£‡∏±‡∏ö ‡πÉ‡∏´‡πâ‡πÄ‡∏î‡∏¥‡∏ô‡πÑ‡∏õ‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏∞...</td>\n","    </tr>\n","    <tr>\n","      <th>471</th>\n","      <td>neg</td>\n","      <td>‡∏ü‡∏±‡∏á‡∏ó‡πà‡∏≤‡∏ô ‡∏£‡∏°‡∏ï. ‡πÅ‡∏•‡πâ‡∏ß ‡∏ó‡πà‡∏≤‡∏ô‡πÄ‡∏≠‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏£...</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>neg</td>\n","      <td>‡πÉ‡∏ô ‡∏Ñ‡∏£‡∏° ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÉ‡∏Ñ‡∏£‡∏â‡∏•‡∏≤‡∏î‡∏ö‡πâ‡∏≤‡∏á‡∏ß‡∏∞ ‡∏ï‡∏≠‡∏ô‡∏£‡∏ß‡∏° ‡∏Ñ‡∏£‡∏° ‡∏ú‡πà‡∏≤‡∏ï‡∏±‡∏î‡πÄ‡∏≠‡∏≤...</td>\n","    </tr>\n","    <tr>\n","      <th>318</th>\n","      <td>neg</td>\n","      <td>‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡∏â‡∏µ‡∏î‡∏ß‡∏±‡∏Ñ‡∏ã‡∏µ‡∏ô‡πÑ‡∏£‡πâ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö1 ‡∏Ç‡∏≠...</td>\n","    </tr>\n","    <tr>\n","      <th>435</th>\n","      <td>neg</td>\n","      <td>‡∏£‡∏°‡∏ï ‡∏ô‡∏µ‡πâ‡∏û‡∏π‡∏î‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏•‡∏¢ ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ß...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    labels                                           comments\n","475    neg  ‡∏ô‡∏µ‡πà‡πÄ‡∏≠‡∏≤‡∏£‡∏±‡∏ê‡∏°‡∏ô‡∏ï‡∏£‡∏µ‡∏°‡∏≤‡∏Ñ‡∏∏‡∏¢‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏´‡∏£‡∏≠‡∏Ñ‡∏£‡∏±‡∏ö ‡πÉ‡∏´‡πâ‡πÄ‡∏î‡∏¥‡∏ô‡πÑ‡∏õ‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏∞...\n","471    neg  ‡∏ü‡∏±‡∏á‡∏ó‡πà‡∏≤‡∏ô ‡∏£‡∏°‡∏ï. ‡πÅ‡∏•‡πâ‡∏ß ‡∏ó‡πà‡∏≤‡∏ô‡πÄ‡∏≠‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏£...\n","328    neg  ‡πÉ‡∏ô ‡∏Ñ‡∏£‡∏° ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÉ‡∏Ñ‡∏£‡∏â‡∏•‡∏≤‡∏î‡∏ö‡πâ‡∏≤‡∏á‡∏ß‡∏∞ ‡∏ï‡∏≠‡∏ô‡∏£‡∏ß‡∏° ‡∏Ñ‡∏£‡∏° ‡∏ú‡πà‡∏≤‡∏ï‡∏±‡∏î‡πÄ‡∏≠‡∏≤...\n","318    neg  ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡∏â‡∏µ‡∏î‡∏ß‡∏±‡∏Ñ‡∏ã‡∏µ‡∏ô‡πÑ‡∏£‡πâ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö1 ‡∏Ç‡∏≠...\n","435    neg  ‡∏£‡∏°‡∏ï ‡∏ô‡∏µ‡πâ‡∏û‡∏π‡∏î‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏•‡∏¢ ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ß..."]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"C3IGJROI9A5x","executionInfo":{"status":"ok","timestamp":1628694884152,"user_tz":-420,"elapsed":59,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"9fd773bb-7864-4aa9-a811-fbed2a725264"},"source":["sentiment_df = pd.concat([neg_df, pos_df])\n","sentiment_df.head()"],"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>labels</th>\n","      <th>comments</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>475</th>\n","      <td>neg</td>\n","      <td>‡∏ô‡∏µ‡πà‡πÄ‡∏≠‡∏≤‡∏£‡∏±‡∏ê‡∏°‡∏ô‡∏ï‡∏£‡∏µ‡∏°‡∏≤‡∏Ñ‡∏∏‡∏¢‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏´‡∏£‡∏≠‡∏Ñ‡∏£‡∏±‡∏ö ‡πÉ‡∏´‡πâ‡πÄ‡∏î‡∏¥‡∏ô‡πÑ‡∏õ‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏∞...</td>\n","    </tr>\n","    <tr>\n","      <th>471</th>\n","      <td>neg</td>\n","      <td>‡∏ü‡∏±‡∏á‡∏ó‡πà‡∏≤‡∏ô ‡∏£‡∏°‡∏ï. ‡πÅ‡∏•‡πâ‡∏ß ‡∏ó‡πà‡∏≤‡∏ô‡πÄ‡∏≠‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏£...</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>neg</td>\n","      <td>‡πÉ‡∏ô ‡∏Ñ‡∏£‡∏° ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÉ‡∏Ñ‡∏£‡∏â‡∏•‡∏≤‡∏î‡∏ö‡πâ‡∏≤‡∏á‡∏ß‡∏∞ ‡∏ï‡∏≠‡∏ô‡∏£‡∏ß‡∏° ‡∏Ñ‡∏£‡∏° ‡∏ú‡πà‡∏≤‡∏ï‡∏±‡∏î‡πÄ‡∏≠‡∏≤...</td>\n","    </tr>\n","    <tr>\n","      <th>318</th>\n","      <td>neg</td>\n","      <td>‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡∏â‡∏µ‡∏î‡∏ß‡∏±‡∏Ñ‡∏ã‡∏µ‡∏ô‡πÑ‡∏£‡πâ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö1 ‡∏Ç‡∏≠...</td>\n","    </tr>\n","    <tr>\n","      <th>435</th>\n","      <td>neg</td>\n","      <td>‡∏£‡∏°‡∏ï ‡∏ô‡∏µ‡πâ‡∏û‡∏π‡∏î‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏•‡∏¢ ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ß...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    labels                                           comments\n","475    neg  ‡∏ô‡∏µ‡πà‡πÄ‡∏≠‡∏≤‡∏£‡∏±‡∏ê‡∏°‡∏ô‡∏ï‡∏£‡∏µ‡∏°‡∏≤‡∏Ñ‡∏∏‡∏¢‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏´‡∏£‡∏≠‡∏Ñ‡∏£‡∏±‡∏ö ‡πÉ‡∏´‡πâ‡πÄ‡∏î‡∏¥‡∏ô‡πÑ‡∏õ‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏∞...\n","471    neg  ‡∏ü‡∏±‡∏á‡∏ó‡πà‡∏≤‡∏ô ‡∏£‡∏°‡∏ï. ‡πÅ‡∏•‡πâ‡∏ß ‡∏ó‡πà‡∏≤‡∏ô‡πÄ‡∏≠‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏£...\n","328    neg  ‡πÉ‡∏ô ‡∏Ñ‡∏£‡∏° ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÉ‡∏Ñ‡∏£‡∏â‡∏•‡∏≤‡∏î‡∏ö‡πâ‡∏≤‡∏á‡∏ß‡∏∞ ‡∏ï‡∏≠‡∏ô‡∏£‡∏ß‡∏° ‡∏Ñ‡∏£‡∏° ‡∏ú‡πà‡∏≤‡∏ï‡∏±‡∏î‡πÄ‡∏≠‡∏≤...\n","318    neg  ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡∏â‡∏µ‡∏î‡∏ß‡∏±‡∏Ñ‡∏ã‡∏µ‡∏ô‡πÑ‡∏£‡πâ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö1 ‡∏Ç‡∏≠...\n","435    neg  ‡∏£‡∏°‡∏ï ‡∏ô‡∏µ‡πâ‡∏û‡∏π‡∏î‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏•‡∏¢ ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏ß..."]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7c5Ae0839Czh","executionInfo":{"status":"ok","timestamp":1628694884153,"user_tz":-420,"elapsed":59,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"0c0ecf2d-44ea-45ad-db8e-b3877e7f0104"},"source":["comments = sentiment_df.comments.values\n","comments.shape"],"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(500,)"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"m0NHcH9t9Cwy","executionInfo":{"status":"ok","timestamp":1628694884153,"user_tz":-420,"elapsed":55,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"9675e7cb-cc94-4544-a735-653c71c37f87"},"source":["comments[0]"],"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'‡∏ô‡∏µ‡πà‡πÄ‡∏≠‡∏≤‡∏£‡∏±‡∏ê‡∏°‡∏ô‡∏ï‡∏£‡∏µ‡∏°‡∏≤‡∏Ñ‡∏∏‡∏¢‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏´‡∏£‡∏≠‡∏Ñ‡∏£‡∏±‡∏ö ‡πÉ‡∏´‡πâ‡πÄ‡∏î‡∏¥‡∏ô‡πÑ‡∏õ‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏∞‡∏õ‡πâ‡∏≤‡∏Ç‡∏≤‡∏¢‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ï‡∏≤‡∏°‡∏™‡∏±‡πà‡∏á‡∏¢‡∏±‡∏á‡∏£‡∏∏‡πâ‡∏™‡∏∂‡∏Å‡∏ß‡πà‡∏≤‡∏ï‡∏≠‡∏ö‡∏°‡∏µ‡∏™‡∏≤‡∏£‡∏∞ ‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏•‡∏¢ ‡∏ô‡∏µ‡πà‡∏ü‡∏±‡∏á‡∏ï‡∏£‡∏£‡∏Å‡∏∞‡∏û‡∏±‡∏á‡∏û‡∏¥‡∏ô‡∏≤‡∏®‡∏°‡∏≤‡∏Å‡πÄ‡∏•‡∏¢‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏î‡∏π‡∏Ç‡πà‡∏≤‡∏ß'"]},"metadata":{"tags":[]},"execution_count":85}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQG0ZLsA9Q2q","executionInfo":{"status":"ok","timestamp":1628694884155,"user_tz":-420,"elapsed":56,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"e63b9a1e-6c6a-4a1c-e9de-1b984ce4c74f"},"source":["labels = sentiment_df.labels.values\n","labels.shape"],"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(500,)"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"markdown","metadata":{"id":"v2Ky1vMF5Wwp"},"source":["\n","\n","> ‡∏™‡∏£‡πâ‡∏≤‡∏áFunction‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏áTrain Data\n","\n"]},{"cell_type":"code","metadata":{"id":"h0_lsWqL9QvC","executionInfo":{"status":"ok","timestamp":1628694884156,"user_tz":-420,"elapsed":55,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["def cleaning(sentences):\n","  words = []\n","  temp = []\n","  for s in sentences:\n","    clean = re.sub(r'[^‡∏Å-‡πô]', \"\", s)\n","    w = word_tokenize(clean)\n","    temp.append([i.lower() for i in w])\n","    words.append(' '.join(w).lower())\n","    \n","  return words, temp"],"execution_count":87,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JcxfSqdD9QlJ","executionInfo":{"status":"ok","timestamp":1628694884156,"user_tz":-420,"elapsed":54,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"c1232187-7270-471e-a96e-e3b5ff357f12"},"source":["cleaned_words, temp = cleaning(comments)\n","print(len(cleaned_words))\n","print(cleaned_words[:5])"],"execution_count":88,"outputs":[{"output_type":"stream","text":["500\n","['‡∏ô‡∏µ‡πà ‡πÄ‡∏≠‡∏≤ ‡∏£‡∏±‡∏ê‡∏°‡∏ô‡∏ï‡∏£‡∏µ ‡∏°‡∏≤ ‡∏Ñ‡∏∏‡∏¢ ‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏´‡∏£‡∏≠ ‡∏Ñ‡∏£‡∏±‡∏ö ‡πÉ‡∏´‡πâ ‡πÄ‡∏î‡∏¥‡∏ô ‡πÑ‡∏õ ‡∏Ñ‡∏∏‡∏¢ ‡∏Å‡∏∞ ‡∏õ‡πâ‡∏≤ ‡∏Ç‡∏≤‡∏¢ ‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‡∏ï‡∏≤‡∏° ‡∏™‡∏±‡πà‡∏á ‡∏¢‡∏±‡∏á ‡∏£‡∏∏‡πâ ‡∏™‡∏∂‡∏Å ‡∏ß‡πà‡∏≤ ‡∏ï‡∏≠‡∏ö ‡∏°‡∏µ ‡∏™‡∏≤‡∏£‡∏∞ ‡πÅ‡∏•‡∏∞ ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏• ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ ‡∏ô‡∏µ‡πâ ‡πÄ‡∏•‡∏¢ ‡∏ô‡∏µ‡πà ‡∏ü‡∏±‡∏á ‡∏ï‡∏£‡∏£‡∏Å‡∏∞ ‡∏û‡∏±‡∏á‡∏û‡∏¥‡∏ô‡∏≤‡∏® ‡∏°‡∏≤‡∏Å ‡πÄ‡∏•‡∏¢ ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô ‡πÑ‡∏°‡πà ‡πÄ‡∏Ñ‡∏¢ ‡∏î‡∏π ‡∏Ç‡πà‡∏≤‡∏ß', '‡∏ü‡∏±‡∏á ‡∏ó‡πà‡∏≤ ‡∏ô‡∏£ ‡∏°‡∏ï ‡πÅ‡∏•‡πâ‡∏ß ‡∏ó‡πà‡∏≤‡∏ô ‡πÄ‡∏≠‡∏≤ ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® ‡πÑ‡∏ó‡∏¢ ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö ‡∏Å‡∏≤‡∏£ ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö ‡∏ß‡∏±‡∏Ñ‡∏ã‡∏µ‡∏ô ‡∏Å‡∏±‡∏ö ‡∏≠‡∏≤‡πÄ‡∏ã‡∏µ‡∏¢‡∏ô ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö ‡∏≠‡∏±‡∏ï‡∏£‡∏≤ ‡∏Å‡∏≤‡∏£ ‡πÄ‡∏™‡∏µ‡∏¢‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï ‡∏Å‡∏±‡∏ö ‡∏ó‡∏±‡πà‡∏ß‡πÇ‡∏•‡∏Å ‡∏û‡∏π‡∏î ‡∏ï‡∏≤‡∏°‡∏ï‡∏£‡∏á ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î ‡∏ó‡πà‡∏≤‡∏ô ‡∏°‡∏±‡∏ô ‡∏´‡πà‡∏ß‡∏¢‡πÅ‡∏ï‡∏Å ‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏ô‡∏±‡πà‡∏á ‡∏ü‡∏±‡∏á ‡∏ó‡πà‡∏≤‡∏ô ‡∏°‡∏≤ ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô ‡∏ó‡πà‡∏≤‡∏ô ‡πÅ‡∏ñ', '‡πÉ‡∏ô ‡∏Ñ‡∏£‡∏° ‡∏ô‡∏µ‡πâ ‡∏°‡∏µ ‡πÉ‡∏Ñ‡∏£ ‡∏â‡∏•‡∏≤‡∏î ‡∏ö‡πâ‡∏≤‡∏á ‡∏ß‡∏∞ ‡∏ï‡∏≠‡∏ô ‡∏£‡∏ß‡∏° ‡∏Ñ‡∏£‡∏° ‡∏ú‡πà‡∏≤‡∏ï‡∏±‡∏î ‡πÄ‡∏≠‡∏≤ ‡∏™‡∏°‡∏≠‡∏á ‡∏≠‡∏≠‡∏Å ‡∏Å‡πà‡∏≠‡∏ô ‡∏´‡∏£‡∏≠ ‡∏ñ‡∏∂‡∏á ‡∏à‡∏∞ ‡πÄ‡∏õ‡πá‡∏ô ‡∏£‡∏ê‡∏ö ‡πÑ‡∏î‡πâ', '‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® ‡πÑ‡∏ó‡∏¢ ‡∏â‡∏µ‡∏î‡∏ß‡∏±‡∏Ñ‡∏ã‡∏µ‡∏ô ‡πÑ‡∏£‡πâ ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û ‡πÄ‡∏õ‡πá‡∏ô ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö ‡∏Ç‡∏≠‡∏á ‡∏≠‡∏≤‡πÄ‡∏ã‡∏µ‡∏¢‡∏ô ‡∏†‡∏π‡∏°‡∏¥‡πÉ‡∏à ‡∏°‡∏≤‡∏Å ‡∏Ñ‡πà‡∏≤', '‡∏£‡∏° ‡∏ï ‡∏ô‡∏µ‡πâ ‡∏û‡∏π‡∏î ‡πÑ‡∏°‡πà ‡∏°‡∏µ ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å ‡πÄ‡∏•‡∏¢ ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å ‡∏ß‡πà‡∏≤ ‡πÑ‡∏°‡πà ‡∏à‡∏£‡∏¥‡∏á ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏à ‡∏ï‡πà‡∏≠ ‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô ‡∏ï‡∏≠‡∏ö ‡πÅ‡∏•‡∏∞ ‡πÅ‡∏ñ ‡πÑ‡∏õ ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ ‡πÑ‡∏°‡πà ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞ ‡πÑ‡∏°‡πà ‡∏°‡∏µ ‡∏®‡∏±‡∏ó‡∏ò‡∏≤ ‡πÄ‡∏•‡∏¢']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OzABPZqE9u84","executionInfo":{"status":"ok","timestamp":1628694884158,"user_tz":-420,"elapsed":53,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["def create_tokenizer(words, filters = ''):\n","    token = Tokenizer(filters=filters)\n","    token.fit_on_texts(words)\n","    return token"],"execution_count":89,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6c9c6r8q9u2Y","executionInfo":{"status":"ok","timestamp":1628694884162,"user_tz":-420,"elapsed":57,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"d423d3fa-4434-4279-8e7f-fb025fd58918"},"source":["train_word_tokenizer = create_tokenizer(cleaned_words)\n","vocab_size = len(train_word_tokenizer.word_index) + 1\n","\n","train_word_tokenizer.word_index"],"execution_count":90,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'‡πÑ‡∏°‡πà': 1,\n"," '‡∏Ñ‡∏∏‡∏ì': 2,\n"," '‡∏ó‡∏µ‡πà': 3,\n"," '‡∏°‡∏≤‡∏Å': 4,\n"," '‡πÑ‡∏î‡πâ': 5,\n"," '‡∏Ñ‡∏£‡∏±‡∏ö': 6,\n"," '‡∏°‡∏µ': 7,\n"," '‡πÄ‡∏•‡∏¢': 8,\n"," '‡πÅ‡∏•‡πâ‡∏ß': 9,\n"," '‡∏°‡∏≤': 10,\n"," '‡∏à‡∏≠‡∏°‡∏Ç‡∏ß‡∏±‡∏ç': 11,\n"," '‡πÄ‡∏õ‡πá‡∏ô': 12,\n"," '‡πÑ‡∏õ': 13,\n"," '‡∏Ñ‡∏ô': 14,\n"," '‡∏Ñ‡πà‡∏∞': 15,\n"," '‡∏ó‡∏¥‡∏°': 16,\n"," '‡πÉ‡∏´‡πâ': 17,\n"," '‡πÅ‡∏ï‡πà': 18,\n"," '‡∏û‡∏π‡∏î': 19,\n"," '‡πÅ‡∏•‡∏∞': 20,\n"," '‡∏ü‡∏±‡∏á': 21,\n"," '‡∏ß‡πà‡∏≤': 22,\n"," '‡πÜ': 23,\n"," '‡∏Å‡πá': 24,\n"," '‡∏ô‡∏µ‡πâ': 25,\n"," '‡∏£‡∏±‡∏ê‡∏ö‡∏≤‡∏•': 26,\n"," '‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô': 27,\n"," '‡∏°‡∏±‡∏ô': 28,\n"," '‡∏à‡∏∞': 29,\n"," '‡∏Å‡∏±‡∏ö': 30,\n"," '‡∏Ç‡∏≠‡∏á': 31,\n"," '‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®': 32,\n"," '‡∏û‡∏¥‡∏ò‡∏≤': 33,\n"," '‡∏£‡∏±‡∏ê‡∏°‡∏ô‡∏ï‡∏£‡∏µ': 34,\n"," '‡∏ó‡πà‡∏≤‡∏ô': 35,\n"," '‡∏Ñ‡∏∑‡∏≠': 36,\n"," '‡∏£‡∏°': 37,\n"," '‡∏à‡∏£‡∏¥‡∏á‡πÜ': 38,\n"," '‡πÉ‡∏ô': 39,\n"," '‡∏ï': 40,\n"," '‡πÅ‡∏ñ': 41,\n"," '‡∏ô‡∏∞': 42,\n"," '‡πÄ‡∏£‡∏≤': 43,\n"," '‡∏î‡∏µ': 44,\n"," '‡πÄ‡∏Å‡πà‡∏á': 45,\n"," '‡πÄ‡∏Ç‡∏≤': 46,\n"," '‡∏£‡∏π‡πâ': 47,\n"," '‡∏ä‡∏≠‡∏ö': 48,\n"," '‡∏Ñ‡∏∏‡∏ì‡∏´‡∏ç‡∏¥‡∏á': 49,\n"," '‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á': 50,\n"," '‡∏î‡∏π': 51,\n"," '‡∏Å‡∏±‡∏ô': 52,\n"," '‡∏≠‡∏∞‡πÑ‡∏£': 53,\n"," '‡πÅ‡∏ö‡∏ö': 54,\n"," '‡∏ô‡∏µ‡πà': 55,\n"," '‡∏Å‡∏≤‡∏£': 56,\n"," '‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ': 57,\n"," '‡∏ô‡∏∞‡∏Ñ‡∏∞': 58,\n"," '‡∏ó‡∏≥': 59,\n"," '‡∏ï‡πâ‡∏≠‡∏á': 60,\n"," '‡πÇ‡∏á‡πà': 61,\n"," '‡∏ô‡∏≤‡∏¢‡∏Å': 62,\n"," '‡∏ï‡∏≠‡∏ö': 63,\n"," '‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô': 64,\n"," '‡∏â‡∏•‡∏≤‡∏î': 65,\n"," '‡∏ó‡∏±‡πâ‡∏á': 66,\n"," '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•': 67,\n"," '‡πÄ‡∏≠‡∏≤': 68,\n"," '‡∏à‡∏£‡∏¥‡∏á': 69,\n"," '‡∏¢‡∏±‡∏á': 70,\n"," '‡πÑ‡∏ó‡∏¢': 71,\n"," '‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å': 72,\n"," '‡πÄ‡∏û‡∏£‡∏≤‡∏∞': 73,\n"," '‡∏≠‡∏¢‡πà‡∏≤‡∏á': 74,\n"," '‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì': 75,\n"," '‡πÄ‡∏´‡πá‡∏ô': 76,\n"," '‡∏Ñ‡∏¥‡∏î': 77,\n"," '‡∏£‡∏±‡∏ê': 78,\n"," '‡∏≠‡∏¢‡∏≤‡∏Å': 79,\n"," '‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î': 80,\n"," '‡∏Å‡∏Å': 81,\n"," '‡∏û‡∏¥‡∏°': 82,\n"," '‡∏≠‡∏¢‡∏π‡πà': 83,\n"," '‡πÉ‡∏Ñ‡∏£': 84,\n"," '‡πÉ‡∏ä‡πà': 85,\n"," '‡∏ó‡∏≥‡πÑ‡∏°': 86,\n"," '‡∏ú‡∏°': 87,\n"," '‡∏≠‡∏µ‡∏Å': 88,\n"," '‡∏û‡∏¥': 89,\n"," '‡∏î‡πâ‡∏ß‡∏¢': 90,\n"," '‡∏ó‡∏≥‡∏á‡∏≤‡∏ô': 91,\n"," '‡∏ß‡∏±‡∏Ñ‡∏ã‡∏µ‡∏ô': 92,\n"," '‡∏û‡∏µ‡πà': 93,\n"," '‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£': 94,\n"," '‡∏à‡∏±‡∏á': 95,\n"," '‡πÄ‡∏Ñ‡∏¢': 96,\n"," '‡∏ñ‡∏∂‡∏á': 97,\n"," '‡∏ñ‡∏≤‡∏°': 98,\n"," '‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°': 99,\n"," '‡∏Å‡∏ß‡πà‡∏≤': 100,\n"," '‡∏´‡∏ô‡πà‡∏≠‡∏¢': 101,\n"," '‡∏ô‡πâ‡∏≠‡∏á': 102,\n"," '‡∏£‡∏±‡∏Å': 103,\n"," '‡πÄ‡∏´‡∏£‡∏≠': 104,\n"," '‡∏ñ‡πâ‡∏≤': 105,\n"," '‡πÅ‡∏Ñ‡πà': 106,\n"," '‡∏û‡∏ß‡∏Å': 107,\n"," '‡∏ú‡∏π‡πâ‡∏ô‡∏≥': 108,\n"," '‡∏Ñ‡∏ß‡∏≤‡∏°': 109,\n"," '‡∏û‡∏≠': 110,\n"," '‡∏°‡∏ï': 111,\n"," '‡πÄ‡∏ü‡∏Ñ': 112,\n"," '‡∏Ñ‡∏∞': 113,\n"," '‡πÄ‡∏û‡∏∑‡πà‡∏≠': 114,\n"," '‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à': 115,\n"," '‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏à': 116,\n"," '‡∏Ñ‡∏∏‡∏¢': 117,\n"," '‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á': 118,\n"," '‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£': 119,\n"," '‡∏î‡∏¥‡∏à‡∏¥‡∏ï‡∏≠‡∏•': 120,\n"," '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ': 121,\n"," '‡∏î‡∏µ‡∏°‡∏≤‡∏Å': 122,\n"," '‡∏ö‡πâ‡∏≤‡∏á': 123,\n"," '‡∏™‡∏°‡∏≠‡∏á': 124,\n"," '‡∏≠‡∏≠‡∏Å': 125,\n"," '‡∏≠‡∏∑‡πà‡∏ô': 126,\n"," '‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢': 127,\n"," '‡∏ï‡∏•‡∏≠‡∏î': 128,\n"," '‡πÇ‡∏Ñ‡∏ï‡∏£': 129,\n"," '‡πÄ‡∏¢‡∏≠‡∏∞': 130,\n"," '‡πÄ‡∏Ñ‡πâ‡∏≤': 131,\n"," '‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î': 132,\n"," '‡πÅ‡∏ó‡∏ô': 133,\n"," '‡∏°‡∏≠‡∏á': 134,\n"," '‡∏Å‡πà‡∏≠‡∏ô': 135,\n"," '‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å': 136,\n"," '‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ': 137,\n"," '‡πÇ‡∏î‡∏ô': 138,\n"," '‡∏™‡∏∏‡∏î': 139,\n"," '‡∏´‡∏≤': 140,\n"," '‡∏õ‡∏ä‡∏ä': 141,\n"," '‡πÅ‡∏Ñ‡πà‡∏ô‡∏µ‡πâ': 142,\n"," '‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ': 143,\n"," '‡πÅ‡∏°‡πà': 144,\n"," '‡∏ó‡∏≥‡πÉ‡∏´‡πâ': 145,\n"," '‡∏Ñ‡∏á': 146,\n"," '‡∏Ç‡∏≠': 147,\n"," '‡∏ï‡∏≤‡∏°': 148,\n"," '‡∏ô‡∏£': 149,\n"," '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î': 150,\n"," '‡∏ß‡∏∞': 151,\n"," '‡∏ô‡∏¥‡∏ß‡∏™‡πå': 152,\n"," '‡∏ú‡∏¥‡∏î': 153,\n"," '‡πÄ‡∏ñ‡∏≠‡∏∞': 154,\n"," '‡∏Å‡∏π': 155,\n"," '‡∏≠‡∏≠': 156,\n"," '‡πÇ‡∏ô': 157,\n"," '‡πÅ‡∏ß‡∏Ñ': 158,\n"," '‡πÑ‡∏´‡∏ô': 159,\n"," '‡πÅ‡∏ô‡πà‡∏ô': 160,\n"," '‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û': 161,\n"," '‡∏Ç‡∏ô‡∏≤‡∏î': 162,\n"," '‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ': 163,\n"," '‡∏™‡∏∏‡∏î‡∏≤': 164,\n"," '‡πÑ‡∏î‡πâ‡∏î‡∏µ': 165,\n"," '‡∏Ñ‡∏ô‡∏£‡∏∏‡πà‡∏ô‡πÉ‡∏´‡∏°‡πà': 166,\n"," '‡∏ä‡∏∑‡πà‡∏ô‡∏ä‡∏°': 167,\n"," '‡∏™‡∏π‡πâ': 168,\n"," '‡∏ó‡πà‡∏≤': 169,\n"," '‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö': 170,\n"," '‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢': 171,\n"," '‡∏Ñ‡∏ß‡∏£': 172,\n"," '‡∏°‡∏∂‡∏á': 173,\n"," '‡∏ß‡∏¥‡∏™‡∏±‡∏¢‡∏ó‡∏±‡∏®‡∏ô‡πå': 174,\n"," '‡∏î‡∏≤‡∏£‡∏≤': 175,\n"," '‡∏´‡∏ô‡πâ‡∏≤': 176,\n"," '‡∏ä‡∏±‡∏î': 177,\n"," '‡πÄ‡∏´‡∏•‡∏∑‡∏≠': 178,\n"," '‡∏ä‡πà‡∏≠‡∏á': 179,\n"," '‡∏ï‡∏≤‡∏¢': 180,\n"," '‡πÑ‡∏≠‡πâ': 181,\n"," '‡∏ó‡∏≥‡πÑ‡∏î‡πâ': 182,\n"," '‡∏ä‡∏∏‡∏î': 183,\n"," '‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤': 184,\n"," '‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤': 185,\n"," '‡πÄ‡∏ß‡∏•‡∏≤': 186,\n"," '‡∏à‡∏≤‡∏Å': 187,\n"," '‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ß‡∏±‡∏á': 188,\n"," '‡πÉ‡∏´‡∏°‡πà': 189,\n"," '‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï': 190,\n"," '‡∏£‡∏≠': 191,\n"," '‡∏ñ‡∏π‡∏Å': 192,\n"," '‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö': 193,\n"," '‡∏ó‡∏∏‡∏Å': 194,\n"," '‡∏£‡∏±‡∏ï‡∏ô‡πå': 195,\n"," '‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤': 196,\n"," '‡∏´‡∏£‡∏≠': 197,\n"," '‡πÄ‡∏ô‡∏µ‡πà‡∏¢': 198,\n"," '‡∏°‡∏±‡πâ‡∏¢': 199,\n"," '‡∏≠‡∏∂‡∏î‡∏≠‡∏±‡∏î': 200,\n"," '‡∏¢‡∏±‡∏á‡πÑ‡∏á': 201,\n"," '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ': 202,\n"," '‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç': 203,\n"," '‡πÇ‡∏Å‡∏´‡∏Å': 204,\n"," '‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡πá': 205,\n"," '‡∏ô‡πà‡∏≤‡∏à‡∏∞': 206,\n"," '‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå': 207,\n"," '‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô': 208,\n"," '‡∏≠‡∏¢‡πà‡∏≤': 209,\n"," '‡∏ï‡πà‡∏≠‡πÑ‡∏õ': 210,\n"," '‡∏à‡∏ö': 211,\n"," '‡∏ö‡∏≠‡∏Å': 212,\n"," '‡∏•‡∏≤‡∏≠‡∏≠‡∏Å': 213,\n"," '‡∏≠‡πâ‡∏≤‡∏á': 214,\n"," '‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°': 215,\n"," '‡πÉ‡∏ä‡πâ': 216,\n"," '‡πÑ‡∏á': 217,\n"," '‡∏¢‡∏¥‡πà‡∏á': 218,\n"," '‡∏ö‡πâ‡∏≤‡∏ô': 219,\n"," '‡∏ó‡∏µ': 220,\n"," '‡∏ô‡πà‡∏≤': 221,\n"," '‡∏ó‡∏µ‡∏°‡∏á‡∏≤‡∏ô': 222,\n"," '‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ': 223,\n"," '‡∏ß‡∏±‡∏ô': 224,\n"," '‡πÜ‡πÜ': 225,\n"," '‡∏Ç‡∏∂‡πâ‡∏ô': 226,\n"," '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô': 227,\n"," '‡∏Ñ‡∏ô‡πÑ‡∏ó‡∏¢': 228,\n"," '‡∏ü‡πâ‡∏≠‡∏á': 229,\n"," '‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢': 230,\n"," '‡πÇ‡∏ó‡∏©': 231,\n"," '‡∏Ñ‡∏ô‡∏≠‡∏∑‡πà‡∏ô': 232,\n"," '‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°': 233,\n"," '‡∏ï‡∏£‡∏á': 234,\n"," '‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô': 235,\n"," '‡∏ú‡πà‡∏≤‡∏ô': 236,\n"," '‡πÄ‡∏Æ‡∏á‡∏ã‡∏ß‡∏¢': 237,\n"," '‡∏£‡∏∞‡∏î‡∏±‡∏ö': 238,\n"," '‡∏´‡∏£‡∏≠‡∏Å': 239,\n"," '‡πÄ‡∏à‡∏≠': 240,\n"," '‡∏´‡πà‡∏ß‡∏¢': 241,\n"," '‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà': 242,\n"," '‡∏´‡∏•‡∏≤‡∏¢': 243,\n"," '‡∏†‡∏≤‡∏©‡∏µ': 244,\n"," '‡∏™‡∏∑‡πà‡∏≠': 245,\n"," '‡∏ã‡∏¥': 246,\n"," '‡πÜ‡πÜ‡πÜ‡πÜ': 247,\n"," '‡∏Ñ‡∏≥‡∏û‡∏π‡∏î': 248,\n"," '‡∏Ç‡∏≥': 249,\n"," '‡∏à‡∏ô': 250,\n"," '‡∏Å‡∏£‡∏∞‡∏ó‡∏£‡∏ß‡∏á': 251,\n"," '‡∏á': 252,\n"," '‡πÄ‡∏≠‡∏á': 253,\n"," '‡∏°‡∏µ‡∏≠‡∏≥‡∏ô‡∏≤‡∏à': 254,\n"," '‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö': 255,\n"," '‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏≤‡∏¢': 256,\n"," '‡∏ö‡∏≠': 257,\n"," '‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö': 258,\n"," '‡∏£‡∏±‡∏ö': 259,\n"," '‡∏ã‡∏∑‡πâ‡∏≠': 260,\n"," '‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô': 261,\n"," '‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå': 262,\n"," '‡πÑ‡∏£': 263,\n"," '‡∏ó‡∏≥‡∏ú‡∏¥‡∏î': 264,\n"," '‡∏≠‡∏∞': 265,\n"," '‡∏à‡∏∏‡∏î': 266,\n"," '‡πÅ‡∏ô‡πà‡πÜ': 267,\n"," '‡∏≠‡∏≠‡∏Å‡∏°‡∏≤': 268,\n"," '‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£': 269,\n"," '‡πÄ‡∏•‡∏∑‡∏≠‡∏Å': 270,\n"," '‡∏•‡∏π‡∏Å‡∏™‡∏≤‡∏ß': 271,\n"," '‡∏Ç‡∏≤‡∏¢': 272,\n"," '‡∏ï‡∏£‡∏£‡∏Å‡∏∞': 273,\n"," '‡∏≠‡∏≤‡πÄ‡∏ã‡∏µ‡∏¢‡∏ô': 274,\n"," '‡∏ô‡∏±‡πà‡∏á': 275,\n"," '‡∏ï‡∏≠‡∏ô': 276,\n"," '‡∏ï‡πà‡∏≠': 277,\n"," '‡∏Å‡∏•‡πâ‡∏≤': 278,\n"," '‡πÄ‡∏ô‡∏≠‡∏∞': 279,\n"," '‡∏™‡∏á‡∏™‡∏≤‡∏£': 280,\n"," '‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô': 281,\n"," '‡∏Ñ‡∏ô‡∏ï‡∏≤‡∏¢': 282,\n"," '‡πÄ‡∏î‡πá‡∏Å': 283,\n"," '‡πÉ‡∏à': 284,\n"," '‡∏£‡∏∞‡∏ö‡∏ö': 285,\n"," '‡∏Ñ‡∏ì‡∏∞': 286,\n"," '‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á': 287,\n"," '‡∏ß‡∏ô': 288,\n"," '‡πÄ‡∏ó‡∏õ': 289,\n"," '‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà': 290,\n"," '‡∏¢‡∏≠‡∏î': 291,\n"," '‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô': 292,\n"," '‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö': 293,\n"," '‡πÇ‡∏≠‡πâ‡∏¢': 294,\n"," '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á': 295,\n"," '‡∏ß‡∏¥‡∏ò‡∏µ': 296,\n"," '‡∏ï‡∏•‡∏≤‡∏î': 297,\n"," '‡∏õ‡∏±‡∏ç‡∏ç‡∏≤': 298,\n"," '‡∏´‡∏£‡∏∑‡∏≠': 299,\n"," '‡πÅ‡∏ô‡πà': 300,\n"," '‡∏Å‡∏¥‡∏ô': 301,\n"," '‡∏Å‡∏£': 302,\n"," '‡∏ó‡∏ô': 303,\n"," '‡∏Å‡∏•‡∏±‡∏ß': 304,\n"," '‡∏ô‡∏≤‡∏¢': 305,\n"," '‡πÑ‡∏´‡∏°': 306,\n"," '‡∏õ‡∏µ': 307,\n"," '‡∏´‡∏°‡∏≠': 308,\n"," '‡∏´‡∏ô‡∏π': 309,\n"," '‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏Å‡∏£': 310,\n"," '‡∏≠‡∏ß‡∏¢': 311,\n"," '‡∏ó‡∏±‡πâ‡∏á‡∏ô‡∏±‡πâ‡∏ô': 312,\n"," '‡πÇ‡∏•‡∏Å': 313,\n"," '‡∏ù‡πà‡∏≤‡∏¢‡∏Ñ‡πâ‡∏≤‡∏ô': 314,\n"," '‡∏ô‡πâ‡∏≠‡∏¢': 315,\n"," '‡∏ï‡∏¥‡∏î': 316,\n"," '‡∏ó‡∏≥‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î': 317,\n"," '‡∏´‡∏±‡∏ß': 318,\n"," '‡∏´‡∏°‡∏î': 319,\n"," '‡πÇ‡∏Ñ': 320,\n"," '‡∏ó‡∏≤‡∏á': 321,\n"," '‡∏ô‡∏µ‡πà‡πÅ‡∏´‡∏•‡∏∞': 322,\n"," '‡∏Ç‡∏≠‡πÉ‡∏´‡πâ': 323,\n"," '‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ': 324,\n"," '‡∏™‡∏¥': 325,\n"," '‡πÅ‡∏ñ‡∏°': 326,\n"," '‡∏ô‡∏¥‡∏ß': 327,\n"," '‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤': 328,\n"," '‡∏á‡∏á': 329,\n"," '‡πÅ‡∏Å‡πâ‡∏ï‡∏±‡∏ß': 330,\n"," '‡∏ô‡∏≤‡∏ô': 331,\n"," '‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢': 332,\n"," '‡∏ô‡∏±‡∏ö‡∏ñ‡∏∑‡∏≠': 333,\n"," '‡πÄ‡∏≠‡πá‡∏ô‡∏î‡∏π': 334,\n"," '‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç': 335,\n"," '‡∏ä‡πà‡∏ß‡∏¢‡∏Å‡∏±‡∏ô': 336,\n"," '‡∏®‡∏∂‡∏Å‡∏©‡∏≤': 337,\n"," '‡∏õ‡∏±‡∏á': 338,\n"," '‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢': 339,\n"," '‡∏Å‡∏∞': 340,\n"," '‡∏õ‡πâ‡∏≤': 341,\n"," '‡∏™‡∏±‡πà‡∏á': 342,\n"," '‡∏£‡∏∏‡πâ': 343,\n"," '‡∏Ç‡πà‡∏≤‡∏ß': 344,\n"," '‡∏ó‡∏±‡πà‡∏ß‡πÇ‡∏•‡∏Å': 345,\n"," '‡∏´‡πà‡∏ß‡∏¢‡πÅ‡∏ï‡∏Å': 346,\n"," '‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö': 347,\n"," '‡∏Ñ‡πà‡∏≤': 348,\n"," '‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å': 349,\n"," '‡∏°‡∏±‡∏ô‡∏™‡∏°‡∏≠‡∏á': 350,\n"," '‡∏õ‡∏±‡∏ç‡∏´‡∏≤': 351,\n"," '‡∏™‡∏£‡πâ‡∏≤‡∏á': 352,\n"," '‡∏°‡∏∂‡∏ô': 353,\n"," '‡πÄ‡∏î‡∏µ‡∏¢‡∏ß': 354,\n"," '‡∏Ç‡πâ‡∏≤‡∏á': 355,\n"," '‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á': 356,\n"," '‡∏Ñ‡∏ß‡∏≤‡∏¢': 357,\n"," '‡∏ã‡∏∞': 358,\n"," '‡πÄ‡∏´‡∏°‡∏≤‡∏∞': 359,\n"," '‡∏ú‡∏•‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå': 360,\n"," '‡∏ô‡∏µ‡πâ‡πÅ‡∏´‡∏•‡∏∞': 361,\n"," '‡∏ö‡∏¥‡∏î‡πÄ‡∏ö‡∏∑‡∏≠‡∏ô': 362,\n"," '‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏≤‡∏ô': 363,\n"," '‡∏°‡∏≤‡∏£‡∏¢‡∏≤‡∏ó': 364,\n"," '‡∏™‡∏≤‡∏°': 365,\n"," '‡∏ï‡∏π‡πà': 366,\n"," '‡∏™‡∏π‡∏á': 367,\n"," '‡∏¢‡∏±‡∏á‡∏°‡∏µ': 368,\n"," '‡∏ó‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà': 369,\n"," '‡πÄ‡∏á‡∏¥‡∏ô': 370,\n"," '‡πÅ‡∏•‡πâ': 371,\n"," '‡∏£‡∏ö': 372,\n"," '‡πÄ‡∏ï‡πá‡∏°‡∏ó‡∏µ‡πà': 373,\n"," '‡∏≠‡πà‡∏∞': 374,\n"," '‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô': 375,\n"," '‡∏™‡∏±‡∏ç‡∏ç‡∏≤': 376,\n"," '‡∏ö‡πâ‡∏≤‡∏ö‡∏≠': 377,\n"," '‡∏Ñ‡∏±‡∏ö': 378,\n"," '‡∏•‡∏≤': 379,\n"," '‡∏ô‡∏±‡∏Å‡∏Ç‡πà‡∏≤‡∏ß': 380,\n"," '‡πÄ‡∏™‡∏°‡∏≠': 381,\n"," '‡∏™‡∏•‡∏¥‡πà‡∏°': 382,\n"," '‡πÑ‡∏ü': 383,\n"," '‡∏ã‡∏±‡∏Å': 384,\n"," '‡∏Ñ‡∏ô‡πÉ‡∏ô': 385,\n"," '‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á': 386,\n"," '‡πÄ‡∏´‡∏≠‡∏∞': 387,\n"," '‡πÄ‡∏î‡∏¥‡∏°': 388,\n"," '‡πÄ‡∏ä‡∏µ‡∏¢‡∏£‡πå': 389,\n"," '‡∏´‡∏ç‡πâ‡∏≤': 390,\n"," '‡∏ô‡∏±‡πà‡∏ô': 391,\n"," '‡∏à‡∏±‡∏ö‡∏â‡∏•‡∏≤‡∏Å': 392,\n"," '‡∏ú‡∏π‡πâ‡πÉ‡∏´‡∏ç‡πà': 393,\n"," '‡∏£‡πà‡∏ß‡∏°': 394,\n"," '‡∏ï‡πà‡∏≤‡∏á‡πÜ': 395,\n"," '‡πÄ‡∏õ‡∏¥‡∏î': 396,\n"," '‡πÇ‡∏î‡∏¢': 397,\n"," '‡∏¢‡∏≤‡∏Å': 398,\n"," '‡∏î‡πà‡∏≤': 399,\n"," '‡∏£‡∏µ‡∏ö': 400,\n"," '‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö': 401,\n"," '‡πÑ‡∏î‡πâ‡∏Ç‡∏ô‡∏≤‡∏î': 402,\n"," '‡πÄ‡∏™‡∏µ‡∏¢‡∏á': 403,\n"," '‡πÇ‡∏°‡πÇ‡∏´': 404,\n"," '‡∏ß‡πà‡∏∞': 405,\n"," '‡∏ô‡∏±‡πâ‡∏ô': 406,\n"," '‡∏™‡πà‡∏á': 407,\n"," '‡∏ó‡∏±‡πà‡∏ß‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®': 408,\n"," '‡∏Ñ‡∏£‡∏±‡πâ‡∏á': 409,\n"," '‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å': 410,\n"," '‡πÅ‡∏ï‡∏Å': 411,\n"," '‡∏ä‡∏¥': 412,\n"," '‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Ñ‡∏î‡∏µ': 413,\n"," '‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤': 414,\n"," '‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå': 415,\n"," '‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô': 416,\n"," '‡∏ä‡πà‡∏ß‡∏¢': 417,\n"," '‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£': 418,\n"," '‡∏™‡πà‡∏ß‡∏ô': 419,\n"," '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô': 420,\n"," '‡∏Å‡∏∏': 421,\n"," '‡∏£‡∏π‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á': 422,\n"," '‡∏•‡∏∞': 423,\n"," '‡∏û‡∏¥‡∏ò‡∏µ‡∏Å‡∏£': 424,\n"," '‡πÅ‡∏™‡∏î‡∏á': 425,\n"," '‡∏õ‡πà‡∏≤‡∏ß': 426,\n"," '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å': 427,\n"," '‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô': 428,\n"," '‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå': 429,\n"," '‡∏à‡πâ‡∏≤‡∏á': 430,\n"," '‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ': 431,\n"," '‡πÄ‡∏´‡πá‡∏ô‡∏†‡∏≤‡∏û': 432,\n"," '‡∏Ñ‡∏ô‡πÄ‡∏Å‡πà‡∏á': 433,\n"," '‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£': 434,\n"," '‡∏•‡∏á': 435,\n"," '‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà': 436,\n"," '‡∏Å‡∏£‡∏≤‡∏ö': 437,\n"," '‡∏´‡∏±‡∏ß‡πÉ‡∏à': 438,\n"," '‡∏¢‡∏∏‡∏Ñ': 439,\n"," '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏î‡∏ó‡∏ô': 440,\n"," '‡∏™‡∏™': 441,\n"," '‡∏ï‡∏•‡∏≠‡∏î‡πÑ‡∏õ': 442,\n"," '‡∏ô‡∏≤‡∏ó‡∏µ': 443,\n"," '‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á': 444,\n"," '‡∏à‡∏±‡∏î': 445,\n"," '‡πÅ‡∏ä‡∏£‡πå': 446,\n"," '‡πÄ‡∏£‡∏¥‡πà‡∏î': 447,\n"," '‡∏Å‡πâ‡∏≤‡∏ß‡πÑ‡∏Å‡∏•': 448,\n"," '‡∏´‡∏•‡πà‡∏≠': 449,\n"," '‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ô‡∏≥': 450,\n"," '‡∏û‡∏£‡∏£‡∏Ñ': 451,\n"," '‡∏Å‡∏î': 452,\n"," '‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£': 453,\n"," '‡∏™‡∏∂‡∏Å': 454,\n"," '‡∏™‡∏≤‡∏£‡∏∞': 455,\n"," '‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•': 456,\n"," '‡πÄ‡∏™‡∏µ‡∏¢‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï': 457,\n"," '‡∏Ñ‡∏£‡∏°': 458,\n"," '‡∏â‡∏µ‡∏î‡∏ß‡∏±‡∏Ñ‡∏ã‡∏µ‡∏ô': 459,\n"," '‡πÑ‡∏£‡πâ': 460,\n"," '‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û': 461,\n"," '‡∏†‡∏π‡∏°‡∏¥‡πÉ‡∏à': 462,\n"," '‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å': 463,\n"," '‡∏õ‡πà‡∏∞': 464,\n"," '‡∏ï‡∏≠‡πÅ‡∏´‡∏•': 465,\n"," '‡∏ï‡∏≤': 466,\n"," '‡∏Å': 467,\n"," '‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå': 468,\n"," '‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô': 469,\n"," '‡πÉ‡∏Ñ‡∏£‡∏Å‡πá‡πÑ‡∏î‡πâ': 470,\n"," '‡∏û‡∏ß‡∏Å‡∏û‡πâ‡∏≠‡∏á': 471,\n"," '‡∏•‡πà‡∏∞': 472,\n"," '‡∏™‡∏±‡∏á‡∏Ñ‡∏°': 473,\n"," '‡∏ó‡∏≤‡∏™': 474,\n"," '‡πÅ‡∏≠‡∏ö': 475,\n"," '‡∏ã‡∏∂‡πà‡∏á': 476,\n"," '‡∏ù‡∏±‡πà‡∏á': 477,\n"," '‡πÅ‡∏´‡∏•‡∏∞': 478,\n"," '‡πÄ‡∏≠‡∏≤‡πÅ‡∏ï‡πà': 479,\n"," '‡πÄ‡∏ä‡πâ‡∏≤': 480,\n"," '‡πÄ‡∏¢‡πá‡∏ô': 481,\n"," '‡πÄ‡∏´‡πâ': 482,\n"," '‡∏Å‡∏£‡πà‡∏≤‡∏á': 483,\n"," '‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô': 484,\n"," '‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô': 485,\n"," '‡∏õ‡πà‡∏ß‡∏¢': 486,\n"," '‡∏ï‡∏ö': 487,\n"," '‡πÄ‡∏ä‡∏∑‡πà‡∏≠': 488,\n"," '‡πÅ‡∏¢‡πà': 489,\n"," '‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå': 490,\n"," '‡∏Å‡∏ß‡∏ô': 491,\n"," '‡∏û‡∏π‡∏î‡πÅ‡∏ó‡∏£‡∏Å': 492,\n"," '‡πÑ‡∏°‡πà‡∏Ñ‡πà‡∏≠‡∏¢': 493,\n"," '‡πÄ‡∏≠‡∏∑‡πâ‡∏≠': 494,\n"," '‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ': 495,\n"," '‡∏ï‡∏µ‡∏ô': 496,\n"," '‡∏ñ‡∏µ‡∏ö': 497,\n"," '‡∏Å‡∏£‡∏∏‡∏ì‡∏≤': 498,\n"," '‡∏ô‡∏≤': 499,\n"," '‡∏ö‡πâ‡∏≤': 500,\n"," '‡∏≠‡∏µ': 501,\n"," '‡∏£‡∏≠‡∏î': 502,\n"," '‡∏ó‡∏£‡∏≤‡∏ö': 503,\n"," '‡∏™‡∏á‡∏™‡∏±‡∏¢': 504,\n"," '‡∏â‡∏µ‡∏î': 505,\n"," '‡πÄ‡∏Å‡∏•‡∏µ‡∏¢‡∏î': 506,\n"," '‡∏Ñ‡∏≥': 507,\n"," '‡πÑ‡∏´‡∏ß': 508,\n"," '‡∏Ñ‡∏ô‡πÇ‡∏á‡πà': 509,\n"," '‡∏£‡∏π‡πâ‡∏ï‡∏±‡∏ß': 510,\n"," '‡∏°‡∏µ‡πÅ‡∏ö‡∏ö‡πÅ‡∏ú‡∏ô': 511,\n"," '‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô': 512,\n"," '‡∏ó‡∏≥‡∏ï‡∏≤‡∏°': 513,\n"," '‡πÄ‡∏Å‡∏¥‡∏ô': 514,\n"," '‡∏ä‡∏≤‡∏ï‡∏¥': 515,\n"," '‡∏ô‡∏∞‡∏à‡πä‡∏∞': 516,\n"," '‡∏î‡∏π‡πÅ‡∏•': 517,\n"," '‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå': 518,\n"," '‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•': 519,\n"," '‡∏û‡∏π‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á': 520,\n"," '‡πÇ‡∏ô‡πâ‡∏ô': 521,\n"," '‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô': 522,\n"," '‡πÅ‡∏ó‡∏ö‡∏ï‡∏≤‡∏¢': 523,\n"," '‡∏ï‡∏≠': 524,\n"," '‡πÅ‡∏Ç‡∏Å‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡∏¥‡∏ç': 525,\n"," '‡πÑ‡∏•‡πà': 526,\n"," '‡πÄ‡∏ã‡∏≠‡∏£‡πå': 527,\n"," '‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô': 528,\n"," '‡∏´‡∏≤‡∏¢': 529,\n"," '‡∏≠‡∏≤': 530,\n"," '‡∏ô‡∏±‡∏Å‡∏•‡∏á‡∏ó‡∏∏‡∏ô': 531,\n"," '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à': 532,\n"," '‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå': 533,\n"," '‡∏™‡∏±‡πâ‡∏ô': 534,\n"," '‡∏ï‡∏£‡∏á‡πÜ': 535,\n"," '‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°': 536,\n"," '‡∏ó‡∏µ‡πà‡∏°‡∏≤': 537,\n"," '‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á': 538,\n"," '‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô': 539,\n"," '‡∏ó‡∏±‡πâ‡∏á‡πÇ‡∏•‡∏Å': 540,\n"," '‡∏ü‡πâ‡∏≤': 541,\n"," '‡πÄ‡∏´‡∏ß': 542,\n"," '‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î': 543,\n"," '‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô': 544,\n"," '‡∏Ç‡∏π‡πà': 545,\n"," '‡∏ï‡∏≤‡∏°‡∏°‡∏≤': 546,\n"," '‡∏û‡∏≠‡πÑ‡∏î‡πâ': 547,\n"," '‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡∏±‡∏Å': 548,\n"," '‡∏à‡∏≤': 549,\n"," '‡∏Ç‡πâ‡∏≤‡∏á‡πÜ': 550,\n"," '‡∏ó‡∏±‡∏®‡∏ô‡∏Ñ‡∏ï‡∏¥': 551,\n"," '‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢': 552,\n"," '‡∏¢‡∏¥‡πà‡∏á‡∏Å‡∏ß‡πà‡∏≤': 553,\n"," '‡∏Å‡πâ‡∏≠': 554,\n"," '‡∏™‡∏°‡∏Ñ‡∏ß‡∏£': 555,\n"," '‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß': 556,\n"," '‡∏ô‡πà‡∏≤‡∏ü‡∏±‡∏á': 557,\n"," '‡∏Ç‡πâ‡∏≠‡πÄ‡∏ó‡πá‡∏à‡∏à‡∏£‡∏¥‡∏á': 558,\n"," '‡∏Ñ‡∏π‡πà‡∏Ç‡∏ô‡∏≤‡∏ô': 559,\n"," '‡∏ï‡∏Å': 560,\n"," '‡πÑ‡∏£‡πâ‡∏™‡∏≤‡∏£‡∏∞': 561,\n"," '‡∏ó‡∏±‡πâ‡∏á‡πÜ': 562,\n"," '‡∏Ç‡πâ‡∏≠‡∏≠‡πâ‡∏≤‡∏á': 563,\n"," '‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©': 564,\n"," '‡∏ö‡∏∏‡∏Ñ‡∏•‡∏≤‡∏Å‡∏£': 565,\n"," '‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß': 566,\n"," '‡∏°‡∏µ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•': 567,\n"," '‡∏ï‡∏£‡∏µ': 568,\n"," '‡∏•‡πâ‡∏≤‡∏ô': 569,\n"," '‡∏û‡∏ß‡∏Å‡∏Ñ‡∏∏‡∏ì': 570,\n"," '‡∏™‡∏¥‡πà‡∏á': 571,\n"," '‡∏™‡∏µ‡∏Ç‡πâ‡∏≤‡∏á': 572,\n"," '‡∏û‡∏π‡∏î‡∏à‡∏≤': 573,\n"," '‡∏ß‡∏Å‡∏ß‡∏ô': 574,\n"," '‡πÄ‡∏ö‡∏•‡∏≠': 575,\n"," '‡πÄ‡∏ö‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô': 576,\n"," '‡πÄ‡∏ã‡∏•‡∏•‡πå': 577,\n"," '‡πÄ‡∏•‡∏∞': 578,\n"," '‡∏ó‡∏´‡∏≤‡∏£': 579,\n"," '‡πÄ‡∏£‡πá‡∏ß': 580,\n"," '‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï': 581,\n"," '‡∏Å‡∏µ‡πà': 582,\n"," '‡πÅ‡∏≠‡πá‡∏Ñ': 583,\n"," '‡∏ä‡∏¥‡∏ö‡∏´‡∏≤‡∏¢': 584,\n"," '‡∏ô‡∏∂‡∏á': 585,\n"," '‡∏ö‡∏ô': 586,\n"," '‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢‡πÉ‡∏à': 587,\n"," '‡∏´‡∏á‡∏∏‡∏î‡∏´‡∏á‡∏¥‡∏î': 588,\n"," '‡πÑ‡∏î‡πâ‡∏°‡∏≤': 589,\n"," '‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà': 590,\n"," '‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤': 591,\n"," '‡∏õ': 592,\n"," '‡πÅ‡∏Å‡πâ': 593,\n"," '‡∏ß‡∏à‡∏∞': 594,\n"," '‡∏Å‡πá‡πÑ‡∏î‡πâ': 595,\n"," '‡∏Å‡∏è': 596,\n"," '‡∏´‡∏°‡∏≤‡∏¢': 597,\n"," '‡πÅ‡∏Å': 598,\n"," '‡∏™‡∏≤‡∏¢‡∏ï‡∏≤': 599,\n"," '‡πÇ‡∏ü‡∏Å‡∏±‡∏™': 600,\n"," '‡∏á‡∏≤‡∏ô': 601,\n"," '‡∏Ñ‡∏ô‡∏à‡∏ô': 602,\n"," '‡∏ä‡πâ‡∏≤': 603,\n"," '‡∏¢‡∏µ‡πà‡∏´‡πâ‡∏≠': 604,\n"," '‡πÄ‡πÄ‡∏ö‡∏ö': 605,\n"," '‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á': 606,\n"," '‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô': 607,\n"," '‡∏ô‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á': 608,\n"," '‡∏û‡∏±‡∏í‡∏ô‡∏≤': 609,\n"," '‡∏õ‡∏Å‡∏ï‡∏¥': 610,\n"," '‡∏ï‡πà‡∏≤‡∏á': 611,\n"," '‡∏¢‡∏¢‡∏¢': 612,\n"," '‡πÅ‡∏Ñ‡∏ö': 613,\n"," '‡∏Å‡∏•‡πà‡∏≤‡∏ß‡πÇ‡∏ó‡∏©': 614,\n"," '‡∏°‡∏±‡πà‡∏ß': 615,\n"," '‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î': 616,\n"," '‡∏£‡πâ‡∏≠‡∏á': 617,\n"," '‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢': 618,\n"," '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£': 619,\n"," '‡πÑ‡∏≠': 620,\n"," '‡∏ä‡∏±‡πà‡∏ß': 621,\n"," '‡∏†‡∏≤‡∏û': 622,\n"," '‡∏ä‡∏∑‡πà‡∏≠': 623,\n"," '‡πÉ‡∏´‡∏ç‡πà': 624,\n"," '‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà': 625,\n"," '‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢': 626,\n"," '‡∏ñ‡∏ô‡∏ô': 627,\n"," '‡∏Ç‡∏¢‡∏∞': 628,\n"," '‡∏ô': 629,\n"," '‡∏°‡∏≤‡∏à‡∏≤‡∏Å': 630,\n"," '‡πÄ‡∏ä‡∏¥‡∏ç': 631,\n"," '‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à': 632,\n"," '‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö': 633,\n"," '‡∏û‡∏£‡πâ‡∏≠‡∏°': 634,\n"," '‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤': 635,\n"," '‡∏á‡πà‡∏≤‡∏¢': 636,\n"," '‡∏ä‡∏±‡∏¢': 637,\n"," '‡∏ß‡∏∏‡∏í‡∏¥': 638,\n"," '‡∏Ñ': 639,\n"," '‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢': 640,\n"," '‡∏°': 641,\n"," '‡∏•‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏á': 642,\n"," '‡∏û‡∏±‡∏á': 643,\n"," '‡∏Ñ‡∏£‡∏±‡∏ö‡∏ú‡∏°': 644,\n"," '‡πÇ‡∏Ü‡∏©‡∏Å': 645,\n"," '‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡πÅ‡∏£‡∏Å': 646,\n"," '‡∏ó‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏´‡∏ß': 647,\n"," '‡∏£‡∏ï': 648,\n"," '‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà': 649,\n"," '‡∏£': 650,\n"," '‡∏™‡∏£‡∏∏‡∏õ': 651,\n"," '‡∏î‡πâ‡∏≤‡∏ô': 652,\n"," '‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å': 653,\n"," '‡∏•‡∏π‡∏Å‡∏ô‡πâ‡∏≠‡∏á': 654,\n"," '‡πÜ‡πÜ‡πÜ‡πÜ‡πÜ': 655,\n"," '‡πÄ‡∏Ç‡πâ‡∏≤': 656,\n"," '‡∏à‡∏µ‡∏ô': 657,\n"," '‡πÅ‡∏õ‡∏•‡∏Å‡πÉ‡∏à': 658,\n"," '‡πÄ‡∏Å‡πá‡∏ö': 659,\n"," '‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ': 660,\n"," '‡∏ô‡∏≠': 661,\n"," '‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ': 662,\n"," '‡πÄ‡∏à‡πá‡∏ö': 663,\n"," '‡∏õ‡∏≤‡∏Å': 664,\n"," '‡∏Ñ‡∏ô‡∏î‡∏µ': 665,\n"," '‡∏ô‡∏≠‡∏ô': 666,\n"," '‡∏´‡πà‡∏ß‡∏á': 667,\n"," '‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤': 668,\n"," '‡∏ñ‡∏π‡∏Å‡πÉ‡∏à': 669,\n"," '‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß': 670,\n"," '‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤': 671,\n"," '‡∏ä‡∏°': 672,\n"," '‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£': 673,\n"," '‡∏Ç‡∏¥‡∏á': 674,\n"," '‡∏Å‡∏£‡∏∞‡∏à‡∏≠‡∏Å': 675,\n"," '‡∏Å‡∏≤': 676,\n"," '‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡πâ‡∏á': 677,\n"," '‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°': 678,\n"," '‡∏û‡∏£‡∏£‡∏Ñ‡∏Å‡πâ‡∏≤‡∏ß‡πÑ‡∏Å‡∏•': 679,\n"," '‡∏ú‡∏¥‡∏î‡∏´‡∏ß‡∏±‡∏á': 680,\n"," '‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà': 681,\n"," '‡πí': 682,\n"," '‡∏ú‡∏π‡πâ': 683,\n"," '‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å': 684,\n"," '‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î': 685,\n"," '‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á': 686,\n"," '‡πÄ‡∏Å‡πã‡∏≤': 687,\n"," '‡πÄ‡∏Å‡∏°‡∏™‡πå': 688,\n"," '‡∏™‡∏≠‡∏á': 689,\n"," '‡∏´‡∏•‡∏±‡∏Å‡πÅ‡∏´‡∏•‡∏°': 690,\n"," '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ß‡∏±‡∏á': 691,\n"," '‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ä‡∏≤‡∏ï‡∏¥': 692,\n"," '‡∏®‡∏£‡∏±‡∏ó‡∏ò‡∏≤': 693,\n"," '‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå': 694,\n"," '‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ô': 695,\n"," '‡∏≠‡∏¢‡∏≤‡∏Å‡∏£‡∏π‡πâ': 696,\n"," '‡∏•‡∏∂‡∏Å': 697,\n"," '‡∏Å‡πá‡∏î‡∏µ': 698,\n"," '‡∏ä‡πà‡∏ß‡∏á': 699,\n"," '‡∏£‡∏≠‡∏ö‡∏î‡πâ‡∏≤‡∏ô': 700,\n"," '‡∏™‡∏ß‡∏¢': 701,\n"," '‡∏ó‡∏±‡∏ô': 702,\n"," '‡∏ô‡∏±‡∏Å': 703,\n"," '‡πÄ‡∏ï‡πá‡∏°‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢': 704,\n"," '‡∏£‡πâ‡∏≤': 705,\n"," '‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô': 706,\n"," '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå': 707,\n"," '‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏ô': 708,\n"," '‡∏´‡∏π': 709,\n"," '‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï': 710,\n"," '‡∏°‡∏∏‡∏°': 711,\n"," '‡∏≠‡∏î‡∏ó‡∏ô': 712,\n"," '‡πÄ‡∏ï‡πá‡∏°': 713,\n"," '‡∏û‡πà‡∏≠': 714,\n"," '‡πÑ‡∏Å‡∏•': 715,\n"," '‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°': 716,\n"," '‡∏û‡∏µ‡∏Ñ': 717,\n"," '‡∏ï‡∏£‡∏ß‡∏à': 718,\n"," '‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ö‡πâ‡∏≤‡∏ô': 719,\n"," '‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°': 720,\n"," '‡πÄ‡∏´‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢': 721,\n"," '‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°': 722,\n"," '‡∏ú‡∏π‡πâ‡∏´‡∏ç‡∏¥‡∏á': 723,\n"," '‡∏û‡∏π‡∏î‡∏Ñ‡∏∏‡∏¢': 724,\n"," '‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á': 725,\n"," '‡πÄ‡∏î‡∏¥‡∏ô': 726,\n"," '‡∏≠‡∏≤‡∏´‡∏≤‡∏£': 727,\n"," '‡∏û‡∏±‡∏á‡∏û‡∏¥‡∏ô‡∏≤‡∏®': 728,\n"," '‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö': 729,\n"," '‡∏≠‡∏±‡∏ï‡∏£‡∏≤': 730,\n"," '‡∏ï‡∏≤‡∏°‡∏ï‡∏£‡∏á': 731,\n"," '‡∏£‡∏ß‡∏°': 732,\n"," '‡∏ú‡πà‡∏≤‡∏ï‡∏±‡∏î': 733,\n"," '‡∏£‡∏ê‡∏ö': 734,\n"," '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å': 735,\n"," '‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß': 736,\n"," '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏à': 737,\n"," '‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢': 738,\n"," '‡∏®‡∏±‡∏ó‡∏ò‡∏≤': 739,\n"," '‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö': 740,\n"," '‡∏ó‡πâ‡∏≤‡∏¢': 741,\n"," '‡∏´‡∏π‡∏ó‡∏ß‡∏ô‡∏•‡∏°': 742,\n"," '‡πÅ‡∏Å‡πâ‡πÄ‡∏Å‡πâ‡∏≠': 743,\n"," '‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠': 744,\n"," '‡∏•‡πà‡∏≠‡∏á': 745,\n"," '‡πÅ‡∏•‡πà': 746,\n"," '‡∏´‡∏±‡∏ß‡πÄ‡∏£‡∏≤‡∏∞': 747,\n"," '‡∏Ñ‡∏¥‡∏Å‡∏Ñ‡∏±‡∏Å': 748,\n"," '‡∏≠‡∏≤‡∏à‡∏à‡∏∞': 749,\n"," '‡∏û‡∏¥‡∏ò‡∏µ': 750,\n"," '‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô': 751,\n"," '‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà': 752,\n"," '‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô': 753,\n"," '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏≠‡∏ö‡∏ò‡∏£‡∏£‡∏°': 754,\n"," '‡∏´‡∏ô‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏ß': 755,\n"," '‡∏£‡∏∏‡πà‡∏ô‡πÉ‡∏´‡∏°‡πà': 756,\n"," '‡∏ó‡πâ‡∏≠‡πÅ‡∏ó‡πâ': 757,\n"," '‡∏≠‡∏∏‡∏õ': 758,\n"," '‡∏ñ‡∏±‡∏°‡∏õ‡πå': 759,\n"," '‡∏ä‡∏ô‡∏ä‡∏±‡πâ‡∏ô': 760,\n"," '‡∏Ç‡∏∏‡∏ô‡∏ô‡∏≤‡∏á': 761,\n"," '‡∏≠‡∏≥‡∏°‡∏≤‡∏ï‡∏¢‡πå': 762,\n"," '‡∏ó‡∏≥‡∏•‡∏≤‡∏¢': 763,\n"," '‡∏¢‡∏≤‡∏Å‡∏à‡∏ô': 764,\n"," '‡∏ó‡∏±‡∏ô‡∏Ñ‡∏ô': 765,\n"," '‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡πÜ': 766,\n"," '‡∏ï‡∏∞': 767,\n"," '‡∏ï‡∏µ': 768,\n"," '‡∏î‡πâ‡∏ß‡∏¢‡∏ã‡πâ‡∏≥': 769,\n"," '‡πÑ‡∏î‡πâ‡∏Ñ‡∏¥‡∏î': 770,\n"," '‡∏ï‡∏±‡πâ‡∏á': 771,\n"," '‡πÉ‡∏à‡∏°‡∏≤': 772,\n"," '‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≤‡∏á': 773,\n"," '‡∏ó‡∏£‡∏á': 774,\n"," '‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ': 775,\n"," '‡∏á‡πâ‡∏≤‡∏ß': 776,\n"," '‡πÜ‡πÜ‡πÜ': 777,\n"," '‡πÅ‡∏ï‡πà‡πÅ‡∏£‡∏Å': 778,\n"," '‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÑ‡∏õ': 779,\n"," '‡∏´‡∏•‡πà‡∏∞': 780,\n"," '‡∏´‡∏•‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á': 781,\n"," '‡∏Ø‡∏•‡∏Ø': 782,\n"," '‡∏¢‡∏∑‡∏ô': 783,\n"," '‡∏ã‡πâ‡∏≠‡∏ô': 784,\n"," '‡∏ô‡∏±‡πà‡∏ô‡πÅ‡∏´‡∏•‡∏∞': 785,\n"," '‡∏ï‡∏±‡∏ß‡∏õ‡∏±‡∏ç‡∏´‡∏≤': 786,\n"," '‡∏ö‡∏±‡∏ç‡∏ç‡∏±‡∏ï‡∏¥': 787,\n"," '‡∏Ø': 788,\n"," '‡∏Å‡∏≥‡∏õ‡∏±‡πâ‡∏ô‡∏ó‡∏∏‡∏ö‡∏î‡∏¥‡∏ô': 789,\n"," '‡∏ó‡∏∏‡∏ö': 790,\n"," '‡∏î‡∏¥‡∏ô': 791,\n"," '‡∏à‡∏≠‡∏°': 792,\n"," '‡∏¢‡∏±‡∏ö': 793,\n"," '‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ä‡∏≤‡∏ï‡∏¥': 794,\n"," '‡∏ï‡∏ô‡πÄ‡∏≠‡∏á': 795,\n"," '‡πÇ‡∏õ‡∏£‡∏î‡∏±‡∏Å‡∏ä‡∏±‡πà‡∏ô': 796,\n"," '‡πÄ‡∏°‡∏µ‡∏¢‡∏á': 797,\n"," '‡∏¢‡∏¢': 798,\n"," '‡∏£‡∏°‡∏ß': 799,\n"," '‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏•': 800,\n"," '‡∏ù‡∏∂‡∏Å': 801,\n"," '‡∏ß‡∏¥‡∏ä‡∏≤': 802,\n"," '‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™': 803,\n"," '‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡πà‡∏ß‡∏á': 804,\n"," '‡πÉ‡∏î': 805,\n"," '‡∏≠‡∏∂‡∏ô': 806,\n"," '‡πÜ‡∏á‡∏á‡πÜ': 807,\n"," '‡πà': 808,\n"," '‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß': 809,\n"," '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡πâ‡∏ô': 810,\n"," '‡∏õ‡∏£‡∏∞‡∏ï‡∏π': 811,\n"," '‡∏ß‡∏¥‡πÄ‡∏®‡∏©': 812,\n"," '‡∏ã‡∏π‡∏°': 813,\n"," '‡∏î‡∏∂‡∏á': 814,\n"," '‡πÄ‡∏™‡∏µ‡∏¢‡∏†‡∏≤‡∏©‡∏µ': 815,\n"," '‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á‡∏î‡∏π': 816,\n"," '‡∏≠': 817,\n"," '‡∏•‡∏≠‡∏Ñ': 818,\n"," '‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏•‡∏¢': 819,\n"," '‡πÄ‡∏®‡∏£‡πâ‡∏≤': 820,\n"," '‡πÄ‡∏ô‡∏µ‡∏¢‡∏ô': 821,\n"," '‡πÇ‡∏Å‡πâ': 822,\n"," '‡πÄ‡∏Å‡∏°': 823,\n"," '‡πÇ‡∏Å‡∏á': 824,\n"," '‡πÑ‡∏Ç‡πà': 825,\n"," '‡∏´‡∏±‡∏ß‡∏´‡∏°‡∏≠': 826,\n"," '‡πÄ‡∏≠‡∏≤‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö': 827,\n"," '‡∏Æ‡∏∑‡∏≠': 828,\n"," '‡∏ï‡∏£‡∏≤‡∏ö‡πÉ‡∏î‡∏ó‡∏µ‡πà': 829,\n"," '‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏á': 830,\n"," '‡∏•‡∏á‡∏ó‡∏∏‡∏ô': 831,\n"," '‡πÄ‡∏à‡πä‡∏á': 832,\n"," '‡∏ú‡∏à‡∏ç': 833,\n"," '‡∏ä‡∏∞‡∏ï‡∏≤‡∏Å‡∏£‡∏£‡∏°': 834,\n"," '‡πÄ‡∏ã‡∏ü': 835,\n"," '‡∏°‡∏£‡∏∂‡∏á': 836,\n"," '‡∏ß‡∏≠': 837,\n"," '‡∏™': 838,\n"," '‡∏ú‡∏π‡πâ‡∏Ç‡∏≤‡∏¢': 839,\n"," '‡∏•‡πâ‡∏≥‡∏´‡∏ô‡πâ‡∏≤': 840,\n"," '‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà': 841,\n"," '‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á': 842,\n"," '‡∏á‡∏µ‡πâ': 843,\n"," '‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á': 844,\n"," '‡∏ü‡∏∞': 845,\n"," '‡∏≠‡∏≥‡∏ô‡∏≤‡∏à': 846,\n"," '‡∏°‡∏∑‡∏≠': 847,\n"," '‡∏Æ‡∏±‡∏•': 848,\n"," '‡πÇ‡∏•': 849,\n"," '‡πÅ‡∏ß‡∏Ñ‡∏õ‡∏õ‡∏ä': 850,\n"," '‡∏ô‡πâ‡∏≠': 851,\n"," '‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£': 852,\n"," '‡∏™‡∏±‡∏à': 853,\n"," '‡πÅ‡∏ï‡πà‡∏ß‡πà‡∏≤': 854,\n"," '‡πÄ‡∏â‡πÑ‡∏â': 855,\n"," '‡∏à‡πâ‡∏≠‡∏á': 856,\n"," '‡πÇ‡∏≠‡πä‡∏∞': 857,\n"," '‡∏Ñ‡∏≤‡∏á‡∏Ñ‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡∏ß‡∏≠': 858,\n"," '‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏î‡πâ': 859,\n"," '‡∏≠‡πä‡∏ö‡πÜ‡πÜ‡πÜ': 860,\n"," '‡∏Ç‡∏≠‡πÄ‡∏ß‡∏•‡∏≤': 861,\n"," '‡∏≠‡∏µ‡∏Å‡πÑ‡∏°‡πà‡∏ô‡∏≤‡∏ô': 862,\n"," '‡∏¢‡∏∏‡∏ó‡∏ò': 863,\n"," '‡∏®‡∏≤‡∏™': 864,\n"," '‡∏≠‡πÄ‡∏ô‡∏µ‡πâ‡∏¢‡∏¢': 865,\n"," '‡∏ñ‡∏∂‡∏á‡∏Å‡∏±‡∏ö': 866,\n"," '‡∏õ‡∏£‡∏µ‡πä‡∏î': 867,\n"," '‡∏ö‡∏∏': 868,\n"," '‡∏Ñ‡∏Ñ': 869,\n"," '‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏à': 870,\n"," '‡∏≠‡πà‡∏≤‡∏ô': 871,\n"," '‡∏õ‡∏õ‡∏ä': 872,\n"," '‡πÇ‡∏û‡∏™‡∏ï‡πå': 873,\n"," '‡∏¢‡πâ‡∏≥': 874,\n"," '‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö': 875,\n"," '‡∏£‡∏∞‡∏ö‡∏≤‡∏î': 876,\n"," '‡∏ö‡∏î‡∏µ': 877,\n"," '‡∏≠‡∏ô‡∏∏‡∏ó‡∏¥‡∏ô': 878,\n"," '‡∏û‡∏Å': 879,\n"," '‡πÄ‡∏£‡∏µ‡∏¢‡∏Å': 880,\n"," '‡πÄ‡∏ô‡πâ‡∏ô': 881,\n"," '‡∏≠‡πÄ‡∏°‡∏£‡∏¥‡∏Å‡∏≤': 882,\n"," '‡πÇ‡∏à‡∏°‡∏ï‡∏µ': 883,\n"," '‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà': 884,\n"," '‡∏î‡∏±‡∏Å‡∏î‡∏≤‡∏ô': 885,\n"," '‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡πÄ‡∏ä‡∏¥‡πâ‡∏ï': 886,\n"," '‡∏õ‡∏Å‡∏Ñ‡∏•‡∏∏‡∏°': 887,\n"," '‡∏£‡πà‡∏≤‡∏á': 888,\n"," '‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå': 889,\n"," '‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÄ‡∏õ‡∏∑‡πà‡∏≠‡∏¢': 890,\n"," '‡∏ú‡∏π‡πâ‡∏°‡∏µ‡∏≠‡∏≥‡∏ô‡∏≤‡∏à': 891,\n"," '‡∏™‡∏±‡πà‡∏á‡∏Å‡∏≤‡∏£': 892,\n"," '‡∏à‡∏±‡∏î‡∏™‡∏£‡∏£': 893,\n"," '‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î': 894,\n"," '‡∏î‡πà‡∏≤‡∏ô': 895,\n"," '‡∏à': 896,\n"," '‡πÄ‡∏´‡πá‡∏ö': 897,\n"," '‡∏´‡∏°‡∏±‡∏î': 898,\n"," '‡πÄ‡∏Å‡∏≤‡∏∞‡∏Å‡∏¥‡∏ô': 899,\n"," '‡∏ù‡∏±‡∏á': 900,\n"," '‡∏¢‡∏∂‡∏î‡∏Ñ‡∏£‡∏≠‡∏á': 901,\n"," '‡∏¢‡πà‡∏≠‡∏°': 902,\n"," '‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢': 903,\n"," '‡∏¢‡∏≤‡∏ß': 904,\n"," '‡πÜ‡∏ß‡∏ô': 905,\n"," '‡∏Ñ‡∏ô‡∏ü‡∏±‡∏á': 906,\n"," '‡∏£‡πâ‡∏π': 907,\n"," '‡∏û‡∏π‡∏î‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÄ‡∏õ‡∏∑‡πà‡∏≠‡∏¢': 908,\n"," '‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå': 909,\n"," '‡∏≠‡∏≤‡∏£‡πå‡∏°': 910,\n"," '‡∏¢‡∏±‡∏á‡∏á‡∏±‡∏¢': 911,\n"," '‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á': 912,\n"," '‡πÄ‡∏¢‡∏µ‡∏¢‡∏ß‡∏¢‡∏≤': 913,\n"," '‡πÄ‡∏û‡∏•‡∏µ‡∏¢': 914,\n"," '‡∏ï‡πà‡∏≠‡πÉ‡∏´‡πâ': 915,\n"," '‡∏ü‡∏∑‡πâ‡∏ô': 916,\n"," '‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ': 917,\n"," '‡∏≠‡∏±‡∏•‡∏ü‡∏≠‡∏•': 918,\n"," '‡∏î‡∏±‡∏á': 919,\n"," '‡∏ö‡∏≤‡∏¢': 920,\n"," '‡∏ú‡∏¥‡∏î‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥': 921,\n"," '‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢': 922,\n"," '‡πÄ‡∏î‡∏¥‡∏ô‡∏´‡∏ô‡πâ‡∏≤': 923,\n"," '‡∏ñ‡∏≠‡∏¢‡∏´‡∏•‡∏±‡∏á': 924,\n"," '‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°': 925,\n"," '‡∏à‡πà‡∏≤‡∏¢': 926,\n"," '‡πÑ‡∏ï‡∏£‡πà‡∏ï‡∏£‡∏≠‡∏á': 927,\n"," '‡∏ô‡∏ô': 928,\n"," '‡∏û‡∏£‡∏£‡∏Ñ‡∏û‡∏ß‡∏Å': 929,\n"," '‡∏´‡∏ô‡∏±‡∏Å': 930,\n"," '‡∏™‡∏±‡∏ô‡∏î‡∏≤‡∏ô': 931,\n"," '‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡πà‡∏≤': 932,\n"," '‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏µ‡πâ': 933,\n"," '‡∏´‡∏¢‡∏∏‡∏î': 934,\n"," '‡πÄ‡πÄ‡∏•‡πâ‡∏ß': 935,\n"," '‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£': 936,\n"," '‡πÄ‡∏•‡∏µ‡∏¢': 937,\n"," '‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏≠‡∏î': 938,\n"," '‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠': 939,\n"," '‡πÄ‡∏´‡πá‡∏ô‡πÅ‡∏Å‡πà‡∏ï‡∏±‡∏ß': 940,\n"," '‡πÑ‡∏ß‡∏£‡∏±‡∏™': 941,\n"," '‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏á‡∏≤‡∏ô': 942,\n"," '‡∏°‡∏≤‡∏ï‡∏£‡∏≤': 943,\n"," '‡∏ê‡∏≤‡∏ô': 944,\n"," '‡∏ó‡∏±‡πâ‡∏á‡∏û‡∏ß‡∏Å': 945,\n"," '‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô': 946,\n"," '‡∏•‡πâ‡∏°': 947,\n"," '‡πÅ‡∏´‡∏°‡πà': 948,\n"," '‡∏ï‡∏∑‡πà‡∏ô': 949,\n"," '‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•': 950,\n"," '‡πÉ‡∏Å‡∏•‡πâ': 951,\n"," '‡πÅ‡∏ñ‡∏•‡∏á': 952,\n"," '‡∏ú‡∏≤‡∏¢‡∏•‡∏°': 953,\n"," '‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞': 954,\n"," '‡∏Ç‡∏ö‡∏ß‡∏ô': 955,\n"," '‡πÄ‡∏•‡∏≠‡∏∞‡πÄ‡∏ó‡∏≠‡∏∞': 956,\n"," '‡∏´‡∏•‡∏±‡∏á': 957,\n"," '‡∏ú‡∏•‡∏á‡∏≤‡∏ô': 958,\n"," '‡πÄ‡∏™‡∏ô‡∏≠‡∏´‡∏ô‡πâ‡∏≤': 959,\n"," '‡πÅ‡∏ñ‡∏•‡∏á‡∏Ç‡πà‡∏≤‡∏ß': 960,\n"," '‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà': 961,\n"," '‡∏Ñ‡∏≥‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©': 962,\n"," '‡πÄ‡∏î‡πã‡∏ß': 963,\n"," '‡πÅ‡∏û‡∏ó‡∏¢‡πå': 964,\n"," '‡∏ï‡∏•‡∏Å': 965,\n"," '‡∏õ‡∏ó‡∏ó': 966,\n"," '‡∏°‡∏≤‡∏ñ‡∏∂‡∏á': 967,\n"," '‡πÄ‡∏ß‡∏£‡∏Å‡∏£‡∏£‡∏°': 968,\n"," '‡∏õ‡∏ó': 969,\n"," '‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö': 970,\n"," '‡πÄ‡∏ó‡∏µ‡∏¢‡∏¢': 971,\n"," '‡∏™‡∏±‡∏Å‡∏ô‡∏¥‡∏î': 972,\n"," '‡∏°‡∏ì': 973,\n"," '‡∏´‡∏•‡∏±‡∏Å': 974,\n"," '‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏ó‡∏≥': 975,\n"," '‡∏´‡∏•‡∏±‡∏Å‡∏´‡∏ô‡πà‡∏ß‡∏¢': 976,\n"," '‡∏•‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏≥': 977,\n"," '‡∏ó‡∏∏‡πÄ‡∏£‡∏®': 978,\n"," '‡∏ï‡∏±‡∏ß': 979,\n"," '‡∏£‡∏±‡∏î': 980,\n"," '‡∏ö‡∏≤‡∏ô': 981,\n"," '‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô': 982,\n"," '‡∏™‡∏±‡∏Å‡∏ß‡∏±‡∏ô': 983,\n"," '‡∏ñ‡∏•‡∏≠‡∏Å': 984,\n"," '‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢': 985,\n"," '‡∏£‡∏±‡∏á‡πÅ‡∏Å': 986,\n"," '‡∏à‡∏µ‡πâ': 987,\n"," '‡πÇ‡∏ñ‡πà': 988,\n"," '‡∏î‡∏±‡∏ö': 989,\n"," '‡∏Ñ‡∏≤': 990,\n"," '‡∏à‡∏≠': 991,\n"," '‡∏•‡∏π‡∏Å‡∏û‡∏µ‡πà‡∏•‡∏π‡∏Å‡∏ô‡πâ‡∏≠‡∏á': 992,\n"," '‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß': 993,\n"," '‡∏ô‡∏¥‡∏™‡∏±‡∏¢': 994,\n"," '‡∏£‡∏π‡πâ‡∏™‡∏≥‡∏ô‡∏∂‡∏Å': 995,\n"," '‡∏Å‡∏•‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏Å‡∏•‡∏±‡∏ö‡πÉ‡∏à': 996,\n"," '‡∏ö‡∏±‡πà‡∏ô‡∏ó‡∏≠‡∏ô': 997,\n"," '‡∏™‡∏†‡∏≤‡∏û': 998,\n"," '‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ': 999,\n"," '‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤': 1000,\n"," ...}"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"code","metadata":{"id":"jIi0dB-d9uw5","executionInfo":{"status":"ok","timestamp":1628694884163,"user_tz":-420,"elapsed":52,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["def max_length(words):\n","    return(len(max(words, key = len)))"],"execution_count":91,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PHgkG2tr9utw","executionInfo":{"status":"ok","timestamp":1628694884163,"user_tz":-420,"elapsed":52,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"4bb777d5-dbdb-489c-8010-730dae6b600f"},"source":["max_length = max_length(temp)\n","max_length"],"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/plain":["65"]},"metadata":{"tags":[]},"execution_count":92}]},{"cell_type":"code","metadata":{"id":"t0NhznO2_jtg","executionInfo":{"status":"ok","timestamp":1628694884164,"user_tz":-420,"elapsed":33,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["def encoding_doc(token, words):\n","    return(token.texts_to_sequences(words))"],"execution_count":93,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iosiVh5y_1nJ","executionInfo":{"status":"ok","timestamp":1628694884164,"user_tz":-420,"elapsed":33,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"9e43eaad-4511-415f-d7e7-328b76be9e49"},"source":["encoded_doc = encoding_doc(train_word_tokenizer, cleaned_words)\n","\n","print(cleaned_words[0])\n","print(encoded_doc[0])"],"execution_count":94,"outputs":[{"output_type":"stream","text":["‡∏ô‡∏µ‡πà ‡πÄ‡∏≠‡∏≤ ‡∏£‡∏±‡∏ê‡∏°‡∏ô‡∏ï‡∏£‡∏µ ‡∏°‡∏≤ ‡∏Ñ‡∏∏‡∏¢ ‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏´‡∏£‡∏≠ ‡∏Ñ‡∏£‡∏±‡∏ö ‡πÉ‡∏´‡πâ ‡πÄ‡∏î‡∏¥‡∏ô ‡πÑ‡∏õ ‡∏Ñ‡∏∏‡∏¢ ‡∏Å‡∏∞ ‡∏õ‡πâ‡∏≤ ‡∏Ç‡∏≤‡∏¢ ‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‡∏ï‡∏≤‡∏° ‡∏™‡∏±‡πà‡∏á ‡∏¢‡∏±‡∏á ‡∏£‡∏∏‡πâ ‡∏™‡∏∂‡∏Å ‡∏ß‡πà‡∏≤ ‡∏ï‡∏≠‡∏ö ‡∏°‡∏µ ‡∏™‡∏≤‡∏£‡∏∞ ‡πÅ‡∏•‡∏∞ ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏• ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ ‡∏ô‡∏µ‡πâ ‡πÄ‡∏•‡∏¢ ‡∏ô‡∏µ‡πà ‡∏ü‡∏±‡∏á ‡∏ï‡∏£‡∏£‡∏Å‡∏∞ ‡∏û‡∏±‡∏á‡∏û‡∏¥‡∏ô‡∏≤‡∏® ‡∏°‡∏≤‡∏Å ‡πÄ‡∏•‡∏¢ ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô ‡πÑ‡∏°‡πà ‡πÄ‡∏Ñ‡∏¢ ‡∏î‡∏π ‡∏Ç‡πà‡∏≤‡∏ß\n","[55, 68, 34, 10, 117, 69, 104, 6, 17, 726, 13, 117, 340, 341, 272, 727, 148, 342, 70, 343, 454, 22, 63, 7, 455, 20, 456, 196, 25, 8, 55, 21, 273, 728, 4, 8, 64, 1, 96, 51, 344]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KpTWHnbGAJQ6","executionInfo":{"status":"ok","timestamp":1628694884165,"user_tz":-420,"elapsed":31,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["def padding_doc(encoded_doc, max_length):\n","    return(pad_sequences(encoded_doc, maxlen = max_length, padding = \"post\"))"],"execution_count":95,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K8Ufr4g8ASZn","executionInfo":{"status":"ok","timestamp":1628694884876,"user_tz":-420,"elapsed":741,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"16393128-8745-4227-f991-3f7d61e71334"},"source":["padded_doc = padding_doc(encoded_doc, max_length)\n","print(\"Shape of padded docs = \",padded_doc.shape)\n","\n","print(cleaned_words[0])\n","print(encoded_doc[0])\n","print(padded_doc[0])"],"execution_count":96,"outputs":[{"output_type":"stream","text":["Shape of padded docs =  (500, 65)\n","‡∏ô‡∏µ‡πà ‡πÄ‡∏≠‡∏≤ ‡∏£‡∏±‡∏ê‡∏°‡∏ô‡∏ï‡∏£‡∏µ ‡∏°‡∏≤ ‡∏Ñ‡∏∏‡∏¢ ‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏´‡∏£‡∏≠ ‡∏Ñ‡∏£‡∏±‡∏ö ‡πÉ‡∏´‡πâ ‡πÄ‡∏î‡∏¥‡∏ô ‡πÑ‡∏õ ‡∏Ñ‡∏∏‡∏¢ ‡∏Å‡∏∞ ‡∏õ‡πâ‡∏≤ ‡∏Ç‡∏≤‡∏¢ ‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‡∏ï‡∏≤‡∏° ‡∏™‡∏±‡πà‡∏á ‡∏¢‡∏±‡∏á ‡∏£‡∏∏‡πâ ‡∏™‡∏∂‡∏Å ‡∏ß‡πà‡∏≤ ‡∏ï‡∏≠‡∏ö ‡∏°‡∏µ ‡∏™‡∏≤‡∏£‡∏∞ ‡πÅ‡∏•‡∏∞ ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏• ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ ‡∏ô‡∏µ‡πâ ‡πÄ‡∏•‡∏¢ ‡∏ô‡∏µ‡πà ‡∏ü‡∏±‡∏á ‡∏ï‡∏£‡∏£‡∏Å‡∏∞ ‡∏û‡∏±‡∏á‡∏û‡∏¥‡∏ô‡∏≤‡∏® ‡∏°‡∏≤‡∏Å ‡πÄ‡∏•‡∏¢ ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô ‡πÑ‡∏°‡πà ‡πÄ‡∏Ñ‡∏¢ ‡∏î‡∏π ‡∏Ç‡πà‡∏≤‡∏ß\n","[55, 68, 34, 10, 117, 69, 104, 6, 17, 726, 13, 117, 340, 341, 272, 727, 148, 342, 70, 343, 454, 22, 63, 7, 455, 20, 456, 196, 25, 8, 55, 21, 273, 728, 4, 8, 64, 1, 96, 51, 344]\n","[ 55  68  34  10 117  69 104   6  17 726  13 117 340 341 272 727 148 342\n","  70 343 454  22  63   7 455  20 456 196  25   8  55  21 273 728   4   8\n","  64   1  96  51 344   0   0   0   0   0   0   0   0   0   0   0   0   0\n","   0   0   0   0   0   0   0   0   0   0   0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UM6X1wTsBcff","executionInfo":{"status":"ok","timestamp":1628694884876,"user_tz":-420,"elapsed":31,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"2a2ea7b0-0236-435f-d9e7-ef0d8ce1ea7b"},"source":["unique_labels = list(set(labels))\n","unique_labels"],"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['neg', 'pos']"]},"metadata":{"tags":[]},"execution_count":97}]},{"cell_type":"code","metadata":{"id":"TqCtOHcbBcdL","executionInfo":{"status":"ok","timestamp":1628694884876,"user_tz":-420,"elapsed":26,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["output_tokenizer = create_tokenizer(unique_labels)"],"execution_count":98,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Pv6qgskBca2","executionInfo":{"status":"ok","timestamp":1628694884877,"user_tz":-420,"elapsed":27,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"13bc79f7-184c-46d6-8b88-4f52d8fe4c31"},"source":["encoded_output = encoding_doc(output_tokenizer, labels)\n","print(labels[0:2])\n","print(encoded_output[0:2])"],"execution_count":99,"outputs":[{"output_type":"stream","text":["['neg' 'neg']\n","[[1], [1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QVlV0Q1OBcYN","executionInfo":{"status":"ok","timestamp":1628694884877,"user_tz":-420,"elapsed":23,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"6a8a05a4-60f5-4900-87d7-170934932e6a"},"source":["encoded_output = np.array(encoded_output).reshape(len(encoded_output), 1)\n","encoded_output.shape"],"execution_count":100,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(500, 1)"]},"metadata":{"tags":[]},"execution_count":100}]},{"cell_type":"code","metadata":{"id":"oEMlVdULBcVy","executionInfo":{"status":"ok","timestamp":1628694884877,"user_tz":-420,"elapsed":20,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["def one_hot(encode):\n","  oh = OneHotEncoder(sparse = False)\n","  return(oh.fit_transform(encode))"],"execution_count":101,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o2b8je29BcTA","executionInfo":{"status":"ok","timestamp":1628694884877,"user_tz":-420,"elapsed":20,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"76e23788-258b-48ac-fb73-13f77bb2cf85"},"source":["output_one_hot = one_hot(encoded_output)\n","print(encoded_output[0])\n","print(output_one_hot[0])"],"execution_count":102,"outputs":[{"output_type":"stream","text":["[1]\n","[1. 0.]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XWnz15Xu6Riq"},"source":["\n","\n","> ‡πÅ‡∏ö‡πà‡∏áDataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Train 80% ‡πÅ‡∏•‡∏∞ Validate 20%\n","\n"]},{"cell_type":"code","metadata":{"id":"bqpPKuRXDnTD","executionInfo":{"status":"ok","timestamp":1628694884878,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["train_X, val_X, train_Y, val_Y = train_test_split(padded_doc, output_one_hot, shuffle = True, test_size = 0.2, stratify=output_one_hot)"],"execution_count":103,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V8Zbx94GDnQP","executionInfo":{"status":"ok","timestamp":1628694884878,"user_tz":-420,"elapsed":18,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"d51ddd79-73b7-46c9-bd8a-98d4f3f49f2e"},"source":["print(\"Shape of train_X = %s and train_Y = %s\" % (train_X.shape, train_Y.shape))\n","print(\"Shape of val_X = %s and val_Y = %s\" % (val_X.shape, val_Y.shape))"],"execution_count":104,"outputs":[{"output_type":"stream","text":["Shape of train_X = (400, 65) and train_Y = (400, 2)\n","Shape of val_X = (100, 65) and val_Y = (100, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wloS4Rn6DnNU","executionInfo":{"status":"ok","timestamp":1628694884878,"user_tz":-420,"elapsed":15,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["num_classes = len(unique_labels)"],"execution_count":105,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dGAUOx1w6tSD"},"source":["\n","\n","> ‡∏ô‡∏¥‡∏¢‡∏≤‡∏° Model ‡πÅ‡∏ö‡∏ö GRU\n","\n","*   ‡∏Å‡∏≥‡∏´‡∏ô‡∏î learning_rate=0.0001\n","*   ‡∏Å‡∏≥‡∏´‡∏ô‡∏î dropout = 0.3\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IeSNVzAJ9vRz","executionInfo":{"status":"ok","timestamp":1628694884878,"user_tz":-420,"elapsed":15,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"7f26f59b-2be3-407e-8bae-a5e2d3210a1a"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, GRU, LSTM, Bidirectional, Embedding, Dropout, BatchNormalization\n","from tensorflow.keras.models import load_model\n","\n","from tensorflow.keras.optimizers import Adam\n","adam = Adam(learning_rate=0.0001)\n","\n","def create_model(vocab_size, max_length):\n","  model = Sequential()\n","  \n","  model.add(Embedding(vocab_size, 128, input_length = max_length,  trainable = True))\n","  model.add(Bidirectional(GRU(128, activation = \"relu\"))) # activation = \"relu\"\n","  model.add(Dense(128, activation = \"relu\"))\n","  model.add(Dropout(0.3))\n","  model.add(Dense(64, activation = \"relu\"))\n","  model.add(Dropout(0.3))\n","  model.add(BatchNormalization())\n","  model.add(Dense(num_classes, activation = \"softmax\"))\n","  \n","  return model\n","  \n","model = create_model(vocab_size, max_length)"],"execution_count":106,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fSsrygvmIxwG","executionInfo":{"status":"ok","timestamp":1628694884878,"user_tz":-420,"elapsed":12,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"5a7f59e4-5dcc-46df-cc55-404620e57c44"},"source":["model.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n","model.summary()"],"execution_count":107,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, 65, 128)           202496    \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 256)               198144    \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 64)                8256      \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 64)                256       \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 2)                 130       \n","=================================================================\n","Total params: 442,178\n","Trainable params: 442,050\n","Non-trainable params: 128\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nxwmUzGp7cV5"},"source":["\n","\n","> ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏∏‡∏î Check Point ‡πÄ‡∏û‡∏∑‡πà‡∏≠ Save Model\n","\n"]},{"cell_type":"code","metadata":{"id":"9WUOAXL_Ixtg","executionInfo":{"status":"ok","timestamp":1628694884878,"user_tz":-420,"elapsed":9,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["filename = 'model.h5_kr'\n","checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"],"execution_count":108,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HAUZ7bU37fQa"},"source":["\n","\n","> Train Model\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CJJEl0NtIxrQ","executionInfo":{"status":"ok","timestamp":1628695630495,"user_tz":-420,"elapsed":745626,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"8c498d52-05db-4e3d-8540-add7dde9eb2c"},"source":["hist = model.fit(train_X, train_Y, epochs = EPOCHS, batch_size = BS, validation_data = (val_X, val_Y), callbacks = [checkpoint])"],"execution_count":109,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","13/13 [==============================] - 8s 305ms/step - loss: 0.7094 - accuracy: 0.5000 - val_loss: 0.6917 - val_accuracy: 0.6000\n","\n","Epoch 00001: val_loss improved from inf to 0.69174, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 2/150\n","13/13 [==============================] - 4s 284ms/step - loss: 0.6737 - accuracy: 0.5500 - val_loss: 0.6906 - val_accuracy: 0.6300\n","\n","Epoch 00002: val_loss improved from 0.69174 to 0.69058, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 3/150\n","13/13 [==============================] - 3s 268ms/step - loss: 0.6508 - accuracy: 0.6275 - val_loss: 0.6892 - val_accuracy: 0.7900\n","\n","Epoch 00003: val_loss improved from 0.69058 to 0.68923, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 4/150\n","13/13 [==============================] - 4s 271ms/step - loss: 0.6263 - accuracy: 0.6650 - val_loss: 0.6874 - val_accuracy: 0.7300\n","\n","Epoch 00004: val_loss improved from 0.68923 to 0.68744, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 5/150\n","13/13 [==============================] - 3s 262ms/step - loss: 0.5881 - accuracy: 0.7300 - val_loss: 0.6853 - val_accuracy: 0.7800\n","\n","Epoch 00005: val_loss improved from 0.68744 to 0.68526, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 6/150\n","13/13 [==============================] - 4s 270ms/step - loss: 0.5699 - accuracy: 0.7400 - val_loss: 0.6827 - val_accuracy: 0.8000\n","\n","Epoch 00006: val_loss improved from 0.68526 to 0.68273, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 7/150\n","13/13 [==============================] - 4s 270ms/step - loss: 0.5272 - accuracy: 0.7650 - val_loss: 0.6794 - val_accuracy: 0.8000\n","\n","Epoch 00007: val_loss improved from 0.68273 to 0.67945, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 8/150\n","13/13 [==============================] - 4s 275ms/step - loss: 0.4848 - accuracy: 0.8175 - val_loss: 0.6747 - val_accuracy: 0.8000\n","\n","Epoch 00008: val_loss improved from 0.67945 to 0.67465, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 9/150\n","13/13 [==============================] - 4s 278ms/step - loss: 0.4375 - accuracy: 0.8325 - val_loss: 0.6689 - val_accuracy: 0.8100\n","\n","Epoch 00009: val_loss improved from 0.67465 to 0.66890, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 10/150\n","13/13 [==============================] - 4s 271ms/step - loss: 0.4174 - accuracy: 0.8400 - val_loss: 0.6628 - val_accuracy: 0.8400\n","\n","Epoch 00010: val_loss improved from 0.66890 to 0.66277, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 11/150\n","13/13 [==============================] - 3s 251ms/step - loss: 0.3647 - accuracy: 0.8900 - val_loss: 0.6553 - val_accuracy: 0.8600\n","\n","Epoch 00011: val_loss improved from 0.66277 to 0.65532, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 12/150\n","13/13 [==============================] - 4s 281ms/step - loss: 0.3421 - accuracy: 0.8925 - val_loss: 0.6476 - val_accuracy: 0.8400\n","\n","Epoch 00012: val_loss improved from 0.65532 to 0.64757, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 13/150\n","13/13 [==============================] - 3s 266ms/step - loss: 0.2962 - accuracy: 0.9050 - val_loss: 0.6378 - val_accuracy: 0.8500\n","\n","Epoch 00013: val_loss improved from 0.64757 to 0.63779, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 14/150\n","13/13 [==============================] - 4s 280ms/step - loss: 0.2640 - accuracy: 0.9300 - val_loss: 0.6274 - val_accuracy: 0.8500\n","\n","Epoch 00014: val_loss improved from 0.63779 to 0.62736, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 15/150\n","13/13 [==============================] - 3s 262ms/step - loss: 0.2417 - accuracy: 0.9375 - val_loss: 0.6148 - val_accuracy: 0.8600\n","\n","Epoch 00015: val_loss improved from 0.62736 to 0.61480, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 16/150\n","13/13 [==============================] - 3s 253ms/step - loss: 0.2029 - accuracy: 0.9425 - val_loss: 0.6011 - val_accuracy: 0.8700\n","\n","Epoch 00016: val_loss improved from 0.61480 to 0.60113, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 17/150\n","13/13 [==============================] - 3s 257ms/step - loss: 0.1909 - accuracy: 0.9525 - val_loss: 0.5881 - val_accuracy: 0.8700\n","\n","Epoch 00017: val_loss improved from 0.60113 to 0.58806, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 18/150\n","13/13 [==============================] - 3s 258ms/step - loss: 0.1440 - accuracy: 0.9750 - val_loss: 0.5710 - val_accuracy: 0.8700\n","\n","Epoch 00018: val_loss improved from 0.58806 to 0.57105, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 19/150\n","13/13 [==============================] - 3s 262ms/step - loss: 0.1422 - accuracy: 0.9600 - val_loss: 0.5507 - val_accuracy: 0.8900\n","\n","Epoch 00019: val_loss improved from 0.57105 to 0.55069, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 20/150\n","13/13 [==============================] - 4s 273ms/step - loss: 0.1270 - accuracy: 0.9725 - val_loss: 0.5333 - val_accuracy: 0.9000\n","\n","Epoch 00020: val_loss improved from 0.55069 to 0.53332, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 21/150\n","13/13 [==============================] - 4s 271ms/step - loss: 0.1026 - accuracy: 0.9750 - val_loss: 0.5123 - val_accuracy: 0.9000\n","\n","Epoch 00021: val_loss improved from 0.53332 to 0.51234, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 22/150\n","13/13 [==============================] - 3s 264ms/step - loss: 0.0851 - accuracy: 0.9850 - val_loss: 0.4920 - val_accuracy: 0.9000\n","\n","Epoch 00022: val_loss improved from 0.51234 to 0.49201, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 23/150\n","13/13 [==============================] - 3s 256ms/step - loss: 0.0778 - accuracy: 0.9850 - val_loss: 0.4723 - val_accuracy: 0.9000\n","\n","Epoch 00023: val_loss improved from 0.49201 to 0.47226, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 24/150\n","13/13 [==============================] - 3s 255ms/step - loss: 0.0570 - accuracy: 0.9900 - val_loss: 0.4509 - val_accuracy: 0.8800\n","\n","Epoch 00024: val_loss improved from 0.47226 to 0.45088, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 25/150\n","13/13 [==============================] - 3s 253ms/step - loss: 0.0624 - accuracy: 0.9875 - val_loss: 0.4249 - val_accuracy: 0.9000\n","\n","Epoch 00025: val_loss improved from 0.45088 to 0.42494, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 26/150\n","13/13 [==============================] - 3s 252ms/step - loss: 0.0555 - accuracy: 0.9925 - val_loss: 0.4001 - val_accuracy: 0.8900\n","\n","Epoch 00026: val_loss improved from 0.42494 to 0.40007, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 27/150\n","13/13 [==============================] - 3s 271ms/step - loss: 0.0370 - accuracy: 0.9975 - val_loss: 0.3769 - val_accuracy: 0.8900\n","\n","Epoch 00027: val_loss improved from 0.40007 to 0.37687, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 28/150\n","13/13 [==============================] - 4s 274ms/step - loss: 0.0322 - accuracy: 0.9975 - val_loss: 0.3519 - val_accuracy: 0.8900\n","\n","Epoch 00028: val_loss improved from 0.37687 to 0.35186, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 29/150\n","13/13 [==============================] - 4s 269ms/step - loss: 0.0290 - accuracy: 0.9975 - val_loss: 0.3304 - val_accuracy: 0.9100\n","\n","Epoch 00029: val_loss improved from 0.35186 to 0.33038, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 30/150\n","13/13 [==============================] - 3s 256ms/step - loss: 0.0321 - accuracy: 0.9975 - val_loss: 0.3123 - val_accuracy: 0.9100\n","\n","Epoch 00030: val_loss improved from 0.33038 to 0.31232, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 31/150\n","13/13 [==============================] - 3s 261ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9200\n","\n","Epoch 00031: val_loss improved from 0.31232 to 0.29252, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 32/150\n","13/13 [==============================] - 3s 255ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9200\n","\n","Epoch 00032: val_loss improved from 0.29252 to 0.27359, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 33/150\n","13/13 [==============================] - 3s 255ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9000\n","\n","Epoch 00033: val_loss improved from 0.27359 to 0.26046, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 34/150\n","13/13 [==============================] - 3s 261ms/step - loss: 0.0327 - accuracy: 0.9975 - val_loss: 0.2472 - val_accuracy: 0.9000\n","\n","Epoch 00034: val_loss improved from 0.26046 to 0.24721, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 35/150\n","13/13 [==============================] - 4s 273ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9100\n","\n","Epoch 00035: val_loss improved from 0.24721 to 0.23908, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 36/150\n","13/13 [==============================] - 4s 276ms/step - loss: 0.0190 - accuracy: 0.9975 - val_loss: 0.2231 - val_accuracy: 0.9000\n","\n","Epoch 00036: val_loss improved from 0.23908 to 0.22312, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 37/150\n","13/13 [==============================] - 4s 275ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9100\n","\n","Epoch 00037: val_loss improved from 0.22312 to 0.21613, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 38/150\n","13/13 [==============================] - 4s 273ms/step - loss: 0.0223 - accuracy: 0.9975 - val_loss: 0.2161 - val_accuracy: 0.9100\n","\n","Epoch 00038: val_loss improved from 0.21613 to 0.21610, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 39/150\n","13/13 [==============================] - 3s 261ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9200\n","\n","Epoch 00039: val_loss did not improve from 0.21610\n","Epoch 40/150\n","13/13 [==============================] - 3s 258ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9200\n","\n","Epoch 00040: val_loss improved from 0.21610 to 0.21335, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 41/150\n","13/13 [==============================] - 3s 254ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9200\n","\n","Epoch 00041: val_loss improved from 0.21335 to 0.20888, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 42/150\n","13/13 [==============================] - 3s 259ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9300\n","\n","Epoch 00042: val_loss improved from 0.20888 to 0.20543, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 43/150\n","13/13 [==============================] - 4s 265ms/step - loss: 0.0116 - accuracy: 0.9975 - val_loss: 0.2029 - val_accuracy: 0.9300\n","\n","Epoch 00043: val_loss improved from 0.20543 to 0.20288, saving model to model.h5_kr\n","INFO:tensorflow:Assets written to: model.h5_kr/assets\n","Epoch 44/150\n","13/13 [==============================] - 4s 274ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9300\n","\n","Epoch 00044: val_loss did not improve from 0.20288\n","Epoch 45/150\n","13/13 [==============================] - 4s 280ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9300\n","\n","Epoch 00045: val_loss did not improve from 0.20288\n","Epoch 46/150\n","13/13 [==============================] - 4s 282ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9200\n","\n","Epoch 00046: val_loss did not improve from 0.20288\n","Epoch 47/150\n","13/13 [==============================] - 4s 278ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9300\n","\n","Epoch 00047: val_loss did not improve from 0.20288\n","Epoch 48/150\n","13/13 [==============================] - 4s 278ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9300\n","\n","Epoch 00048: val_loss did not improve from 0.20288\n","Epoch 49/150\n","13/13 [==============================] - 4s 281ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9300\n","\n","Epoch 00049: val_loss did not improve from 0.20288\n","Epoch 50/150\n","13/13 [==============================] - 3s 266ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9300\n","\n","Epoch 00050: val_loss did not improve from 0.20288\n","Epoch 51/150\n","13/13 [==============================] - 3s 267ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9300\n","\n","Epoch 00051: val_loss did not improve from 0.20288\n","Epoch 52/150\n","13/13 [==============================] - 4s 273ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9300\n","\n","Epoch 00052: val_loss did not improve from 0.20288\n","Epoch 53/150\n","13/13 [==============================] - 4s 280ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9300\n","\n","Epoch 00053: val_loss did not improve from 0.20288\n","Epoch 54/150\n","13/13 [==============================] - 4s 281ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9300\n","\n","Epoch 00054: val_loss did not improve from 0.20288\n","Epoch 55/150\n","13/13 [==============================] - 4s 278ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9200\n","\n","Epoch 00055: val_loss did not improve from 0.20288\n","Epoch 56/150\n","13/13 [==============================] - 4s 284ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9200\n","\n","Epoch 00056: val_loss did not improve from 0.20288\n","Epoch 57/150\n","13/13 [==============================] - 4s 283ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9300\n","\n","Epoch 00057: val_loss did not improve from 0.20288\n","Epoch 58/150\n","13/13 [==============================] - 4s 278ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9300\n","\n","Epoch 00058: val_loss did not improve from 0.20288\n","Epoch 59/150\n","13/13 [==============================] - 3s 267ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9300\n","\n","Epoch 00059: val_loss did not improve from 0.20288\n","Epoch 60/150\n","13/13 [==============================] - 3s 262ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9300\n","\n","Epoch 00060: val_loss did not improve from 0.20288\n","Epoch 61/150\n","13/13 [==============================] - 3s 263ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9300\n","\n","Epoch 00061: val_loss did not improve from 0.20288\n","Epoch 62/150\n","13/13 [==============================] - 3s 261ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.9300\n","\n","Epoch 00062: val_loss did not improve from 0.20288\n","Epoch 63/150\n","13/13 [==============================] - 3s 261ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9300\n","\n","Epoch 00063: val_loss did not improve from 0.20288\n","Epoch 64/150\n","13/13 [==============================] - 3s 260ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9300\n","\n","Epoch 00064: val_loss did not improve from 0.20288\n","Epoch 65/150\n","13/13 [==============================] - 3s 252ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9400\n","\n","Epoch 00065: val_loss did not improve from 0.20288\n","Epoch 66/150\n","13/13 [==============================] - 3s 257ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9400\n","\n","Epoch 00066: val_loss did not improve from 0.20288\n","Epoch 67/150\n","13/13 [==============================] - 3s 254ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9400\n","\n","Epoch 00067: val_loss did not improve from 0.20288\n","Epoch 68/150\n","13/13 [==============================] - 3s 257ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9400\n","\n","Epoch 00068: val_loss did not improve from 0.20288\n","Epoch 69/150\n","13/13 [==============================] - 3s 268ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9400\n","\n","Epoch 00069: val_loss did not improve from 0.20288\n","Epoch 70/150\n","13/13 [==============================] - 3s 269ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9400\n","\n","Epoch 00070: val_loss did not improve from 0.20288\n","Epoch 71/150\n","13/13 [==============================] - 4s 276ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9400\n","\n","Epoch 00071: val_loss did not improve from 0.20288\n","Epoch 72/150\n","13/13 [==============================] - 4s 285ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 0.9400\n","\n","Epoch 00072: val_loss did not improve from 0.20288\n","Epoch 73/150\n","13/13 [==============================] - 4s 277ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2760 - val_accuracy: 0.9400\n","\n","Epoch 00073: val_loss did not improve from 0.20288\n","Epoch 74/150\n","13/13 [==============================] - 4s 280ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9400\n","\n","Epoch 00074: val_loss did not improve from 0.20288\n","Epoch 75/150\n","13/13 [==============================] - 4s 278ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9400\n","\n","Epoch 00075: val_loss did not improve from 0.20288\n","Epoch 76/150\n","13/13 [==============================] - 4s 281ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9400\n","\n","Epoch 00076: val_loss did not improve from 0.20288\n","Epoch 77/150\n","13/13 [==============================] - 3s 268ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9400\n","\n","Epoch 00077: val_loss did not improve from 0.20288\n","Epoch 78/150\n","13/13 [==============================] - 3s 257ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9400\n","\n","Epoch 00078: val_loss did not improve from 0.20288\n","Epoch 79/150\n","13/13 [==============================] - 3s 262ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9400\n","\n","Epoch 00079: val_loss did not improve from 0.20288\n","Epoch 80/150\n","13/13 [==============================] - 3s 261ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9400\n","\n","Epoch 00080: val_loss did not improve from 0.20288\n","Epoch 81/150\n","13/13 [==============================] - 3s 262ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9400\n","\n","Epoch 00081: val_loss did not improve from 0.20288\n","Epoch 82/150\n","13/13 [==============================] - 3s 255ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.9400\n","\n","Epoch 00082: val_loss did not improve from 0.20288\n","Epoch 83/150\n","13/13 [==============================] - 3s 258ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9400\n","\n","Epoch 00083: val_loss did not improve from 0.20288\n","Epoch 84/150\n","13/13 [==============================] - 3s 255ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9500\n","\n","Epoch 00084: val_loss did not improve from 0.20288\n","Epoch 85/150\n","13/13 [==============================] - 3s 257ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9500\n","\n","Epoch 00085: val_loss did not improve from 0.20288\n","Epoch 86/150\n","13/13 [==============================] - 3s 256ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9400\n","\n","Epoch 00086: val_loss did not improve from 0.20288\n","Epoch 87/150\n","13/13 [==============================] - 3s 259ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9400\n","\n","Epoch 00087: val_loss did not improve from 0.20288\n","Epoch 88/150\n","13/13 [==============================] - 3s 258ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9400\n","\n","Epoch 00088: val_loss did not improve from 0.20288\n","Epoch 89/150\n","13/13 [==============================] - 3s 256ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9400\n","\n","Epoch 00089: val_loss did not improve from 0.20288\n","Epoch 90/150\n","13/13 [==============================] - 4s 282ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9400\n","\n","Epoch 00090: val_loss did not improve from 0.20288\n","Epoch 91/150\n","13/13 [==============================] - 4s 281ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9500\n","\n","Epoch 00091: val_loss did not improve from 0.20288\n","Epoch 92/150\n","13/13 [==============================] - 4s 271ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.9500\n","\n","Epoch 00092: val_loss did not improve from 0.20288\n","Epoch 93/150\n","13/13 [==============================] - 4s 280ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.9500\n","\n","Epoch 00093: val_loss did not improve from 0.20288\n","Epoch 94/150\n","13/13 [==============================] - 4s 271ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2604 - val_accuracy: 0.9500\n","\n","Epoch 00094: val_loss did not improve from 0.20288\n","Epoch 95/150\n","13/13 [==============================] - 4s 276ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2501 - val_accuracy: 0.9500\n","\n","Epoch 00095: val_loss did not improve from 0.20288\n","Epoch 96/150\n","13/13 [==============================] - 4s 275ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9500\n","\n","Epoch 00096: val_loss did not improve from 0.20288\n","Epoch 97/150\n","13/13 [==============================] - 3s 265ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9500\n","\n","Epoch 00097: val_loss did not improve from 0.20288\n","Epoch 98/150\n","13/13 [==============================] - 3s 267ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9200\n","\n","Epoch 00098: val_loss did not improve from 0.20288\n","Epoch 99/150\n","13/13 [==============================] - 3s 262ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9200\n","\n","Epoch 00099: val_loss did not improve from 0.20288\n","Epoch 100/150\n","13/13 [==============================] - 3s 264ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9200\n","\n","Epoch 00100: val_loss did not improve from 0.20288\n","Epoch 101/150\n","13/13 [==============================] - 3s 257ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9500\n","\n","Epoch 00101: val_loss did not improve from 0.20288\n","Epoch 102/150\n","13/13 [==============================] - 3s 256ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9500\n","\n","Epoch 00102: val_loss did not improve from 0.20288\n","Epoch 103/150\n","13/13 [==============================] - 3s 256ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9500\n","\n","Epoch 00103: val_loss did not improve from 0.20288\n","Epoch 104/150\n","13/13 [==============================] - 3s 258ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9400\n","\n","Epoch 00104: val_loss did not improve from 0.20288\n","Epoch 105/150\n","13/13 [==============================] - 3s 256ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.9400\n","\n","Epoch 00105: val_loss did not improve from 0.20288\n","Epoch 106/150\n","13/13 [==============================] - 3s 257ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.9500\n","\n","Epoch 00106: val_loss did not improve from 0.20288\n","Epoch 107/150\n","13/13 [==============================] - 3s 258ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9500\n","\n","Epoch 00107: val_loss did not improve from 0.20288\n","Epoch 108/150\n","13/13 [==============================] - 3s 265ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9500\n","\n","Epoch 00108: val_loss did not improve from 0.20288\n","Epoch 109/150\n","13/13 [==============================] - 4s 273ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9500\n","\n","Epoch 00109: val_loss did not improve from 0.20288\n","Epoch 110/150\n","13/13 [==============================] - 4s 276ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9500\n","\n","Epoch 00110: val_loss did not improve from 0.20288\n","Epoch 111/150\n","13/13 [==============================] - 4s 287ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9500\n","\n","Epoch 00111: val_loss did not improve from 0.20288\n","Epoch 112/150\n","13/13 [==============================] - 4s 281ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9400\n","\n","Epoch 00112: val_loss did not improve from 0.20288\n","Epoch 113/150\n","13/13 [==============================] - 4s 290ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9300\n","\n","Epoch 00113: val_loss did not improve from 0.20288\n","Epoch 114/150\n","13/13 [==============================] - 4s 280ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9300\n","\n","Epoch 00114: val_loss did not improve from 0.20288\n","Epoch 115/150\n","13/13 [==============================] - 3s 268ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9400\n","\n","Epoch 00115: val_loss did not improve from 0.20288\n","Epoch 116/150\n","13/13 [==============================] - 4s 276ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9500\n","\n","Epoch 00116: val_loss did not improve from 0.20288\n","Epoch 117/150\n","13/13 [==============================] - 3s 266ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.9400\n","\n","Epoch 00117: val_loss did not improve from 0.20288\n","Epoch 118/150\n","13/13 [==============================] - 3s 266ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.9400\n","\n","Epoch 00118: val_loss did not improve from 0.20288\n","Epoch 119/150\n","13/13 [==============================] - 3s 263ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9400\n","\n","Epoch 00119: val_loss did not improve from 0.20288\n","Epoch 120/150\n","13/13 [==============================] - 3s 261ms/step - loss: 8.2079e-04 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9400\n","\n","Epoch 00120: val_loss did not improve from 0.20288\n","Epoch 121/150\n","13/13 [==============================] - 3s 257ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9500\n","\n","Epoch 00121: val_loss did not improve from 0.20288\n","Epoch 122/150\n","13/13 [==============================] - 3s 264ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9500\n","\n","Epoch 00122: val_loss did not improve from 0.20288\n","Epoch 123/150\n","13/13 [==============================] - 3s 263ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9500\n","\n","Epoch 00123: val_loss did not improve from 0.20288\n","Epoch 124/150\n","13/13 [==============================] - 3s 263ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9400\n","\n","Epoch 00124: val_loss did not improve from 0.20288\n","Epoch 125/150\n","13/13 [==============================] - 3s 262ms/step - loss: 9.2162e-04 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9500\n","\n","Epoch 00125: val_loss did not improve from 0.20288\n","Epoch 126/150\n","13/13 [==============================] - 3s 268ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9400\n","\n","Epoch 00126: val_loss did not improve from 0.20288\n","Epoch 127/150\n","13/13 [==============================] - 3s 272ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2802 - val_accuracy: 0.9400\n","\n","Epoch 00127: val_loss did not improve from 0.20288\n","Epoch 128/150\n","13/13 [==============================] - 4s 277ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9400\n","\n","Epoch 00128: val_loss did not improve from 0.20288\n","Epoch 129/150\n","13/13 [==============================] - 4s 282ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9400\n","\n","Epoch 00129: val_loss did not improve from 0.20288\n","Epoch 130/150\n","13/13 [==============================] - 4s 279ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9300\n","\n","Epoch 00130: val_loss did not improve from 0.20288\n","Epoch 131/150\n","13/13 [==============================] - 4s 274ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9300\n","\n","Epoch 00131: val_loss did not improve from 0.20288\n","Epoch 132/150\n","13/13 [==============================] - 4s 275ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9400\n","\n","Epoch 00132: val_loss did not improve from 0.20288\n","Epoch 133/150\n","13/13 [==============================] - 4s 282ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9300\n","\n","Epoch 00133: val_loss did not improve from 0.20288\n","Epoch 134/150\n","13/13 [==============================] - 4s 271ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9000\n","\n","Epoch 00134: val_loss did not improve from 0.20288\n","Epoch 135/150\n","13/13 [==============================] - 3s 258ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9400\n","\n","Epoch 00135: val_loss did not improve from 0.20288\n","Epoch 136/150\n","13/13 [==============================] - 3s 266ms/step - loss: 8.7221e-04 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9400\n","\n","Epoch 00136: val_loss did not improve from 0.20288\n","Epoch 137/150\n","13/13 [==============================] - 3s 253ms/step - loss: 7.5238e-04 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9400\n","\n","Epoch 00137: val_loss did not improve from 0.20288\n","Epoch 138/150\n","13/13 [==============================] - 3s 260ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9400\n","\n","Epoch 00138: val_loss did not improve from 0.20288\n","Epoch 139/150\n","13/13 [==============================] - 3s 260ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9400\n","\n","Epoch 00139: val_loss did not improve from 0.20288\n","Epoch 140/150\n","13/13 [==============================] - 3s 260ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.9400\n","\n","Epoch 00140: val_loss did not improve from 0.20288\n","Epoch 141/150\n","13/13 [==============================] - 3s 256ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9400\n","\n","Epoch 00141: val_loss did not improve from 0.20288\n","Epoch 142/150\n","13/13 [==============================] - 3s 262ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9400\n","\n","Epoch 00142: val_loss did not improve from 0.20288\n","Epoch 143/150\n","13/13 [==============================] - 3s 261ms/step - loss: 7.2110e-04 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9400\n","\n","Epoch 00143: val_loss did not improve from 0.20288\n","Epoch 144/150\n","13/13 [==============================] - 3s 265ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9400\n","\n","Epoch 00144: val_loss did not improve from 0.20288\n","Epoch 145/150\n","13/13 [==============================] - 3s 263ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9300\n","\n","Epoch 00145: val_loss did not improve from 0.20288\n","Epoch 146/150\n","13/13 [==============================] - 4s 274ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9400\n","\n","Epoch 00146: val_loss did not improve from 0.20288\n","Epoch 147/150\n","13/13 [==============================] - 4s 279ms/step - loss: 7.1894e-04 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9400\n","\n","Epoch 00147: val_loss did not improve from 0.20288\n","Epoch 148/150\n","13/13 [==============================] - 4s 281ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9400\n","\n","Epoch 00148: val_loss did not improve from 0.20288\n","Epoch 149/150\n","13/13 [==============================] - 4s 282ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9300\n","\n","Epoch 00149: val_loss did not improve from 0.20288\n","Epoch 150/150\n","13/13 [==============================] - 4s 283ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9300\n","\n","Epoch 00150: val_loss did not improve from 0.20288\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MoERUfiR7qrY"},"source":["\n","\n","> Save History\n","\n"]},{"cell_type":"code","metadata":{"id":"5HdEYvZERZUK","executionInfo":{"status":"ok","timestamp":1628695630496,"user_tz":-420,"elapsed":9,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["with open('history_model_kr', 'wb') as file:\n","    p.dump(hist.history, file)"],"execution_count":110,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ELiWp0dF7tEy"},"source":["\n","\n","> Load History\n","\n"]},{"cell_type":"code","metadata":{"id":"MIuuqJf7RZRs","executionInfo":{"status":"ok","timestamp":1628695630497,"user_tz":-420,"elapsed":8,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["with open('history_model_kr', 'rb') as file:\n","    his = p.load(file)"],"execution_count":111,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dSLuBtO57xWz"},"source":["\n","\n","> Plot Loss ‡πÅ‡∏•‡∏∞ Validate Loss\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"-vHlFhbbRZPS","executionInfo":{"status":"ok","timestamp":1628695630497,"user_tz":-420,"elapsed":8,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"f7325ef6-0f61-4b77-896a-f898a5a417cd"},"source":["h1 = go.Scatter(y=his['loss'], \n","                    mode=\"lines\", line=dict(\n","                    width=2,\n","                    color='blue'),\n","                    name=\"loss\"\n","                   )\n","h2 = go.Scatter(y=his['val_loss'], \n","                    mode=\"lines\", line=dict(\n","                    width=2,\n","                    color='red'),\n","                    name=\"val_loss\"\n","                   )\n","\n","data = [h1,h2]\n","layout1 = go.Layout(title='Loss',\n","                   xaxis=dict(title='epochs'),\n","                   yaxis=dict(title=''))\n","fig1 = go.Figure(data = data, layout=layout1)\n","plotly.offline.iplot(fig1, filename=\"Intent Classification\")"],"execution_count":112,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"bc09143c-416e-4c4b-9c51-f9dc322592ce\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"bc09143c-416e-4c4b-9c51-f9dc322592ce\")) {\n","                    Plotly.newPlot(\n","                        'bc09143c-416e-4c4b-9c51-f9dc322592ce',\n","                        [{\"line\": {\"color\": \"blue\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"loss\", \"type\": \"scatter\", \"y\": [0.709392786026001, 0.6737344264984131, 0.6508345603942871, 0.6263372898101807, 0.5881463289260864, 0.5699416995048523, 0.5271648168563843, 0.48477092385292053, 0.43753746151924133, 0.4173527657985687, 0.3646678030490875, 0.3421440124511719, 0.296183317899704, 0.2640053331851959, 0.24174214899539948, 0.20287154614925385, 0.19086553156375885, 0.14401674270629883, 0.14223043620586395, 0.12699522078037262, 0.10261175036430359, 0.08505294471979141, 0.07781029492616653, 0.05704217031598091, 0.06236796826124191, 0.05549272894859314, 0.037009164690971375, 0.03219207748770714, 0.02901112474501133, 0.03211671859025955, 0.023725802078843117, 0.025868788361549377, 0.022898156195878983, 0.032716166228055954, 0.01461671944707632, 0.018986176699399948, 0.012760519981384277, 0.02227918617427349, 0.014522815123200417, 0.01151431817561388, 0.008685329928994179, 0.007517046760767698, 0.011578166857361794, 0.0089108319953084, 0.01432883832603693, 0.009825129061937332, 0.008637157268822193, 0.0073499600403010845, 0.00853380374610424, 0.006794372107833624, 0.005684252828359604, 0.009084406308829784, 0.010103021748363972, 0.006063966546207666, 0.00740079628303647, 0.005480458028614521, 0.004706351552158594, 0.008449114859104156, 0.005331113468855619, 0.007059833500534296, 0.006022296380251646, 0.007118621841073036, 0.004764140117913485, 0.004591731354594231, 0.004399499855935574, 0.0036338025238364935, 0.0043793837539851665, 0.005293922033160925, 0.00495443120598793, 0.0036068970803171396, 0.003226181026548147, 0.0038864121306687593, 0.003372713690623641, 0.0048890914767980576, 0.002212358871474862, 0.004958119709044695, 0.0028365980833768845, 0.002950090216472745, 0.002623294945806265, 0.004260017070919275, 0.0029770799446851015, 0.0035490503069013357, 0.0027663763612508774, 0.00540202995762229, 0.0029277533758431673, 0.004696239717304707, 0.0023303967900574207, 0.002488694852218032, 0.0036131807137280703, 0.0029927524738013744, 0.0032256264239549637, 0.0025966393295675516, 0.0037005108315497637, 0.0033732429146766663, 0.00682932510972023, 0.0023988382890820503, 0.0020107501186430454, 0.0037050610408186913, 0.002607455477118492, 0.0034940040204674006, 0.001757273101247847, 0.001684002112597227, 0.0019156974740326405, 0.0018585240468382835, 0.0016308181220665574, 0.003971049562096596, 0.002090386115014553, 0.002341688610613346, 0.0017504723509773612, 0.002180499956011772, 0.0020881968084722757, 0.0019643022678792477, 0.0023954836651682854, 0.0013748322380706668, 0.0013568472350016236, 0.0033866041339933872, 0.003211405361071229, 0.001031376188620925, 0.0010514308232814074, 0.000820790184661746, 0.0030257992912083864, 0.0020963114220649004, 0.0014564828015863895, 0.0035165678709745407, 0.0009216232574544847, 0.0019308470655232668, 0.002679725643247366, 0.002084579784423113, 0.0010406422661617398, 0.0016640452668070793, 0.0026625844184309244, 0.003565593622624874, 0.0031536242458969355, 0.0021949594374746084, 0.0021470715291798115, 0.0008722121128812432, 0.0007523795939050615, 0.002587426220998168, 0.0011494705686345696, 0.0021545004565268755, 0.0016660161782056093, 0.0026003080420196056, 0.0007211019983515143, 0.001755662146024406, 0.0010069046402350068, 0.0015437635593116283, 0.0007189352181740105, 0.0010562795214354992, 0.0015573616838082671, 0.0024048290215432644]}, {\"line\": {\"color\": \"red\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"val_loss\", \"type\": \"scatter\", \"y\": [0.6917421221733093, 0.6905834078788757, 0.6892252564430237, 0.6874391436576843, 0.6852643489837646, 0.6827253103256226, 0.6794492602348328, 0.674653947353363, 0.6689009070396423, 0.6627700328826904, 0.6553192138671875, 0.6475698947906494, 0.6377899646759033, 0.6273550987243652, 0.614800214767456, 0.6011268496513367, 0.5880608558654785, 0.5710496306419373, 0.5506855845451355, 0.5333184003829956, 0.5123435258865356, 0.4920102059841156, 0.47226452827453613, 0.45087695121765137, 0.4249440133571625, 0.40007317066192627, 0.37687230110168457, 0.35185518860816956, 0.3303762376308441, 0.312318354845047, 0.29251542687416077, 0.2735895812511444, 0.2604626715183258, 0.24720734357833862, 0.23908381164073944, 0.2231249213218689, 0.21613162755966187, 0.21610204875469208, 0.22033147513866425, 0.2133455127477646, 0.20887906849384308, 0.2054278701543808, 0.20288372039794922, 0.20685499906539917, 0.2063210904598236, 0.2159966081380844, 0.2066102921962738, 0.20863214135169983, 0.21545995771884918, 0.213359072804451, 0.21642500162124634, 0.2250722348690033, 0.2124851942062378, 0.21465082466602325, 0.25126320123672485, 0.2600115239620209, 0.24650812149047852, 0.2372547686100006, 0.23596368730068207, 0.24527965486049652, 0.24056214094161987, 0.253932923078537, 0.2553981840610504, 0.25457850098609924, 0.2565021812915802, 0.253741979598999, 0.2392958104610443, 0.24076654016971588, 0.23756279051303864, 0.22760426998138428, 0.2447766810655594, 0.2633289098739624, 0.27599403262138367, 0.2594882845878601, 0.25458618998527527, 0.24999067187309265, 0.2587736248970032, 0.26657742261886597, 0.2664366066455841, 0.26571691036224365, 0.2877388298511505, 0.274797648191452, 0.2694847881793976, 0.2448962777853012, 0.23890776932239532, 0.2604631781578064, 0.27201348543167114, 0.2652052938938141, 0.27634745836257935, 0.268324077129364, 0.24855607748031616, 0.2551625669002533, 0.25394636392593384, 0.26043689250946045, 0.2501027584075928, 0.24845929443836212, 0.26160940527915955, 0.23898227512836456, 0.24235846102237701, 0.23646026849746704, 0.2738945484161377, 0.27594467997550964, 0.27562108635902405, 0.28491199016571045, 0.28193801641464233, 0.25363436341285706, 0.24975259602069855, 0.2680302858352661, 0.2675584554672241, 0.26213911175727844, 0.25757884979248047, 0.2764285206794739, 0.24190276861190796, 0.24071425199508667, 0.2477102279663086, 0.2591191232204437, 0.25555992126464844, 0.2840428054332733, 0.2862032949924469, 0.27967679500579834, 0.2603006660938263, 0.2531934678554535, 0.25456732511520386, 0.26342785358428955, 0.2592395842075348, 0.26809436082839966, 0.2801721692085266, 0.2645259201526642, 0.26773345470428467, 0.287563294172287, 0.2530340850353241, 0.26841363310813904, 0.2504320442676544, 0.2608424425125122, 0.23343677818775177, 0.24493449926376343, 0.24731872975826263, 0.24770571291446686, 0.25710001587867737, 0.26106464862823486, 0.2745642364025116, 0.2735331654548645, 0.2576078176498413, 0.24393613636493683, 0.23863710463047028, 0.2369227260351181, 0.25266531109809875, 0.25027933716773987, 0.2690248191356659, 0.26640573143959045]}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Loss\"}, \"xaxis\": {\"title\": {\"text\": \"epochs\"}}, \"yaxis\": {\"title\": {\"text\": \"\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('bc09143c-416e-4c4b-9c51-f9dc322592ce');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"qp2TYL4c77em"},"source":["\n","\n","> Plot Accuracy ‡πÅ‡∏•‡∏∞ Validate Accuracy\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"JhB-DrdqRZNE","executionInfo":{"status":"ok","timestamp":1628695631191,"user_tz":-420,"elapsed":700,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"60f1b356-a190-4f83-dce7-b4d14bc94cac"},"source":["h1 = go.Scatter(y=his['accuracy'], \n","                    mode=\"lines\", line=dict(\n","                    width=2,\n","                    color='blue'),\n","                    name=\"acc\"\n","                   )\n","h2 = go.Scatter(y=his['val_accuracy'], \n","                    mode=\"lines\", line=dict(\n","                    width=2,\n","                    color='red'),\n","                    name=\"val_acc\"\n","                   )\n","\n","data = [h1,h2]\n","layout1 = go.Layout(title='Accuracy',\n","                   xaxis=dict(title='epochs'),\n","                   yaxis=dict(title=''))\n","fig1 = go.Figure(data = data, layout=layout1)\n","plotly.offline.iplot(fig1, filename=\"Intent Classification\")"],"execution_count":113,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"3073f3d3-cdcd-496e-b39f-770406d871ce\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"3073f3d3-cdcd-496e-b39f-770406d871ce\")) {\n","                    Plotly.newPlot(\n","                        '3073f3d3-cdcd-496e-b39f-770406d871ce',\n","                        [{\"line\": {\"color\": \"blue\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"acc\", \"type\": \"scatter\", \"y\": [0.5, 0.550000011920929, 0.6274999976158142, 0.6650000214576721, 0.7300000190734863, 0.7400000095367432, 0.7649999856948853, 0.8174999952316284, 0.8324999809265137, 0.8399999737739563, 0.8899999856948853, 0.8924999833106995, 0.9049999713897705, 0.9300000071525574, 0.9375, 0.9424999952316284, 0.9524999856948853, 0.9750000238418579, 0.9599999785423279, 0.9725000262260437, 0.9750000238418579, 0.9850000143051147, 0.9850000143051147, 0.9900000095367432, 0.987500011920929, 0.9925000071525574, 0.9975000023841858, 0.9975000023841858, 0.9975000023841858, 0.9975000023841858, 1.0, 1.0, 1.0, 0.9975000023841858, 1.0, 0.9975000023841858, 1.0, 0.9975000023841858, 1.0, 1.0, 1.0, 1.0, 0.9975000023841858, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, {\"line\": {\"color\": \"red\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"val_acc\", \"type\": \"scatter\", \"y\": [0.6000000238418579, 0.6299999952316284, 0.7900000214576721, 0.7300000190734863, 0.7799999713897705, 0.800000011920929, 0.800000011920929, 0.800000011920929, 0.8100000023841858, 0.8399999737739563, 0.8600000143051147, 0.8399999737739563, 0.8500000238418579, 0.8500000238418579, 0.8600000143051147, 0.8700000047683716, 0.8700000047683716, 0.8700000047683716, 0.8899999856948853, 0.8999999761581421, 0.8999999761581421, 0.8999999761581421, 0.8999999761581421, 0.8799999952316284, 0.8999999761581421, 0.8899999856948853, 0.8899999856948853, 0.8899999856948853, 0.9100000262260437, 0.9100000262260437, 0.9200000166893005, 0.9200000166893005, 0.8999999761581421, 0.8999999761581421, 0.9100000262260437, 0.8999999761581421, 0.9100000262260437, 0.9100000262260437, 0.9200000166893005, 0.9200000166893005, 0.9200000166893005, 0.9300000071525574, 0.9300000071525574, 0.9300000071525574, 0.9300000071525574, 0.9200000166893005, 0.9300000071525574, 0.9300000071525574, 0.9300000071525574, 0.9300000071525574, 0.9300000071525574, 0.9300000071525574, 0.9300000071525574, 0.9300000071525574, 0.9200000166893005, 0.9200000166893005, 0.9300000071525574, 0.9300000071525574, 0.9300000071525574, 0.9300000071525574, 0.9300000071525574, 0.9300000071525574, 0.9300000071525574, 0.9300000071525574, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.949999988079071, 0.949999988079071, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.9200000166893005, 0.9200000166893005, 0.9200000166893005, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.9399999976158142, 0.9399999976158142, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.9399999976158142, 0.9300000071525574, 0.9300000071525574, 0.9399999976158142, 0.949999988079071, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.9399999976158142, 0.949999988079071, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9300000071525574, 0.9300000071525574, 0.9399999976158142, 0.9300000071525574, 0.8999999761581421, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9300000071525574, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9300000071525574, 0.9300000071525574]}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Accuracy\"}, \"xaxis\": {\"title\": {\"text\": \"epochs\"}}, \"yaxis\": {\"title\": {\"text\": \"\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('3073f3d3-cdcd-496e-b39f-770406d871ce');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EAM3Ev_SUNAr","executionInfo":{"status":"ok","timestamp":1628695633592,"user_tz":-420,"elapsed":2410,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"e2c79ab4-cf35-4baf-cfc1-d811cdfeb7ca"},"source":["predict_model = load_model(filename) \n","predict_model.summary()"],"execution_count":114,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, 65, 128)           202496    \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 256)               198144    \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 64)                8256      \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 64)                256       \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 2)                 130       \n","=================================================================\n","Total params: 442,178\n","Trainable params: 442,050\n","Non-trainable params: 128\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rHf-d1xOUM97","executionInfo":{"status":"ok","timestamp":1628695633593,"user_tz":-420,"elapsed":12,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"88aa21ba-d9d4-4845-b0be-8b635a9c69e4"},"source":["score = predict_model.evaluate(val_X, val_Y, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":115,"outputs":[{"output_type":"stream","text":["Test loss: 0.20288372039794922\n","Test accuracy: 0.9300000071525574\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OAkwROtDUM7t","executionInfo":{"status":"ok","timestamp":1628695634240,"user_tz":-420,"elapsed":655,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"4c762728-0fdd-49e4-f55d-618e99de1f6a"},"source":["predicted_classes = predict_model.predict_classes(val_X)\n","predicted_classes.shape"],"execution_count":116,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning:\n","\n","`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["(100,)"]},"metadata":{"tags":[]},"execution_count":116}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OYKoyAQsUr-h","executionInfo":{"status":"ok","timestamp":1628695634241,"user_tz":-420,"elapsed":15,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"70b0c008-7371-462d-c5c7-3b5e3e3ebc2c"},"source":["y_true = np.argmax(val_Y,axis = 1)\n","print(val_Y[0])\n","print(y_true[0])"],"execution_count":117,"outputs":[{"output_type":"stream","text":["[1. 0.]\n","0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1WI6nSoW8LoP"},"source":["\n","\n","> Save Confusion Matrix\n","\n"]},{"cell_type":"code","metadata":{"id":"AE2Pi9hNUM5b","executionInfo":{"status":"ok","timestamp":1628695634242,"user_tz":-420,"elapsed":12,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["cm = confusion_matrix(y_true, predicted_classes)\n","np.savetxt(\"confusion_matrix_kr.csv\", cm, delimiter=\",\")"],"execution_count":118,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qQ5Bzdy58OCd"},"source":["\n","\n","> Plot Confusion Matrix\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":814},"id":"9T-txdKZVS3j","executionInfo":{"status":"ok","timestamp":1628695634242,"user_tz":-420,"elapsed":12,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"64ab407c-e360-434c-8dbf-de445f4335b6"},"source":["import seaborn as sn\n","import matplotlib.pyplot as plt\n","\n","df_cm = pd.DataFrame(cm, range(2), range(2))\n","plt.figure(figsize=(20,14))\n","sn.set(font_scale=1.2) # for label size\n","sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 14}, fmt='g') # for num predict size\n","\n","plt.show()"],"execution_count":119,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1440x1008 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"PUkLlykcVTzp","executionInfo":{"status":"ok","timestamp":1628695634243,"user_tz":-420,"elapsed":12,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["label_dict = output_tokenizer.word_index"],"execution_count":120,"outputs":[]},{"cell_type":"code","metadata":{"id":"9lZgFS6sXY8i","executionInfo":{"status":"ok","timestamp":1628695634243,"user_tz":-420,"elapsed":12,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["label = [key for key, value in label_dict.items()]"],"execution_count":121,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zmgbT_J38Sww"},"source":["\n","\n","> ‡πÅ‡∏™‡∏î‡∏á Precision, Recall, F1-score\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"og-45MVEXZnK","executionInfo":{"status":"ok","timestamp":1628695634244,"user_tz":-420,"elapsed":12,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"366b8999-3cf5-4328-dc4f-7e414ec963fd"},"source":["print(classification_report(y_true, predicted_classes, target_names=label, digits=4))"],"execution_count":122,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         neg     0.8909    0.9800    0.9333        50\n","         pos     0.9778    0.8800    0.9263        50\n","\n","    accuracy                         0.9300       100\n","   macro avg     0.9343    0.9300    0.9298       100\n","weighted avg     0.9343    0.9300    0.9298       100\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8edrfgZ2Xg3z","executionInfo":{"status":"ok","timestamp":1628695634244,"user_tz":-420,"elapsed":9,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":[""],"execution_count":122,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4NFKlka986eX"},"source":["**Word2Vec Transfer Learning ‡∏î‡πâ‡∏ß‡∏¢ gensim**\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ibFmUs_a8kxV","executionInfo":{"status":"ok","timestamp":1628695637208,"user_tz":-420,"elapsed":2973,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"a65c8e94-f831-45c0-a855-1b4e81867fc1"},"source":["pip install --upgrade gensim"],"execution_count":123,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.0.1)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fmUljhtJ9MmV"},"source":["> Import Package ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ W2V Tranfer Learning ‡∏î‡πâ‡∏ß‡∏¢ gensim"]},{"cell_type":"code","metadata":{"id":"DHXLi2dp-Ptt","executionInfo":{"status":"ok","timestamp":1628695637209,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["from gensim.models import Word2Vec"],"execution_count":124,"outputs":[]},{"cell_type":"code","metadata":{"id":"AAxYvHuU-SzS","executionInfo":{"status":"ok","timestamp":1628695637209,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["dimension = 128"],"execution_count":125,"outputs":[]},{"cell_type":"code","metadata":{"id":"KxQ4c_Dj-SyA","executionInfo":{"status":"ok","timestamp":1628695637210,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["sentences = [st.split() for st in cleaned_words]"],"execution_count":126,"outputs":[]},{"cell_type":"code","metadata":{"id":"fuqfWGwk-YyY","executionInfo":{"status":"ok","timestamp":1628695664630,"user_tz":-420,"elapsed":27424,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["w2v_model = Word2Vec(sentences, min_count=1, vector_size=dimension, workers=6, sg=1, epochs=1000)"],"execution_count":127,"outputs":[]},{"cell_type":"code","metadata":{"id":"MkFgiGnl-b9c","executionInfo":{"status":"ok","timestamp":1628695664630,"user_tz":-420,"elapsed":20,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["w2v_model.save('w2v_model_gs.bin')"],"execution_count":128,"outputs":[]},{"cell_type":"code","metadata":{"id":"qOSaVXc8-etz","executionInfo":{"status":"ok","timestamp":1628695664631,"user_tz":-420,"elapsed":20,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["new_model = Word2Vec.load('w2v_model_gs.bin')"],"execution_count":129,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qBo9gKYfA8X_"},"source":["> ‡∏ô‡∏¥‡∏¢‡∏≤‡∏° Model ‡πÅ‡∏ö‡∏ö Gensim\n","\n","*   ‡∏Å‡∏≥‡∏´‡∏ô‡∏î learning_rate=0.0001\n","*   ‡∏Å‡∏≥‡∏´‡∏ô‡∏î dropout = 0.3\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OP_YxrNg-ls1","executionInfo":{"status":"ok","timestamp":1628695664631,"user_tz":-420,"elapsed":20,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"8bbbcf03-da70-4d87-b638-c728525bded1"},"source":["embedding_matrix = np.zeros((vocab_size, dimension))\n","\n","for word, i in train_word_tokenizer.word_index.items():\n","    if word in new_model.wv.key_to_index:\n","        embedding_vector = new_model.wv[word]\n","        embedding_matrix[i] = embedding_vector\n","adam = Adam(learning_rate=0.0001)\n","\n","def create_model(vocab_size, max_length):\n","  model = Sequential()\n","  \n","  model.add(Embedding(vocab_size, dimension, input_length = max_length, trainable = False, weights=[embedding_matrix]))\n","  model.add(Bidirectional(GRU(128, activation = \"relu\")))\n","  model.add(Dense(128, activation = \"relu\"))\n","  model.add(Dropout(0.3))\n","  model.add(Dense(64, activation = \"relu\"))\n","  model.add(Dropout(0.3))\n","  model.add(BatchNormalization())\n","  model.add(Dense(num_classes, activation = \"softmax\"))\n","  \n","  return model\n","  \n","model = create_model(vocab_size, max_length)"],"execution_count":130,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7UmAm3GE-pSr","executionInfo":{"status":"ok","timestamp":1628695664632,"user_tz":-420,"elapsed":15,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"c3d4dabd-a86b-46a8-d412-f80da705083e"},"source":["model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n","model.summary()"],"execution_count":131,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, 65, 128)           202496    \n","_________________________________________________________________\n","bidirectional_3 (Bidirection (None, 256)               198144    \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 64)                8256      \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 64)                256       \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 2)                 130       \n","=================================================================\n","Total params: 442,178\n","Trainable params: 239,554\n","Non-trainable params: 202,624\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4wjYf5Z0BGLX"},"source":["\n","> ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏∏‡∏î Check Point ‡πÄ‡∏û‡∏∑‡πà‡∏≠ Save Model\n","\n"]},{"cell_type":"code","metadata":{"id":"f_BM8OWu-qv3","executionInfo":{"status":"ok","timestamp":1628695664632,"user_tz":-420,"elapsed":11,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["filename = 'model.h5_gs'\n","checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"],"execution_count":132,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uDeByh2sBI8c"},"source":["\n","\n","> Train Model\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V3Ao9XuN-weN","executionInfo":{"status":"ok","timestamp":1628696622983,"user_tz":-420,"elapsed":958361,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"c00e0e8d-c80a-41bb-83b6-613ec726d5d5"},"source":["hist = model.fit(train_X, train_Y, epochs = EPOCHS, batch_size = BS, validation_data = (val_X, val_Y), callbacks = [checkpoint])"],"execution_count":133,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","13/13 [==============================] - 6s 270ms/step - loss: 0.9967 - accuracy: 0.5075 - val_loss: 0.6999 - val_accuracy: 0.4500\n","\n","Epoch 00001: val_loss improved from inf to 0.69992, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 2/150\n","13/13 [==============================] - 3s 245ms/step - loss: 0.8949 - accuracy: 0.5200 - val_loss: 0.6884 - val_accuracy: 0.5700\n","\n","Epoch 00002: val_loss improved from 0.69992 to 0.68844, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 3/150\n","13/13 [==============================] - 3s 235ms/step - loss: 0.7848 - accuracy: 0.5850 - val_loss: 0.6777 - val_accuracy: 0.6000\n","\n","Epoch 00003: val_loss improved from 0.68844 to 0.67773, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 4/150\n","13/13 [==============================] - 3s 242ms/step - loss: 0.6879 - accuracy: 0.6325 - val_loss: 0.6667 - val_accuracy: 0.6900\n","\n","Epoch 00004: val_loss improved from 0.67773 to 0.66667, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 5/150\n","13/13 [==============================] - 3s 249ms/step - loss: 0.6369 - accuracy: 0.6650 - val_loss: 0.6545 - val_accuracy: 0.7500\n","\n","Epoch 00005: val_loss improved from 0.66667 to 0.65455, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 6/150\n","13/13 [==============================] - 3s 260ms/step - loss: 0.6275 - accuracy: 0.7025 - val_loss: 0.6409 - val_accuracy: 0.8300\n","\n","Epoch 00006: val_loss improved from 0.65455 to 0.64092, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 7/150\n","13/13 [==============================] - 3s 249ms/step - loss: 0.6002 - accuracy: 0.6775 - val_loss: 0.6288 - val_accuracy: 0.8300\n","\n","Epoch 00007: val_loss improved from 0.64092 to 0.62878, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 8/150\n","13/13 [==============================] - 3s 253ms/step - loss: 0.5887 - accuracy: 0.7150 - val_loss: 0.6156 - val_accuracy: 0.8500\n","\n","Epoch 00008: val_loss improved from 0.62878 to 0.61558, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 9/150\n","13/13 [==============================] - 3s 248ms/step - loss: 0.4834 - accuracy: 0.7700 - val_loss: 0.6010 - val_accuracy: 0.8400\n","\n","Epoch 00009: val_loss improved from 0.61558 to 0.60103, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 10/150\n","13/13 [==============================] - 3s 242ms/step - loss: 0.5181 - accuracy: 0.7575 - val_loss: 0.5867 - val_accuracy: 0.8600\n","\n","Epoch 00010: val_loss improved from 0.60103 to 0.58668, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 11/150\n","13/13 [==============================] - 3s 239ms/step - loss: 0.4145 - accuracy: 0.8150 - val_loss: 0.5705 - val_accuracy: 0.8800\n","\n","Epoch 00011: val_loss improved from 0.58668 to 0.57054, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 12/150\n","13/13 [==============================] - 3s 246ms/step - loss: 0.3893 - accuracy: 0.8200 - val_loss: 0.5538 - val_accuracy: 0.8800\n","\n","Epoch 00012: val_loss improved from 0.57054 to 0.55379, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 13/150\n","13/13 [==============================] - 3s 248ms/step - loss: 0.4203 - accuracy: 0.8025 - val_loss: 0.5383 - val_accuracy: 0.8800\n","\n","Epoch 00013: val_loss improved from 0.55379 to 0.53831, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 14/150\n","13/13 [==============================] - 3s 258ms/step - loss: 0.3980 - accuracy: 0.8175 - val_loss: 0.5216 - val_accuracy: 0.8800\n","\n","Epoch 00014: val_loss improved from 0.53831 to 0.52164, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 15/150\n","13/13 [==============================] - 3s 258ms/step - loss: 0.3742 - accuracy: 0.8325 - val_loss: 0.5076 - val_accuracy: 0.8900\n","\n","Epoch 00015: val_loss improved from 0.52164 to 0.50764, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 16/150\n","13/13 [==============================] - 3s 257ms/step - loss: 0.3697 - accuracy: 0.8425 - val_loss: 0.4911 - val_accuracy: 0.8800\n","\n","Epoch 00016: val_loss improved from 0.50764 to 0.49108, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 17/150\n","13/13 [==============================] - 3s 249ms/step - loss: 0.3774 - accuracy: 0.8250 - val_loss: 0.4732 - val_accuracy: 0.8800\n","\n","Epoch 00017: val_loss improved from 0.49108 to 0.47323, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 18/150\n","13/13 [==============================] - 3s 251ms/step - loss: 0.3576 - accuracy: 0.8300 - val_loss: 0.4565 - val_accuracy: 0.8800\n","\n","Epoch 00018: val_loss improved from 0.47323 to 0.45654, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 19/150\n","13/13 [==============================] - 3s 243ms/step - loss: 0.3722 - accuracy: 0.8425 - val_loss: 0.4425 - val_accuracy: 0.8800\n","\n","Epoch 00019: val_loss improved from 0.45654 to 0.44253, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 20/150\n","13/13 [==============================] - 3s 239ms/step - loss: 0.3545 - accuracy: 0.8350 - val_loss: 0.4312 - val_accuracy: 0.8800\n","\n","Epoch 00020: val_loss improved from 0.44253 to 0.43121, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 21/150\n","13/13 [==============================] - 3s 245ms/step - loss: 0.3301 - accuracy: 0.8725 - val_loss: 0.4173 - val_accuracy: 0.8700\n","\n","Epoch 00021: val_loss improved from 0.43121 to 0.41730, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 22/150\n","13/13 [==============================] - 3s 259ms/step - loss: 0.2865 - accuracy: 0.8825 - val_loss: 0.3993 - val_accuracy: 0.8700\n","\n","Epoch 00022: val_loss improved from 0.41730 to 0.39929, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 23/150\n","13/13 [==============================] - 4s 267ms/step - loss: 0.3159 - accuracy: 0.8775 - val_loss: 0.3826 - val_accuracy: 0.8700\n","\n","Epoch 00023: val_loss improved from 0.39929 to 0.38264, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 24/150\n","13/13 [==============================] - 3s 265ms/step - loss: 0.2957 - accuracy: 0.8800 - val_loss: 0.3696 - val_accuracy: 0.8800\n","\n","Epoch 00024: val_loss improved from 0.38264 to 0.36963, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 25/150\n","13/13 [==============================] - 3s 242ms/step - loss: 0.2570 - accuracy: 0.9050 - val_loss: 0.3534 - val_accuracy: 0.8800\n","\n","Epoch 00025: val_loss improved from 0.36963 to 0.35343, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 26/150\n","13/13 [==============================] - 3s 248ms/step - loss: 0.2340 - accuracy: 0.9100 - val_loss: 0.3387 - val_accuracy: 0.8800\n","\n","Epoch 00026: val_loss improved from 0.35343 to 0.33873, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 27/150\n","13/13 [==============================] - 3s 245ms/step - loss: 0.2529 - accuracy: 0.9025 - val_loss: 0.3237 - val_accuracy: 0.8800\n","\n","Epoch 00027: val_loss improved from 0.33873 to 0.32365, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 28/150\n","13/13 [==============================] - 3s 249ms/step - loss: 0.2478 - accuracy: 0.8900 - val_loss: 0.3076 - val_accuracy: 0.8800\n","\n","Epoch 00028: val_loss improved from 0.32365 to 0.30756, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 29/150\n","13/13 [==============================] - 3s 240ms/step - loss: 0.2752 - accuracy: 0.8875 - val_loss: 0.2949 - val_accuracy: 0.8900\n","\n","Epoch 00029: val_loss improved from 0.30756 to 0.29488, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 30/150\n","13/13 [==============================] - 3s 259ms/step - loss: 0.2175 - accuracy: 0.9025 - val_loss: 0.2838 - val_accuracy: 0.8900\n","\n","Epoch 00030: val_loss improved from 0.29488 to 0.28376, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 31/150\n","13/13 [==============================] - 3s 258ms/step - loss: 0.2060 - accuracy: 0.9250 - val_loss: 0.2725 - val_accuracy: 0.8800\n","\n","Epoch 00031: val_loss improved from 0.28376 to 0.27255, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 32/150\n","13/13 [==============================] - 3s 272ms/step - loss: 0.2401 - accuracy: 0.9175 - val_loss: 0.2618 - val_accuracy: 0.8800\n","\n","Epoch 00032: val_loss improved from 0.27255 to 0.26180, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 33/150\n","13/13 [==============================] - 3s 247ms/step - loss: 0.2316 - accuracy: 0.9200 - val_loss: 0.2539 - val_accuracy: 0.8900\n","\n","Epoch 00033: val_loss improved from 0.26180 to 0.25393, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 34/150\n","13/13 [==============================] - 3s 262ms/step - loss: 0.2242 - accuracy: 0.9100 - val_loss: 0.2491 - val_accuracy: 0.8900\n","\n","Epoch 00034: val_loss improved from 0.25393 to 0.24915, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 35/150\n","13/13 [==============================] - 3s 253ms/step - loss: 0.1944 - accuracy: 0.9225 - val_loss: 0.2462 - val_accuracy: 0.8800\n","\n","Epoch 00035: val_loss improved from 0.24915 to 0.24616, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 36/150\n","13/13 [==============================] - 4s 271ms/step - loss: 0.2211 - accuracy: 0.9100 - val_loss: 0.2404 - val_accuracy: 0.8900\n","\n","Epoch 00036: val_loss improved from 0.24616 to 0.24040, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 37/150\n","13/13 [==============================] - 3s 252ms/step - loss: 0.1816 - accuracy: 0.9375 - val_loss: 0.2349 - val_accuracy: 0.8800\n","\n","Epoch 00037: val_loss improved from 0.24040 to 0.23487, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 38/150\n","13/13 [==============================] - 3s 249ms/step - loss: 0.2098 - accuracy: 0.9125 - val_loss: 0.2279 - val_accuracy: 0.8800\n","\n","Epoch 00038: val_loss improved from 0.23487 to 0.22792, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 39/150\n","13/13 [==============================] - 3s 241ms/step - loss: 0.1579 - accuracy: 0.9550 - val_loss: 0.2220 - val_accuracy: 0.8900\n","\n","Epoch 00039: val_loss improved from 0.22792 to 0.22197, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 40/150\n","13/13 [==============================] - 3s 247ms/step - loss: 0.1435 - accuracy: 0.9375 - val_loss: 0.2155 - val_accuracy: 0.9000\n","\n","Epoch 00040: val_loss improved from 0.22197 to 0.21548, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 41/150\n","13/13 [==============================] - 3s 238ms/step - loss: 0.1581 - accuracy: 0.9425 - val_loss: 0.2099 - val_accuracy: 0.9000\n","\n","Epoch 00041: val_loss improved from 0.21548 to 0.20988, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 42/150\n","13/13 [==============================] - 4s 270ms/step - loss: 0.2092 - accuracy: 0.9200 - val_loss: 0.2075 - val_accuracy: 0.9000\n","\n","Epoch 00042: val_loss improved from 0.20988 to 0.20752, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 43/150\n","13/13 [==============================] - 3s 256ms/step - loss: 0.2193 - accuracy: 0.9125 - val_loss: 0.2052 - val_accuracy: 0.9000\n","\n","Epoch 00043: val_loss improved from 0.20752 to 0.20516, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 44/150\n","13/13 [==============================] - 3s 262ms/step - loss: 0.1509 - accuracy: 0.9500 - val_loss: 0.2007 - val_accuracy: 0.9100\n","\n","Epoch 00044: val_loss improved from 0.20516 to 0.20073, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 45/150\n","13/13 [==============================] - 3s 248ms/step - loss: 0.1544 - accuracy: 0.9375 - val_loss: 0.1986 - val_accuracy: 0.9100\n","\n","Epoch 00045: val_loss improved from 0.20073 to 0.19859, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 46/150\n","13/13 [==============================] - 3s 241ms/step - loss: 0.1442 - accuracy: 0.9450 - val_loss: 0.1977 - val_accuracy: 0.9100\n","\n","Epoch 00046: val_loss improved from 0.19859 to 0.19774, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 47/150\n","13/13 [==============================] - 3s 235ms/step - loss: 0.1714 - accuracy: 0.9250 - val_loss: 0.1954 - val_accuracy: 0.9100\n","\n","Epoch 00047: val_loss improved from 0.19774 to 0.19538, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 48/150\n","13/13 [==============================] - 3s 240ms/step - loss: 0.1400 - accuracy: 0.9550 - val_loss: 0.1936 - val_accuracy: 0.9100\n","\n","Epoch 00048: val_loss improved from 0.19538 to 0.19364, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 49/150\n","13/13 [==============================] - 3s 245ms/step - loss: 0.1160 - accuracy: 0.9525 - val_loss: 0.1923 - val_accuracy: 0.9100\n","\n","Epoch 00049: val_loss improved from 0.19364 to 0.19231, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 50/150\n","13/13 [==============================] - 3s 262ms/step - loss: 0.1413 - accuracy: 0.9575 - val_loss: 0.1895 - val_accuracy: 0.9100\n","\n","Epoch 00050: val_loss improved from 0.19231 to 0.18950, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 51/150\n","13/13 [==============================] - 3s 262ms/step - loss: 0.1409 - accuracy: 0.9425 - val_loss: 0.1858 - val_accuracy: 0.9100\n","\n","Epoch 00051: val_loss improved from 0.18950 to 0.18580, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 52/150\n","13/13 [==============================] - 3s 267ms/step - loss: 0.1206 - accuracy: 0.9675 - val_loss: 0.1831 - val_accuracy: 0.9100\n","\n","Epoch 00052: val_loss improved from 0.18580 to 0.18305, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 53/150\n","13/13 [==============================] - 3s 246ms/step - loss: 0.1123 - accuracy: 0.9600 - val_loss: 0.1802 - val_accuracy: 0.9100\n","\n","Epoch 00053: val_loss improved from 0.18305 to 0.18021, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 54/150\n","13/13 [==============================] - 3s 245ms/step - loss: 0.1265 - accuracy: 0.9550 - val_loss: 0.1783 - val_accuracy: 0.9200\n","\n","Epoch 00054: val_loss improved from 0.18021 to 0.17828, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 55/150\n","13/13 [==============================] - 3s 248ms/step - loss: 0.1178 - accuracy: 0.9600 - val_loss: 0.1793 - val_accuracy: 0.9400\n","\n","Epoch 00055: val_loss did not improve from 0.17828\n","Epoch 56/150\n","13/13 [==============================] - 3s 250ms/step - loss: 0.1139 - accuracy: 0.9675 - val_loss: 0.1794 - val_accuracy: 0.9400\n","\n","Epoch 00056: val_loss did not improve from 0.17828\n","Epoch 57/150\n","13/13 [==============================] - 3s 246ms/step - loss: 0.1078 - accuracy: 0.9600 - val_loss: 0.1776 - val_accuracy: 0.9400\n","\n","Epoch 00057: val_loss improved from 0.17828 to 0.17755, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 58/150\n","13/13 [==============================] - 3s 238ms/step - loss: 0.0932 - accuracy: 0.9650 - val_loss: 0.1768 - val_accuracy: 0.9400\n","\n","Epoch 00058: val_loss improved from 0.17755 to 0.17676, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 59/150\n","13/13 [==============================] - 3s 253ms/step - loss: 0.0834 - accuracy: 0.9725 - val_loss: 0.1741 - val_accuracy: 0.9400\n","\n","Epoch 00059: val_loss improved from 0.17676 to 0.17410, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 60/150\n","13/13 [==============================] - 3s 259ms/step - loss: 0.0942 - accuracy: 0.9725 - val_loss: 0.1751 - val_accuracy: 0.9400\n","\n","Epoch 00060: val_loss did not improve from 0.17410\n","Epoch 61/150\n","13/13 [==============================] - 3s 256ms/step - loss: 0.0772 - accuracy: 0.9800 - val_loss: 0.1762 - val_accuracy: 0.9400\n","\n","Epoch 00061: val_loss did not improve from 0.17410\n","Epoch 62/150\n","13/13 [==============================] - 3s 254ms/step - loss: 0.1235 - accuracy: 0.9475 - val_loss: 0.1716 - val_accuracy: 0.9400\n","\n","Epoch 00062: val_loss improved from 0.17410 to 0.17163, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 63/150\n","13/13 [==============================] - 3s 245ms/step - loss: 0.0810 - accuracy: 0.9675 - val_loss: 0.1703 - val_accuracy: 0.9400\n","\n","Epoch 00063: val_loss improved from 0.17163 to 0.17031, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 64/150\n","13/13 [==============================] - 3s 238ms/step - loss: 0.0639 - accuracy: 0.9875 - val_loss: 0.1644 - val_accuracy: 0.9400\n","\n","Epoch 00064: val_loss improved from 0.17031 to 0.16441, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 65/150\n","13/13 [==============================] - 3s 240ms/step - loss: 0.0738 - accuracy: 0.9850 - val_loss: 0.1604 - val_accuracy: 0.9400\n","\n","Epoch 00065: val_loss improved from 0.16441 to 0.16036, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 66/150\n","13/13 [==============================] - 3s 246ms/step - loss: 0.0838 - accuracy: 0.9725 - val_loss: 0.1606 - val_accuracy: 0.9400\n","\n","Epoch 00066: val_loss did not improve from 0.16036\n","Epoch 67/150\n","13/13 [==============================] - 3s 243ms/step - loss: 0.0607 - accuracy: 0.9900 - val_loss: 0.1611 - val_accuracy: 0.9400\n","\n","Epoch 00067: val_loss did not improve from 0.16036\n","Epoch 68/150\n","13/13 [==============================] - 3s 238ms/step - loss: 0.0818 - accuracy: 0.9800 - val_loss: 0.1575 - val_accuracy: 0.9400\n","\n","Epoch 00068: val_loss improved from 0.16036 to 0.15747, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 69/150\n","13/13 [==============================] - 3s 242ms/step - loss: 0.0872 - accuracy: 0.9725 - val_loss: 0.1554 - val_accuracy: 0.9400\n","\n","Epoch 00069: val_loss improved from 0.15747 to 0.15538, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 70/150\n","13/13 [==============================] - 3s 257ms/step - loss: 0.0701 - accuracy: 0.9775 - val_loss: 0.1542 - val_accuracy: 0.9400\n","\n","Epoch 00070: val_loss improved from 0.15538 to 0.15425, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 71/150\n","13/13 [==============================] - 3s 271ms/step - loss: 0.0849 - accuracy: 0.9725 - val_loss: 0.1536 - val_accuracy: 0.9400\n","\n","Epoch 00071: val_loss improved from 0.15425 to 0.15364, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 72/150\n","13/13 [==============================] - 3s 248ms/step - loss: 0.0563 - accuracy: 0.9850 - val_loss: 0.1519 - val_accuracy: 0.9400\n","\n","Epoch 00072: val_loss improved from 0.15364 to 0.15194, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 73/150\n","13/13 [==============================] - 3s 239ms/step - loss: 0.0590 - accuracy: 0.9875 - val_loss: 0.1494 - val_accuracy: 0.9400\n","\n","Epoch 00073: val_loss improved from 0.15194 to 0.14938, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 74/150\n","13/13 [==============================] - 4s 270ms/step - loss: 0.0637 - accuracy: 0.9775 - val_loss: 0.1480 - val_accuracy: 0.9400\n","\n","Epoch 00074: val_loss improved from 0.14938 to 0.14804, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 75/150\n","13/13 [==============================] - 4s 274ms/step - loss: 0.0425 - accuracy: 0.9950 - val_loss: 0.1475 - val_accuracy: 0.9400\n","\n","Epoch 00075: val_loss improved from 0.14804 to 0.14749, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 76/150\n","13/13 [==============================] - 3s 261ms/step - loss: 0.0559 - accuracy: 0.9850 - val_loss: 0.1482 - val_accuracy: 0.9400\n","\n","Epoch 00076: val_loss did not improve from 0.14749\n","Epoch 77/150\n","13/13 [==============================] - 3s 256ms/step - loss: 0.0639 - accuracy: 0.9775 - val_loss: 0.1475 - val_accuracy: 0.9400\n","\n","Epoch 00077: val_loss did not improve from 0.14749\n","Epoch 78/150\n","13/13 [==============================] - 3s 261ms/step - loss: 0.0503 - accuracy: 0.9825 - val_loss: 0.1438 - val_accuracy: 0.9400\n","\n","Epoch 00078: val_loss improved from 0.14749 to 0.14382, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 79/150\n","13/13 [==============================] - 3s 255ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.1447 - val_accuracy: 0.9400\n","\n","Epoch 00079: val_loss did not improve from 0.14382\n","Epoch 80/150\n","13/13 [==============================] - 3s 254ms/step - loss: 0.0443 - accuracy: 0.9850 - val_loss: 0.1463 - val_accuracy: 0.9400\n","\n","Epoch 00080: val_loss did not improve from 0.14382\n","Epoch 81/150\n","13/13 [==============================] - 3s 256ms/step - loss: 0.0526 - accuracy: 0.9825 - val_loss: 0.1468 - val_accuracy: 0.9400\n","\n","Epoch 00081: val_loss did not improve from 0.14382\n","Epoch 82/150\n","13/13 [==============================] - 3s 248ms/step - loss: 0.0548 - accuracy: 0.9850 - val_loss: 0.1442 - val_accuracy: 0.9400\n","\n","Epoch 00082: val_loss did not improve from 0.14382\n","Epoch 83/150\n","13/13 [==============================] - 3s 246ms/step - loss: 0.0485 - accuracy: 0.9800 - val_loss: 0.1410 - val_accuracy: 0.9400\n","\n","Epoch 00083: val_loss improved from 0.14382 to 0.14104, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 84/150\n","13/13 [==============================] - 3s 250ms/step - loss: 0.0465 - accuracy: 0.9900 - val_loss: 0.1391 - val_accuracy: 0.9400\n","\n","Epoch 00084: val_loss improved from 0.14104 to 0.13906, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 85/150\n","13/13 [==============================] - 3s 257ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9400\n","\n","Epoch 00085: val_loss did not improve from 0.13906\n","Epoch 86/150\n","13/13 [==============================] - 3s 264ms/step - loss: 0.0461 - accuracy: 0.9800 - val_loss: 0.1447 - val_accuracy: 0.9400\n","\n","Epoch 00086: val_loss did not improve from 0.13906\n","Epoch 87/150\n","13/13 [==============================] - 3s 255ms/step - loss: 0.0383 - accuracy: 0.9850 - val_loss: 0.1430 - val_accuracy: 0.9400\n","\n","Epoch 00087: val_loss did not improve from 0.13906\n","Epoch 88/150\n","13/13 [==============================] - 3s 257ms/step - loss: 0.0418 - accuracy: 0.9875 - val_loss: 0.1382 - val_accuracy: 0.9400\n","\n","Epoch 00088: val_loss improved from 0.13906 to 0.13821, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 89/150\n","13/13 [==============================] - 3s 261ms/step - loss: 0.0398 - accuracy: 0.9900 - val_loss: 0.1382 - val_accuracy: 0.9400\n","\n","Epoch 00089: val_loss improved from 0.13821 to 0.13820, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 90/150\n","13/13 [==============================] - 3s 242ms/step - loss: 0.0373 - accuracy: 0.9950 - val_loss: 0.1378 - val_accuracy: 0.9400\n","\n","Epoch 00090: val_loss improved from 0.13820 to 0.13775, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 91/150\n","13/13 [==============================] - 3s 243ms/step - loss: 0.0487 - accuracy: 0.9825 - val_loss: 0.1428 - val_accuracy: 0.9400\n","\n","Epoch 00091: val_loss did not improve from 0.13775\n","Epoch 92/150\n","13/13 [==============================] - 3s 242ms/step - loss: 0.0387 - accuracy: 0.9900 - val_loss: 0.1434 - val_accuracy: 0.9400\n","\n","Epoch 00092: val_loss did not improve from 0.13775\n","Epoch 93/150\n","13/13 [==============================] - 3s 245ms/step - loss: 0.0508 - accuracy: 0.9850 - val_loss: 0.1415 - val_accuracy: 0.9400\n","\n","Epoch 00093: val_loss did not improve from 0.13775\n","Epoch 94/150\n","13/13 [==============================] - 3s 235ms/step - loss: 0.0310 - accuracy: 0.9950 - val_loss: 0.1362 - val_accuracy: 0.9400\n","\n","Epoch 00094: val_loss improved from 0.13775 to 0.13623, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 95/150\n","13/13 [==============================] - 3s 247ms/step - loss: 0.0294 - accuracy: 0.9975 - val_loss: 0.1326 - val_accuracy: 0.9400\n","\n","Epoch 00095: val_loss improved from 0.13623 to 0.13265, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 96/150\n","13/13 [==============================] - 3s 238ms/step - loss: 0.0349 - accuracy: 0.9950 - val_loss: 0.1308 - val_accuracy: 0.9400\n","\n","Epoch 00096: val_loss improved from 0.13265 to 0.13076, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 97/150\n","13/13 [==============================] - 3s 252ms/step - loss: 0.0360 - accuracy: 0.9925 - val_loss: 0.1312 - val_accuracy: 0.9400\n","\n","Epoch 00097: val_loss did not improve from 0.13076\n","Epoch 98/150\n","13/13 [==============================] - 3s 265ms/step - loss: 0.0282 - accuracy: 0.9950 - val_loss: 0.1293 - val_accuracy: 0.9400\n","\n","Epoch 00098: val_loss improved from 0.13076 to 0.12925, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 99/150\n","13/13 [==============================] - 3s 260ms/step - loss: 0.0300 - accuracy: 0.9950 - val_loss: 0.1273 - val_accuracy: 0.9400\n","\n","Epoch 00099: val_loss improved from 0.12925 to 0.12726, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 100/150\n","13/13 [==============================] - 3s 244ms/step - loss: 0.0300 - accuracy: 0.9925 - val_loss: 0.1301 - val_accuracy: 0.9400\n","\n","Epoch 00100: val_loss did not improve from 0.12726\n","Epoch 101/150\n","13/13 [==============================] - 3s 239ms/step - loss: 0.0310 - accuracy: 0.9975 - val_loss: 0.1321 - val_accuracy: 0.9400\n","\n","Epoch 00101: val_loss did not improve from 0.12726\n","Epoch 102/150\n","13/13 [==============================] - 3s 240ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.1289 - val_accuracy: 0.9400\n","\n","Epoch 00102: val_loss did not improve from 0.12726\n","Epoch 103/150\n","13/13 [==============================] - 3s 244ms/step - loss: 0.0215 - accuracy: 0.9975 - val_loss: 0.1291 - val_accuracy: 0.9400\n","\n","Epoch 00103: val_loss did not improve from 0.12726\n","Epoch 104/150\n","13/13 [==============================] - 3s 249ms/step - loss: 0.0276 - accuracy: 0.9975 - val_loss: 0.1263 - val_accuracy: 0.9400\n","\n","Epoch 00104: val_loss improved from 0.12726 to 0.12631, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 105/150\n","13/13 [==============================] - 3s 240ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9400\n","\n","Epoch 00105: val_loss improved from 0.12631 to 0.12394, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 106/150\n","13/13 [==============================] - 3s 249ms/step - loss: 0.0500 - accuracy: 0.9825 - val_loss: 0.1304 - val_accuracy: 0.9500\n","\n","Epoch 00106: val_loss did not improve from 0.12394\n","Epoch 107/150\n","13/13 [==============================] - 3s 253ms/step - loss: 0.0276 - accuracy: 0.9950 - val_loss: 0.1303 - val_accuracy: 0.9500\n","\n","Epoch 00107: val_loss did not improve from 0.12394\n","Epoch 108/150\n","13/13 [==============================] - 3s 242ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9500\n","\n","Epoch 00108: val_loss did not improve from 0.12394\n","Epoch 109/150\n","13/13 [==============================] - 3s 245ms/step - loss: 0.0298 - accuracy: 0.9925 - val_loss: 0.1247 - val_accuracy: 0.9500\n","\n","Epoch 00109: val_loss did not improve from 0.12394\n","Epoch 110/150\n","13/13 [==============================] - 3s 250ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9600\n","\n","Epoch 00110: val_loss improved from 0.12394 to 0.12210, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 111/150\n","13/13 [==============================] - 3s 265ms/step - loss: 0.0261 - accuracy: 0.9975 - val_loss: 0.1199 - val_accuracy: 0.9700\n","\n","Epoch 00111: val_loss improved from 0.12210 to 0.11994, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 112/150\n","13/13 [==============================] - 4s 270ms/step - loss: 0.0367 - accuracy: 0.9900 - val_loss: 0.1172 - val_accuracy: 0.9700\n","\n","Epoch 00112: val_loss improved from 0.11994 to 0.11720, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 113/150\n","13/13 [==============================] - 3s 242ms/step - loss: 0.0359 - accuracy: 0.9875 - val_loss: 0.1134 - val_accuracy: 0.9600\n","\n","Epoch 00113: val_loss improved from 0.11720 to 0.11342, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 114/150\n","13/13 [==============================] - 3s 248ms/step - loss: 0.0243 - accuracy: 0.9950 - val_loss: 0.1125 - val_accuracy: 0.9600\n","\n","Epoch 00114: val_loss improved from 0.11342 to 0.11250, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 115/150\n","13/13 [==============================] - 3s 241ms/step - loss: 0.0244 - accuracy: 0.9950 - val_loss: 0.1118 - val_accuracy: 0.9600\n","\n","Epoch 00115: val_loss improved from 0.11250 to 0.11178, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 116/150\n","13/13 [==============================] - 3s 243ms/step - loss: 0.0254 - accuracy: 0.9950 - val_loss: 0.1158 - val_accuracy: 0.9700\n","\n","Epoch 00116: val_loss did not improve from 0.11178\n","Epoch 117/150\n","13/13 [==============================] - 3s 246ms/step - loss: 0.0220 - accuracy: 0.9950 - val_loss: 0.1168 - val_accuracy: 0.9700\n","\n","Epoch 00117: val_loss did not improve from 0.11178\n","Epoch 118/150\n","13/13 [==============================] - 3s 251ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9700\n","\n","Epoch 00118: val_loss did not improve from 0.11178\n","Epoch 119/150\n","13/13 [==============================] - 3s 244ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 0.9700\n","\n","Epoch 00119: val_loss did not improve from 0.11178\n","Epoch 120/150\n","13/13 [==============================] - 3s 247ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9700\n","\n","Epoch 00120: val_loss did not improve from 0.11178\n","Epoch 121/150\n","13/13 [==============================] - 3s 259ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.1128 - val_accuracy: 0.9700\n","\n","Epoch 00121: val_loss did not improve from 0.11178\n","Epoch 122/150\n","13/13 [==============================] - 3s 259ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9700\n","\n","Epoch 00122: val_loss did not improve from 0.11178\n","Epoch 123/150\n","13/13 [==============================] - 3s 267ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9700\n","\n","Epoch 00123: val_loss did not improve from 0.11178\n","Epoch 124/150\n","13/13 [==============================] - 3s 260ms/step - loss: 0.0225 - accuracy: 0.9975 - val_loss: 0.1124 - val_accuracy: 0.9700\n","\n","Epoch 00124: val_loss did not improve from 0.11178\n","Epoch 125/150\n","13/13 [==============================] - 3s 267ms/step - loss: 0.0207 - accuracy: 0.9950 - val_loss: 0.1142 - val_accuracy: 0.9700\n","\n","Epoch 00125: val_loss did not improve from 0.11178\n","Epoch 126/150\n","13/13 [==============================] - 3s 261ms/step - loss: 0.0196 - accuracy: 0.9950 - val_loss: 0.1127 - val_accuracy: 0.9700\n","\n","Epoch 00126: val_loss did not improve from 0.11178\n","Epoch 127/150\n","13/13 [==============================] - 3s 259ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9700\n","\n","Epoch 00127: val_loss improved from 0.11178 to 0.10960, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 128/150\n","13/13 [==============================] - 3s 242ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9700\n","\n","Epoch 00128: val_loss improved from 0.10960 to 0.10925, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 129/150\n","13/13 [==============================] - 3s 250ms/step - loss: 0.0283 - accuracy: 0.9925 - val_loss: 0.1066 - val_accuracy: 0.9700\n","\n","Epoch 00129: val_loss improved from 0.10925 to 0.10657, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 130/150\n","13/13 [==============================] - 3s 241ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9700\n","\n","Epoch 00130: val_loss did not improve from 0.10657\n","Epoch 131/150\n","13/13 [==============================] - 3s 248ms/step - loss: 0.0178 - accuracy: 0.9975 - val_loss: 0.1115 - val_accuracy: 0.9700\n","\n","Epoch 00131: val_loss did not improve from 0.10657\n","Epoch 132/150\n","13/13 [==============================] - 3s 244ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9700\n","\n","Epoch 00132: val_loss did not improve from 0.10657\n","Epoch 133/150\n","13/13 [==============================] - 3s 238ms/step - loss: 0.0178 - accuracy: 0.9975 - val_loss: 0.1074 - val_accuracy: 0.9700\n","\n","Epoch 00133: val_loss did not improve from 0.10657\n","Epoch 134/150\n","13/13 [==============================] - 3s 242ms/step - loss: 0.0137 - accuracy: 0.9975 - val_loss: 0.1059 - val_accuracy: 0.9700\n","\n","Epoch 00134: val_loss improved from 0.10657 to 0.10589, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 135/150\n","13/13 [==============================] - 3s 262ms/step - loss: 0.0295 - accuracy: 0.9925 - val_loss: 0.1067 - val_accuracy: 0.9700\n","\n","Epoch 00135: val_loss did not improve from 0.10589\n","Epoch 136/150\n","13/13 [==============================] - 3s 264ms/step - loss: 0.0189 - accuracy: 0.9925 - val_loss: 0.1090 - val_accuracy: 0.9700\n","\n","Epoch 00136: val_loss did not improve from 0.10589\n","Epoch 137/150\n","13/13 [==============================] - 3s 259ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9700\n","\n","Epoch 00137: val_loss did not improve from 0.10589\n","Epoch 138/150\n","13/13 [==============================] - 3s 260ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9700\n","\n","Epoch 00138: val_loss did not improve from 0.10589\n","Epoch 139/150\n","13/13 [==============================] - 3s 269ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9700\n","\n","Epoch 00139: val_loss did not improve from 0.10589\n","Epoch 140/150\n","13/13 [==============================] - 3s 261ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9700\n","\n","Epoch 00140: val_loss did not improve from 0.10589\n","Epoch 141/150\n","13/13 [==============================] - 3s 258ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9700\n","\n","Epoch 00141: val_loss did not improve from 0.10589\n","Epoch 142/150\n","13/13 [==============================] - 3s 247ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9700\n","\n","Epoch 00142: val_loss did not improve from 0.10589\n","Epoch 143/150\n","13/13 [==============================] - 3s 244ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9700\n","\n","Epoch 00143: val_loss improved from 0.10589 to 0.10584, saving model to model.h5_gs\n","INFO:tensorflow:Assets written to: model.h5_gs/assets\n","Epoch 144/150\n","13/13 [==============================] - 4s 271ms/step - loss: 0.0180 - accuracy: 0.9975 - val_loss: 0.1070 - val_accuracy: 0.9700\n","\n","Epoch 00144: val_loss did not improve from 0.10584\n","Epoch 145/150\n","13/13 [==============================] - 3s 263ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1079 - val_accuracy: 0.9700\n","\n","Epoch 00145: val_loss did not improve from 0.10584\n","Epoch 146/150\n","13/13 [==============================] - 3s 262ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9700\n","\n","Epoch 00146: val_loss did not improve from 0.10584\n","Epoch 147/150\n","13/13 [==============================] - 3s 262ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9700\n","\n","Epoch 00147: val_loss did not improve from 0.10584\n","Epoch 148/150\n","13/13 [==============================] - 3s 257ms/step - loss: 0.0159 - accuracy: 0.9975 - val_loss: 0.1116 - val_accuracy: 0.9700\n","\n","Epoch 00148: val_loss did not improve from 0.10584\n","Epoch 149/150\n","13/13 [==============================] - 3s 255ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9700\n","\n","Epoch 00149: val_loss did not improve from 0.10584\n","Epoch 150/150\n","13/13 [==============================] - 3s 260ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.1065 - val_accuracy: 0.9700\n","\n","Epoch 00150: val_loss did not improve from 0.10584\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t6TOIVxhCoQr"},"source":["\n","\n","> Save History\n","\n"]},{"cell_type":"code","metadata":{"id":"3WhUxhtSEEAt","executionInfo":{"status":"ok","timestamp":1628696623669,"user_tz":-420,"elapsed":9,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["with open('history_model_gs', 'wb') as file:\n","    p.dump(hist.history, file)"],"execution_count":134,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gVQm6or8CqeQ"},"source":["\n","> Load History\n","\n"]},{"cell_type":"code","metadata":{"id":"e5f8y1zVEDzn","executionInfo":{"status":"ok","timestamp":1628696623670,"user_tz":-420,"elapsed":9,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["with open('history_model_gs', 'rb') as file:\n","    his = p.load(file)"],"execution_count":135,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ruz7rhlzCrQU"},"source":["\n","> Plot Loss ‡πÅ‡∏•‡∏∞ Validate Loss\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"eklcHOR_Fml4","executionInfo":{"status":"ok","timestamp":1628696623670,"user_tz":-420,"elapsed":9,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"3539d17f-0367-4322-c398-f255fbd8900e"},"source":["h1 = go.Scatter(y=his['loss'], \n","                    mode=\"lines\", line=dict(\n","                    width=2,\n","                    color='blue'),\n","                    name=\"loss\"\n","                   )\n","h2 = go.Scatter(y=his['val_loss'], \n","                    mode=\"lines\", line=dict(\n","                    width=2,\n","                    color='red'),\n","                    name=\"val_loss\"\n","                   )\n","\n","data = [h1,h2]\n","layout1 = go.Layout(title='Loss',\n","                   xaxis=dict(title='epochs'),\n","                   yaxis=dict(title=''))\n","fig1 = go.Figure(data = data, layout=layout1)\n","plotly.offline.iplot(fig1, filename=\"Intent Classification\")"],"execution_count":136,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"a0df7dd1-3866-4c35-a993-89586ccc38cc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"a0df7dd1-3866-4c35-a993-89586ccc38cc\")) {\n","                    Plotly.newPlot(\n","                        'a0df7dd1-3866-4c35-a993-89586ccc38cc',\n","                        [{\"line\": {\"color\": \"blue\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"loss\", \"type\": \"scatter\", \"y\": [0.9966906905174255, 0.8948636054992676, 0.7847704291343689, 0.6878719925880432, 0.6369487643241882, 0.6274975538253784, 0.6001542806625366, 0.5887429714202881, 0.48342666029930115, 0.5180566906929016, 0.41449815034866333, 0.3893429934978485, 0.4202634394168854, 0.397960364818573, 0.37423163652420044, 0.369716078042984, 0.3773884177207947, 0.3575783669948578, 0.37222397327423096, 0.3545264005661011, 0.3300637900829315, 0.28652188181877136, 0.3159394860267639, 0.29567742347717285, 0.25700122117996216, 0.2339811772108078, 0.2529119551181793, 0.2478218674659729, 0.27515313029289246, 0.21748633682727814, 0.20595994591712952, 0.2401016801595688, 0.23161545395851135, 0.22424256801605225, 0.1943998783826828, 0.2211194634437561, 0.1816176176071167, 0.20984381437301636, 0.15785737335681915, 0.14345504343509674, 0.1580972522497177, 0.20921674370765686, 0.21931007504463196, 0.15091216564178467, 0.1544051319360733, 0.14416001737117767, 0.17137295007705688, 0.13996486365795135, 0.11599627137184143, 0.14128108322620392, 0.14086481928825378, 0.12062294036149979, 0.11232814937829971, 0.126483753323555, 0.11780514568090439, 0.11392762511968613, 0.10777940601110458, 0.0932183638215065, 0.08340403437614441, 0.09418246895074844, 0.07716862112283707, 0.12346802651882172, 0.08103325217962265, 0.06392180174589157, 0.07384569942951202, 0.08376013487577438, 0.060707058757543564, 0.08178219944238663, 0.08720755577087402, 0.07005630433559418, 0.0848727896809578, 0.05632321909070015, 0.058997269719839096, 0.06371680647134781, 0.042509760707616806, 0.05591956153512001, 0.06394872069358826, 0.050263404846191406, 0.03838162124156952, 0.04427574574947357, 0.05263450741767883, 0.05480886995792389, 0.048479340970516205, 0.04647086560726166, 0.0349520668387413, 0.04605398327112198, 0.03834221512079239, 0.04175040125846863, 0.039778780192136765, 0.03730452433228493, 0.048693832010030746, 0.038742661476135254, 0.05082014575600624, 0.031047819182276726, 0.02944943495094776, 0.034855399280786514, 0.03603355959057808, 0.028156183660030365, 0.029952125623822212, 0.030045878142118454, 0.03103330172598362, 0.031627777963876724, 0.02145756222307682, 0.027562875300645828, 0.02233889140188694, 0.04996705427765846, 0.027647947892546654, 0.02129242569208145, 0.029761850833892822, 0.01780327409505844, 0.026139773428440094, 0.03672296553850174, 0.03585577383637428, 0.024257047101855278, 0.024384109303355217, 0.025383586063981056, 0.02197001688182354, 0.016803128644824028, 0.016903147101402283, 0.012415227480232716, 0.012433110736310482, 0.012485956773161888, 0.015350298024713993, 0.02246953547000885, 0.020744692534208298, 0.019632652401924133, 0.013308526016771793, 0.014246390201151371, 0.028312720358371735, 0.017064156010746956, 0.017794271931052208, 0.008998743258416653, 0.017804589122533798, 0.01371171697974205, 0.029498817399144173, 0.018895184621214867, 0.012323473580181599, 0.009974001906812191, 0.015017452649772167, 0.009178073145449162, 0.01241745613515377, 0.011042854748666286, 0.010386835783720016, 0.017952119931578636, 0.00956286396831274, 0.009955224581062794, 0.009883898310363293, 0.015886861830949783, 0.011936775408685207, 0.012143346481025219]}, {\"line\": {\"color\": \"red\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"val_loss\", \"type\": \"scatter\", \"y\": [0.6999236345291138, 0.6884387731552124, 0.6777265071868896, 0.6666674017906189, 0.6545484066009521, 0.6409220099449158, 0.6287796497344971, 0.6155821084976196, 0.601027250289917, 0.5866812467575073, 0.5705361366271973, 0.5537938475608826, 0.5383133888244629, 0.5216432809829712, 0.5076402425765991, 0.4910833239555359, 0.4732270836830139, 0.45654296875, 0.44253435730934143, 0.43120667338371277, 0.4172956943511963, 0.39929211139678955, 0.38264039158821106, 0.3696287274360657, 0.35343021154403687, 0.33872777223587036, 0.3236512243747711, 0.30756062269210815, 0.2948819100856781, 0.28375887870788574, 0.27254676818847656, 0.2618045508861542, 0.2539304494857788, 0.24914850294589996, 0.24616365134716034, 0.2403985857963562, 0.23486700654029846, 0.22792230546474457, 0.22196751832962036, 0.21548427641391754, 0.20988121628761292, 0.20752353966236115, 0.20515644550323486, 0.20072506368160248, 0.19858701527118683, 0.19773812592029572, 0.19537708163261414, 0.19364100694656372, 0.192305788397789, 0.18949930369853973, 0.18579694628715515, 0.18305246531963348, 0.18021346628665924, 0.17827674746513367, 0.17933689057826996, 0.1794205904006958, 0.1775507777929306, 0.17675979435443878, 0.1741022914648056, 0.17513887584209442, 0.17616790533065796, 0.17163124680519104, 0.17030853033065796, 0.1644143909215927, 0.1603592336177826, 0.16055643558502197, 0.1610683649778366, 0.15746884047985077, 0.1553829461336136, 0.15424610674381256, 0.15363559126853943, 0.15194253623485565, 0.14937523007392883, 0.1480417102575302, 0.14748626947402954, 0.14815016090869904, 0.1474936604499817, 0.14382034540176392, 0.14471593499183655, 0.14630016684532166, 0.1468450427055359, 0.14415980875492096, 0.14103995263576508, 0.13906048238277435, 0.1414848268032074, 0.14465579390525818, 0.14295578002929688, 0.13821497559547424, 0.13819852471351624, 0.13775208592414856, 0.14276352524757385, 0.14339609444141388, 0.14149051904678345, 0.13622958958148956, 0.1326475441455841, 0.13076168298721313, 0.13124030828475952, 0.12925373017787933, 0.12726128101348877, 0.13013392686843872, 0.13214851915836334, 0.1288822740316391, 0.12914566695690155, 0.12630939483642578, 0.12393567711114883, 0.1303630769252777, 0.1302763819694519, 0.1257169395685196, 0.12468592822551727, 0.12210351973772049, 0.1199386864900589, 0.11719563603401184, 0.11342314630746841, 0.11250441521406174, 0.11177583783864975, 0.11582235246896744, 0.11682257056236267, 0.11666356027126312, 0.11483559012413025, 0.11378251761198044, 0.11275873333215714, 0.11356640607118607, 0.11362041532993317, 0.11239084601402283, 0.11419837921857834, 0.11271148920059204, 0.10960213840007782, 0.1092517077922821, 0.10657447576522827, 0.11763045191764832, 0.11145622283220291, 0.11043672263622284, 0.10744940489530563, 0.10588502883911133, 0.10671732574701309, 0.10899663716554642, 0.10819319635629654, 0.1073194146156311, 0.10685563087463379, 0.10692305862903595, 0.10914915800094604, 0.10626966506242752, 0.10584022849798203, 0.10697048902511597, 0.1079491600394249, 0.10820888727903366, 0.10696385055780411, 0.11162994056940079, 0.11181947588920593, 0.10646393895149231]}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Loss\"}, \"xaxis\": {\"title\": {\"text\": \"epochs\"}}, \"yaxis\": {\"title\": {\"text\": \"\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('a0df7dd1-3866-4c35-a993-89586ccc38cc');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"wPUJCjH5Cw7C"},"source":["\n","> Plot Accuracy ‡πÅ‡∏•‡∏∞ Validate Accuracy\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"L9eMYiNBF182","executionInfo":{"status":"ok","timestamp":1628696623671,"user_tz":-420,"elapsed":9,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"f486729e-36ae-4436-92e0-e458fa754861"},"source":["h1 = go.Scatter(y=his['accuracy'], \n","                    mode=\"lines\", line=dict(\n","                    width=2,\n","                    color='blue'),\n","                    name=\"acc\"\n","                   )\n","h2 = go.Scatter(y=his['val_accuracy'], \n","                    mode=\"lines\", line=dict(\n","                    width=2,\n","                    color='red'),\n","                    name=\"val_acc\"\n","                   )\n","\n","data = [h1,h2]\n","layout1 = go.Layout(title='Accuracy',\n","                   xaxis=dict(title='epochs'),\n","                   yaxis=dict(title=''))\n","fig1 = go.Figure(data = data, layout=layout1)\n","plotly.offline.iplot(fig1, filename=\"Intent Classification\")"],"execution_count":137,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"2208cefe-1fda-4748-867e-6691af3ed979\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"2208cefe-1fda-4748-867e-6691af3ed979\")) {\n","                    Plotly.newPlot(\n","                        '2208cefe-1fda-4748-867e-6691af3ed979',\n","                        [{\"line\": {\"color\": \"blue\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"acc\", \"type\": \"scatter\", \"y\": [0.5074999928474426, 0.5199999809265137, 0.5849999785423279, 0.6324999928474426, 0.6650000214576721, 0.7024999856948853, 0.6775000095367432, 0.7149999737739563, 0.7699999809265137, 0.7574999928474426, 0.8149999976158142, 0.8199999928474426, 0.8025000095367432, 0.8174999952316284, 0.8324999809265137, 0.8424999713897705, 0.824999988079071, 0.8299999833106995, 0.8424999713897705, 0.8349999785423279, 0.8725000023841858, 0.8824999928474426, 0.8774999976158142, 0.8799999952316284, 0.9049999713897705, 0.9100000262260437, 0.9024999737739563, 0.8899999856948853, 0.887499988079071, 0.9024999737739563, 0.925000011920929, 0.9175000190734863, 0.9200000166893005, 0.9100000262260437, 0.9225000143051147, 0.9100000262260437, 0.9375, 0.9125000238418579, 0.9549999833106995, 0.9375, 0.9424999952316284, 0.9200000166893005, 0.9125000238418579, 0.949999988079071, 0.9375, 0.9449999928474426, 0.925000011920929, 0.9549999833106995, 0.9524999856948853, 0.9574999809265137, 0.9424999952316284, 0.9674999713897705, 0.9599999785423279, 0.9549999833106995, 0.9599999785423279, 0.9674999713897705, 0.9599999785423279, 0.9649999737739563, 0.9725000262260437, 0.9725000262260437, 0.9800000190734863, 0.9474999904632568, 0.9674999713897705, 0.987500011920929, 0.9850000143051147, 0.9725000262260437, 0.9900000095367432, 0.9800000190734863, 0.9725000262260437, 0.9775000214576721, 0.9725000262260437, 0.9850000143051147, 0.987500011920929, 0.9775000214576721, 0.9950000047683716, 0.9850000143051147, 0.9775000214576721, 0.9825000166893005, 1.0, 0.9850000143051147, 0.9825000166893005, 0.9850000143051147, 0.9800000190734863, 0.9900000095367432, 1.0, 0.9800000190734863, 0.9850000143051147, 0.987500011920929, 0.9900000095367432, 0.9950000047683716, 0.9825000166893005, 0.9900000095367432, 0.9850000143051147, 0.9950000047683716, 0.9975000023841858, 0.9950000047683716, 0.9925000071525574, 0.9950000047683716, 0.9950000047683716, 0.9925000071525574, 0.9975000023841858, 0.9900000095367432, 0.9975000023841858, 0.9975000023841858, 1.0, 0.9825000166893005, 0.9950000047683716, 1.0, 0.9925000071525574, 1.0, 0.9975000023841858, 0.9900000095367432, 0.987500011920929, 0.9950000047683716, 0.9950000047683716, 0.9950000047683716, 0.9950000047683716, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9975000023841858, 0.9950000047683716, 0.9950000047683716, 1.0, 1.0, 0.9925000071525574, 1.0, 0.9975000023841858, 1.0, 0.9975000023841858, 0.9975000023841858, 0.9925000071525574, 0.9925000071525574, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9975000023841858, 1.0, 1.0, 1.0, 0.9975000023841858, 1.0, 1.0]}, {\"line\": {\"color\": \"red\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"val_acc\", \"type\": \"scatter\", \"y\": [0.44999998807907104, 0.5699999928474426, 0.6000000238418579, 0.6899999976158142, 0.75, 0.8299999833106995, 0.8299999833106995, 0.8500000238418579, 0.8399999737739563, 0.8600000143051147, 0.8799999952316284, 0.8799999952316284, 0.8799999952316284, 0.8799999952316284, 0.8899999856948853, 0.8799999952316284, 0.8799999952316284, 0.8799999952316284, 0.8799999952316284, 0.8799999952316284, 0.8700000047683716, 0.8700000047683716, 0.8700000047683716, 0.8799999952316284, 0.8799999952316284, 0.8799999952316284, 0.8799999952316284, 0.8799999952316284, 0.8899999856948853, 0.8899999856948853, 0.8799999952316284, 0.8799999952316284, 0.8899999856948853, 0.8899999856948853, 0.8799999952316284, 0.8899999856948853, 0.8799999952316284, 0.8799999952316284, 0.8899999856948853, 0.8999999761581421, 0.8999999761581421, 0.8999999761581421, 0.8999999761581421, 0.9100000262260437, 0.9100000262260437, 0.9100000262260437, 0.9100000262260437, 0.9100000262260437, 0.9100000262260437, 0.9100000262260437, 0.9100000262260437, 0.9100000262260437, 0.9100000262260437, 0.9200000166893005, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.9399999976158142, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.9599999785423279, 0.9700000286102295, 0.9700000286102295, 0.9599999785423279, 0.9599999785423279, 0.9599999785423279, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295, 0.9700000286102295]}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Accuracy\"}, \"xaxis\": {\"title\": {\"text\": \"epochs\"}}, \"yaxis\": {\"title\": {\"text\": \"\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('2208cefe-1fda-4748-867e-6691af3ed979');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ek2sBum5-zKq","executionInfo":{"status":"ok","timestamp":1628696626089,"user_tz":-420,"elapsed":2426,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"f6d81b00-d8f3-4450-ab0b-fa01dce01c83"},"source":["predict_model = load_model(filename) \n","predict_model.summary()"],"execution_count":138,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, 65, 128)           202496    \n","_________________________________________________________________\n","bidirectional_3 (Bidirection (None, 256)               198144    \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 64)                8256      \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 64)                256       \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 2)                 130       \n","=================================================================\n","Total params: 442,178\n","Trainable params: 239,554\n","Non-trainable params: 202,624\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cFxx9pAG-12a","executionInfo":{"status":"ok","timestamp":1628696626090,"user_tz":-420,"elapsed":10,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"a0576dc5-2f68-4d6d-bad6-39ad15d28829"},"source":["score = predict_model.evaluate(val_X, val_Y, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":139,"outputs":[{"output_type":"stream","text":["Test loss: 0.10584022849798203\n","Test accuracy: 0.9700000286102295\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I52NzM8UGJVz","executionInfo":{"status":"ok","timestamp":1628696626496,"user_tz":-420,"elapsed":410,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"d62eadfe-fe8c-4112-9916-70072defbe34"},"source":["predicted_classes = predict_model.predict_classes(val_X)\n","predicted_classes.shape"],"execution_count":140,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning:\n","\n","`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["(100,)"]},"metadata":{"tags":[]},"execution_count":140}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OW9OQ2IYGJSZ","executionInfo":{"status":"ok","timestamp":1628696626497,"user_tz":-420,"elapsed":8,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"f95468c1-fd16-4c5f-e3c6-7ca020089ff3"},"source":["y_true = np.argmax(val_Y,axis = 1)\n","print(val_Y[0])\n","print(y_true[0])"],"execution_count":141,"outputs":[{"output_type":"stream","text":["[1. 0.]\n","0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Rh09LaV0C5zs"},"source":["\n","\n","> Save Confusion Matrix\n","\n"]},{"cell_type":"code","metadata":{"id":"40TU482PGJP0","executionInfo":{"status":"ok","timestamp":1628696626497,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["cm = confusion_matrix(y_true, predicted_classes)\n","np.savetxt(\"confusion_matrix_gs.csv\", cm, delimiter=\",\")"],"execution_count":142,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TibayIxcC7-8"},"source":["\n","> Plot Confusion Matrix\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":819},"id":"CB0COh35GJNV","executionInfo":{"status":"ok","timestamp":1628696627176,"user_tz":-420,"elapsed":682,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"98fb516b-e2b0-4054-bcd4-04db50824910"},"source":["import seaborn as sn\n","import matplotlib.pyplot as plt\n","\n","df_cm = pd.DataFrame(cm, range(2), range(2))\n","plt.figure(figsize=(20,14))\n","sn.set(font_scale=1.2) # for label size\n","sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 14}, fmt='g') # for num predict size\n","\n","plt.show()"],"execution_count":143,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1440x1008 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"PMo6Z9lCGQUB","executionInfo":{"status":"ok","timestamp":1628696627176,"user_tz":-420,"elapsed":13,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["label_dict = output_tokenizer.word_index"],"execution_count":144,"outputs":[]},{"cell_type":"code","metadata":{"id":"PLTFbwAEGSzB","executionInfo":{"status":"ok","timestamp":1628696627177,"user_tz":-420,"elapsed":14,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}}},"source":["label = [key for key, value in label_dict.items()]"],"execution_count":145,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9KJe1AykC_3L"},"source":["\n","\n","> ‡πÅ‡∏™‡∏î‡∏á Precision, Recall, F1-score\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PPCJazAYGUTv","executionInfo":{"status":"ok","timestamp":1628696627179,"user_tz":-420,"elapsed":15,"user":{"displayName":"Nuttida Lapthanachai","photoUrl":"","userId":"03490394949192523642"}},"outputId":"e1dc67dd-a6db-4b38-fe8e-ee64a90e3015"},"source":["print(classification_report(y_true, predicted_classes, target_names=label, digits=4))"],"execution_count":146,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         neg     0.9434    1.0000    0.9709        50\n","         pos     1.0000    0.9400    0.9691        50\n","\n","    accuracy                         0.9700       100\n","   macro avg     0.9717    0.9700    0.9700       100\n","weighted avg     0.9717    0.9700    0.9700       100\n","\n"],"name":"stdout"}]}]}